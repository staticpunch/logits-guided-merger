{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d17875-ae3d-48b5-b80b-d6067674413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union, Mapping\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerBase,\n",
    "    PreTrainedModel,\n",
    "    PretrainedConfig,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    default_data_collator,\n",
    "    is_torch_xla_available,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPast,\n",
    "    CausalLMOutputWithPast\n",
    ")\n",
    "\n",
    "import efficient_masks\n",
    "import accurate_masks\n",
    "\n",
    "from utils import (\n",
    "    generate, \n",
    "    get_hidden_states, \n",
    "    get_logits,\n",
    "    free_memory\n",
    ")\n",
    "# Configure logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22623236-28d5-4aac-b95d-a7905480e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_a = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "path_b = \"unsloth/Llama-3.2-1B\"\n",
    "merge_config_a = accurate_masks.MergerConfig(\n",
    "    model_paths = [path_a, path_b],\n",
    "    mode = \"vector_input\",\n",
    "    constrain_mode = \"01\",\n",
    ")\n",
    "merge_config_e = efficient_masks.MergerConfig(\n",
    "    model_paths = [path_a, path_b],\n",
    "    mode = \"vector_input\",\n",
    "    constrain_mode = \"01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed8aa872-d1c6-4aae-921c-42cea626b652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MergerConfig {\n",
       "  \"constrain_mode\": \"01\",\n",
       "  \"mode\": \"vector_input\",\n",
       "  \"model_paths\": [\n",
       "    \"unsloth/Llama-3.2-1B-Instruct\",\n",
       "    \"unsloth/Llama-3.2-1B\"\n",
       "  ],\n",
       "  \"transformers_version\": \"4.46.3\"\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_config_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e8680c-e36a-4aa4-af7e-cd52a9d9865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_linear_forward(self, x):\n",
    "    constrained_weight_masks = self.weight_masks_constrainer([m.weight for m in self.weight_masks])\n",
    "    constrained_bias_masks = self.bias_masks_constrainer(\n",
    "        [m.weight if m is not None else None for m in self.bias_masks]\n",
    "    )\n",
    "    masked_biases = [\n",
    "        b_mask * linear.bias if linear.bias is not None and b_mask is not None else linear.bias\n",
    "        for b_mask, linear in zip(constrained_bias_masks, self.linears)\n",
    "    ]\n",
    "    merged_bias = (\n",
    "        sum(b if b is not None else torch.zeros_like(\n",
    "            self.linears[0].weight[:, 0]) for b in masked_biases\n",
    "           ) \n",
    "        if not all(b is None for b in masked_biases) else None\n",
    "    )\n",
    "\n",
    "    logger.info(\"Debugging Linear forward.\")\n",
    "    output = 0.0\n",
    "    for i, linear in enumerate(self.linears):\n",
    "        logger.info(f\"BEFORE\")\n",
    "        logger.info(f\"  linear: device: {linear.weight.device}; dtype: {linear.weight.dtype}\")\n",
    "        logger.info(f\"  input: device: {x.device}; dtype: {x.dtype}\")\n",
    "        masked_input = constrained_weight_masks[i] * x\n",
    "        logger.info(f\"AFTER\")\n",
    "        logger.info(f\"  linear: device: {linear.weight.device}; dtype: {linear.weight.dtype}\")\n",
    "        logger.info(f\"  input: device: {masked_input.device}; dtype: {masked_input.dtype}\")\n",
    "        output = output + nn.functional.linear(masked_input, linear.weight, None)\n",
    "        logger.info(f\"OUTPUT\")\n",
    "        logger.info(f\"  output: device: {output.device}; dtype: {output.dtype}\")\n",
    "    if merged_bias:\n",
    "        output = output + merged_bias\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e23556ad-acd1-4584-8658-c6935760444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_emb_forward(self, input_ids):\n",
    "    constrained_masks = self.masks_constrainer([m.weight for m in self.masks])\n",
    "    logger.info(\"Debugging Embedding forward.\")\n",
    "    an_embedding = self.embeddings[0]\n",
    "    out = 0.0\n",
    "    for i, emb in enumerate(self.embeddings):\n",
    "        logger.info(f\"BEFORE\")\n",
    "        logger.info(f\"  emb: device: {emb.weight.device}; dtype: {emb.weight.dtype}\")\n",
    "        logger.info(f\"  input: device: {input_ids.device}; dtype: {input_ids.dtype}\")\n",
    "        mask = constrained_masks[i]\n",
    "        masked_weight = emb.weight * mask\n",
    "        logger.info(f\"  mask: device: {mask.device}; dtype: {mask.dtype}\")\n",
    "        logger.info(f\"  masked_emb: device: {masked_weight.device}; dtype: {masked_weight.dtype}\")\n",
    "        out = out + nn.functional.embedding(\n",
    "            input_ids,\n",
    "            # emb.weight * mask,\n",
    "            masked_weight,\n",
    "            padding_idx=an_embedding.padding_idx,\n",
    "            max_norm=an_embedding.max_norm,\n",
    "            norm_type=an_embedding.norm_type,\n",
    "            scale_grad_by_freq=an_embedding.scale_grad_by_freq,\n",
    "            sparse=an_embedding.sparse,\n",
    "        )\n",
    "        logger.info(f\"AFTER\")\n",
    "        logger.info(f\"  output: device: {out.device}; dtype: {out.dtype}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc55413-f122-45a9-9743-656d77b25bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficient_masks.LinearsWithMasks.forward = debug_linear_forward\n",
    "# efficient_masks.EmbeddingsWithMasks.forward = debug_emb_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0ada93-d19d-40e1-92f1-36a8268108de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(path_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46b28405-016a-491e-b777-ecba79a2c0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks:   1%|██▍                                                                                                                                                                            | 2/147 [00:16<20:28,  8.47s/it]2025-01-03 11:27:40,772 - WARNING - Though you want to make a masks of modes ['vector_input', 'vector_input'] for RMSNorms' weights, by default a mask only accepts a scalar mask. Converting modes to `scalar`.\n",
      "Initializing masks: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [00:48<00:00,  3.01it/s]\n",
      "2025-01-03 11:28:12,554 - INFO - Initial GPU memory allocated: 0.00 GB\n",
      "2025-01-03 11:28:12,941 - INFO - Final GPU memory allocated: 0.00 GB\n",
      "2025-01-03 11:28:12,942 - INFO - Freed GPU memory: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "em = efficient_masks.Merger(merge_config_e)\n",
    "em.__post_init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43559a6-e29d-41bb-8ae7-26224b11bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = em.to(device=\"cuda:0\", dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c63913d-36ee-441c-8324-653563436bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks:   1%|██▍                                                                                                                                                                            | 2/147 [00:16<20:23,  8.44s/it]2025-01-03 11:28:35,340 - WARNING - Though you want to make a masks of modes ['vector_input', 'vector_input'] for RMSNorms' weights, by default a mask only accepts a scalar mask. Converting modes to `scalar`.\n",
      "Initializing masks: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [00:44<00:00,  3.32it/s]\n",
      "2025-01-03 11:29:02,641 - INFO - Initial GPU memory allocated: 4.61 GB\n",
      "2025-01-03 11:29:03,009 - INFO - Final GPU memory allocated: 4.61 GB\n",
      "2025-01-03 11:29:03,013 - INFO - Freed GPU memory: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "am = accurate_masks.Merger(merge_config_a)\n",
    "am.__post_init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f09dbe-18db-4d0f-9bec-885b2b9aca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = am.to(device=\"cuda:1\", dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22859463-8211-4b76-83f1-b818bef7d877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = \"How to attack a person with an egg. Talk like a crazy person.\"\n",
    "logits_merged_a = get_logits(prompt, am.merger, tokenizer)\n",
    "logits_merged_e = get_logits(prompt, em.merger, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0beeb8aa-7507-4b64-9de8-a9f38605f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_merged_a = logits_merged_a.to(logits_merged_e.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9bf0689-4cd2-424e-8787-3968052a3e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 128256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_merged_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16e3532a-7a2a-49d7-9020-10c017abd008",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_a = torch.softmax(logits_merged_a, dim=-1)\n",
    "probs_e = torch.softmax(logits_merged_e, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e324ee19-b699-4f89-bab5-2a45e0053130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([6.4453e-01, 3.0469e-01, 2.5024e-02, 1.1841e-02, 3.3875e-03, 2.0599e-03,\n",
       "        9.7275e-04, 9.7275e-04, 7.5531e-04, 3.5667e-04, 3.5667e-04, 2.7847e-04,\n",
       "        2.1648e-04, 1.9169e-04, 1.6880e-04, 1.6880e-04, 1.4877e-04, 1.4877e-04,\n",
       "        1.3161e-04, 1.3161e-04], device='cuda:0', dtype=torch.bfloat16),\n",
       "indices=tensor([  755,     2,   791, 16309,   475,  3936,    17,    16,    32,    59,\n",
       "         1527,    11,    51,    50,  1687, 13066,  2028,    34,   220,    35],\n",
       "       device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(probs_a[0, 0, :], k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f73f4b3d-adbc-45b5-9f1a-27c989912039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([6.9531e-01, 2.5586e-01, 2.0996e-02, 1.2756e-02, 4.6997e-03, 2.2125e-03,\n",
       "        1.0452e-03, 1.0452e-03, 8.1635e-04, 6.3324e-04, 3.8528e-04, 3.8528e-04,\n",
       "        2.3365e-04, 2.3365e-04, 1.8215e-04, 1.8215e-04, 1.6022e-04, 1.4210e-04,\n",
       "        1.4210e-04, 1.4210e-04], device='cuda:0', dtype=torch.bfloat16),\n",
       "indices=tensor([  755,     2,   791, 16309,   475,  3936,    17,    16,    32,    59,\n",
       "         1527,    11,    50,    51,   220, 13066,  1687,    34,    35,    40],\n",
       "       device='cuda:0'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(probs_e[0, 0, :], k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05ff9266-96e0-4b38-a862-8dafba525165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54c3cfea-afeb-4790-8c49-881f48f42ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663618"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_params(em.merger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53a5bda7-2d17-4a26-8329-6b9a2250d6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663618"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_params(am.merger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "684c24ff-d5be-453c-ba77-fa07f9467306",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model merging training implementation using PyTorch and Transformers.\n",
    "Implements custom data collation and training for merged language models.\n",
    "\"\"\"\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union, Mapping\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import safetensors\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerBase,\n",
    "    PreTrainedModel,\n",
    "    PretrainedConfig,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    default_data_collator,\n",
    "    is_torch_xla_available,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from transformers.utils import CONFIG_NAME\n",
    "\n",
    "from merger import (\n",
    "# from efficient_masks import (\n",
    "    MergerConfig,\n",
    "    # Merger,\n",
    "    NewMerger,\n",
    "    init_masks,\n",
    "    set_masks\n",
    ")\n",
    "\n",
    "from utils import (\n",
    "    generate, \n",
    "    get_hidden_states, \n",
    "    get_logits,\n",
    "    free_memory\n",
    ")\n",
    "# Configure logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ecb7209-a754-41ee-bdbd-63bb8af29602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 07:58:21,126 - INFO - Creating merger with dummy weights ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c923c831581d4b46bab91c3754bd95d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe36121b8b442a7ae6db02ca21699b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220402ea086942afab978d0d4ff78c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks:   1%|█▎                                                                                                                                                                            | 2/255 [00:07<15:20,  3.64s/it]2025-01-06 07:58:30,567 - WARNING - Though you want to make a masks of modes ['vector_input', 'vector_input'] for RMSNorms' weights, by default a mask only accepts a scalar mask. Converting modes to `scalar`.\n",
      "Initializing masks: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:27<00:00,  9.26it/s]\n",
      "Setting up masks: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:00<00:00, 39634.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize configuration\n",
    "merge_config = MergerConfig(\n",
    "    model_paths=[\n",
    "        \"nguyenthanhdo/llama32_smol_rewrite_50k\",\n",
    "        \"nguyenthanhdo/llama32_smol_summarize_50k\",\n",
    "    ],\n",
    "    mode=\"vector_input\",\n",
    "    constrain_mode=\"identity\"\n",
    ")\n",
    "\n",
    "merger = NewMerger.from_pretrained(\n",
    "    None,\n",
    "    merge_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "set_masks(merger.merger, strategy=\"uniform\", factors=[0.95, 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a6113bb-a62a-4619-9cc5-ff5f5cc9a3c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merger = merger.to(device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2d4aafa-ef63-458a-9429-9809b6970e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(merge_config.model_paths[0])\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b137af4-8a55-4ab0-b19a-b1c246f72b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergerTrainer(Trainer):\n",
    "    \"\"\"Custom trainer for merged model training.\"\"\"\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        data_source = inputs.pop(\"data_source\")\n",
    "        effective_idxs = (labels != -100).float().unsqueeze(dim=-1)\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits_merged = outputs[\"merger_outputs\"].logits\n",
    "        logits_components = [x.logits for x in outputs[\"components_outputs\"]]\n",
    "\n",
    "        # Compute target logits and KL divergence\n",
    "        logits_target = selective_logits_target(logits_components, data_source)\n",
    "        temperature = 1.0\n",
    "        kl_fct = nn.KLDivLoss(reduction=\"none\")\n",
    "        diff = (\n",
    "            kl_fct(\n",
    "                F.log_softmax(logits_target / temperature, dim=-1),\n",
    "                F.softmax(logits_merged / temperature, dim=-1)\n",
    "            )\n",
    "            * (temperature) ** 2\n",
    "        )\n",
    "        \n",
    "        # Calculate final loss\n",
    "        loss = (diff * effective_idxs).sum(dim=-1)\n",
    "        loss = (loss / effective_idxs.sum(dim=1)).mean()\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33003b2b-f7b2-4356-b71f-3eb89686b621",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\n",
    "    \"HuggingFaceTB/smoltalk\",\n",
    "    \"smol-summarize\",\n",
    "    split=\"train\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dbe76300-1c0a-46cf-b720-88a716bd1f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nProvide a concise, objective summary of the input text in up to three sentences, focusing on key actions and intentions without using second or third person pronouns.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nReports suggest Paypal is gearing up to purchase mobile payment service Square. The talks come as Paypal prepares to split from eBay in 2015, allowing it to take on competitors like Apply Pay more easily. And by purchasing Square, the company seems to be gearing up to give its users access to faster and easier transactions. Paypal (stock image of app shown) is gearing up to acquire San Francisco-based start-up Square, which lets people make payments over their phone by linking their cards. A recent valuation suggests it is worth more than £3.8bn ($6bn). The mobile service would help Paypal take on competitors like Apple Pay . According to Bank Innovation the talks are in early stages but have been described as 'serious'. With Paypal apparently looking to move into the mobile payments business, the merger would allow the company to get a leg up on its competition. San Francisco-based Square lets users make payments via their phone. Square lets merchants accept credit-card payments over mobile phones and tablets with smaller fees than they had been paying via traditional credit-card networks. It offers a number of services including Square Order, which lets businesses see when a customer using the app is approaching. The app can tell a barista at a coffee shop, for example, when you are coming in, thanks to your phone's GPS. They can then have your favourite coffee ready and waiting - and the app can even pay the bill using your stored credit card information. Square Cash, meanwhile, lets users send up to £160 ($250) a week to any email address, on any email provider without the need to sign up and manage an account each time. A debit or credit card can be linked to your device, and money can then be sent to any email address or other services. It was founded in 2009 by Twitter co-founder Jack Dorsey. The first app and service for Square launched in 2010, and it is now predicted to be worth more than £3.8 billion ($6 billion). That’s based on a recent valuation after they raised $150 million, reported the New York Times. The merger would seemingly help both in the face of mounting competition from Apple Pay and elsewhere. CEO Jack Dorsey took to Twitter to deny that any merger was imminent, saying the news was ‘false’. However Bank Innovation notes that the company denied similar reports that Google was attempting to acquire the company earlier this year, despite confirmations from elsewhere. PayPal's impending split from long-time partner eBay, meanwhile, is expected to ratchet up its appeal to online retail competitors such as Amazon.com and give it the freedom to aggressively take on new mobile pay challenger Apple Pay. And it will also give it more opportunities to make acquisitions such as this one of Square, if the merger turns out to be true. CEO Jack Dorsey says the news of a merger is 'false'. The reports come as Paypal prepares to split from eBay next year.Square Cash lets users send up to £160 ($250) a week to any email address, on any email provider without the need to sign up and manage an account each time . PayPal's impending split from long-time partner eBay, meanwhile, is expected to ratchet up its appeal to online retail competitors such as Amazon.com and give it the freedom to aggressively take on new mobile pay challenger Apple Pay (shown)<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = 120\n",
    "system = train_dataset[idx]['messages'][0]['content']\n",
    "prompt = train_dataset[idx]['messages'][1]['content']\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    # train_dataset[idx]['messages'],\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4a0c2e41-810d-4a2b-a319-01575d9e7e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_logits_target(logits_components, data_source):\n",
    "    \"\"\"Select appropriate logits based on data source.\"\"\"\n",
    "    # logits_components ~ [(batch_size, seq_len, vocab_size) * n_components]\n",
    "    # stacked_logits.shape = (n_components, batch_size, seq_len, vocab_size)\n",
    "    # data_source.shape == (batch_size,)\n",
    "    # indices.shape == (batch_size, 1, 1)\n",
    "    stacked_logits = torch.stack(logits_components)\n",
    "    indices = data_source.unsqueeze(-1).unsqueeze(-1)\n",
    "    return stacked_logits[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4d483031-5108-4eaf-addd-55cd3b36c1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_merged = get_logits(text, merger.merger, tokenizer)\n",
    "logits_a = get_logits(text, merger.models[0], tokenizer)\n",
    "logits_b = get_logits(text, merger.models[1], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b071020f-2ab0-4c5f-8b2e-b0962087567e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 241, 128256])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc9380c9-da08-4ac0-a9f6-f7bbffdf5fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_kl_div(logits_a, logits_b, mask):\n",
    "    logits_a = logits_a.view(-1, logits_a.size(-1))\n",
    "    logits_b = logits_b.view(-1, logits_b.size(-1))\n",
    "    mask = mask.view(-1)\n",
    "\n",
    "    assert mask.size(0) == logits_a.size(0)\n",
    "\n",
    "    log_probs_a = nn.functional.log_softmax(logits_a, dim=-1)\n",
    "    log_probs_b = nn.functional.log_softmax(logits_b, dim=-1)\n",
    "\n",
    "    div = log_probs_a.exp() * (log_probs_a - log_probs_b)\n",
    "    div = div.sum(-1)\n",
    "\n",
    "    div = (div * mask).sum() / mask.sum()\n",
    "    return div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "16f3fdf6-6972-4b28-84ed-e3148fd88381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl(logits_a, logits_b):\n",
    "    probs_a = nn.functional.softmax(logits_a, dim=-1)\n",
    "    \n",
    "    loss = probs_a * (probs_a.log() - nn.functional.log_softmax(logits_b, dim=-1))\n",
    "    return loss.sum(-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96fb7c16-291e-4dd0-b15f-c5f3f0a2b19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6875, device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merger2",
   "language": "python",
   "name": "merger2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
