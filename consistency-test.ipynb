{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6d17875-ae3d-48b5-b80b-d6067674413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union, Mapping\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerBase,\n",
    "    PreTrainedModel,\n",
    "    PretrainedConfig,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    default_data_collator,\n",
    "    is_torch_xla_available,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPast,\n",
    "    CausalLMOutputWithPast\n",
    ")\n",
    "\n",
    "import efficient_masks\n",
    "import accurate_masks\n",
    "\n",
    "from utils import (\n",
    "    generate, \n",
    "    get_hidden_states, \n",
    "    get_logits,\n",
    "    free_memory\n",
    ")\n",
    "# Configure logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22623236-28d5-4aac-b95d-a7905480e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_a = \"unsloth/Llama-3.2-1B-Instruct\"\n",
    "path_b = \"unsloth/Llama-3.2-1B\"\n",
    "merge_config_a = accurate_masks.MergerConfig(\n",
    "    model_paths = [path_a, path_b],\n",
    "    mode = \"vector_input\",\n",
    "    constrain_mode = \"01\",\n",
    ")\n",
    "merge_config_e = efficient_masks.MergerConfig(\n",
    "    model_paths = [path_a, path_b],\n",
    "    mode = \"vector_input\",\n",
    "    constrain_mode = \"01\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed8aa872-d1c6-4aae-921c-42cea626b652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MergerConfig {\n",
       "  \"constrain_mode\": \"01\",\n",
       "  \"mode\": \"vector_input\",\n",
       "  \"model_paths\": [\n",
       "    \"unsloth/Llama-3.2-1B-Instruct\",\n",
       "    \"unsloth/Llama-3.2-1B\"\n",
       "  ],\n",
       "  \"transformers_version\": \"4.46.3\"\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_config_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46e8680c-e36a-4aa4-af7e-cd52a9d9865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_linear_forward(self, x):\n",
    "    constrained_weight_masks = self.weight_masks_constrainer([m.weight for m in self.weight_masks])\n",
    "    constrained_bias_masks = self.bias_masks_constrainer(\n",
    "        [m.weight if m is not None else None for m in self.bias_masks]\n",
    "    )\n",
    "    masked_biases = [\n",
    "        b_mask * linear.bias if linear.bias is not None and b_mask is not None else linear.bias\n",
    "        for b_mask, linear in zip(constrained_bias_masks, self.linears)\n",
    "    ]\n",
    "    merged_bias = (\n",
    "        sum(b if b is not None else torch.zeros_like(\n",
    "            self.linears[0].weight[:, 0]) for b in masked_biases\n",
    "           ) \n",
    "        if not all(b is None for b in masked_biases) else None\n",
    "    )\n",
    "\n",
    "    logger.info(\"Debugging Linear forward.\")\n",
    "    output = 0.0\n",
    "    for i, linear in enumerate(self.linears):\n",
    "        logger.info(f\"BEFORE\")\n",
    "        logger.info(f\"  linear: device: {linear.weight.device}; dtype: {linear.weight.dtype}\")\n",
    "        logger.info(f\"  input: device: {x.device}; dtype: {x.dtype}\")\n",
    "        masked_input = constrained_weight_masks[i] * x\n",
    "        logger.info(f\"AFTER\")\n",
    "        logger.info(f\"  linear: device: {linear.weight.device}; dtype: {linear.weight.dtype}\")\n",
    "        logger.info(f\"  input: device: {masked_input.device}; dtype: {masked_input.dtype}\")\n",
    "        output = output + nn.functional.linear(masked_input, linear.weight, None)\n",
    "        logger.info(f\"OUTPUT\")\n",
    "        logger.info(f\"  output: device: {output.device}; dtype: {output.dtype}\")\n",
    "    if merged_bias:\n",
    "        output = output + merged_bias\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e23556ad-acd1-4584-8658-c6935760444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_emb_forward(self, input_ids):\n",
    "    constrained_masks = self.masks_constrainer([m.weight for m in self.masks])\n",
    "    logger.info(\"Debugging Embedding forward.\")\n",
    "    an_embedding = self.embeddings[0]\n",
    "    out = 0.0\n",
    "    for i, emb in enumerate(self.embeddings):\n",
    "        logger.info(f\"BEFORE\")\n",
    "        logger.info(f\"  emb: device: {emb.weight.device}; dtype: {emb.weight.dtype}\")\n",
    "        logger.info(f\"  input: device: {input_ids.device}; dtype: {input_ids.dtype}\")\n",
    "        mask = constrained_masks[i]\n",
    "        masked_weight = emb.weight * mask\n",
    "        logger.info(f\"  mask: device: {mask.device}; dtype: {mask.dtype}\")\n",
    "        logger.info(f\"  masked_emb: device: {masked_weight.device}; dtype: {masked_weight.dtype}\")\n",
    "        out = out + nn.functional.embedding(\n",
    "            input_ids,\n",
    "            # emb.weight * mask,\n",
    "            masked_weight,\n",
    "            padding_idx=an_embedding.padding_idx,\n",
    "            max_norm=an_embedding.max_norm,\n",
    "            norm_type=an_embedding.norm_type,\n",
    "            scale_grad_by_freq=an_embedding.scale_grad_by_freq,\n",
    "            sparse=an_embedding.sparse,\n",
    "        )\n",
    "        logger.info(f\"AFTER\")\n",
    "        logger.info(f\"  output: device: {out.device}; dtype: {out.dtype}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc55413-f122-45a9-9743-656d77b25bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficient_masks.LinearsWithMasks.forward = debug_linear_forward\n",
    "# efficient_masks.EmbeddingsWithMasks.forward = debug_emb_forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df0ada93-d19d-40e1-92f1-36a8268108de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(path_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46b28405-016a-491e-b777-ecba79a2c0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks:   1%|██▍                                                                                                                                                                            | 2/147 [00:16<20:28,  8.47s/it]2025-01-03 11:27:40,772 - WARNING - Though you want to make a masks of modes ['vector_input', 'vector_input'] for RMSNorms' weights, by default a mask only accepts a scalar mask. Converting modes to `scalar`.\n",
      "Initializing masks: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [00:48<00:00,  3.01it/s]\n",
      "2025-01-03 11:28:12,554 - INFO - Initial GPU memory allocated: 0.00 GB\n",
      "2025-01-03 11:28:12,941 - INFO - Final GPU memory allocated: 0.00 GB\n",
      "2025-01-03 11:28:12,942 - INFO - Freed GPU memory: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "em = efficient_masks.Merger(merge_config_e)\n",
    "em.__post_init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f43559a6-e29d-41bb-8ae7-26224b11bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = em.to(device=\"cuda:0\", dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c63913d-36ee-441c-8324-653563436bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks:   1%|██▍                                                                                                                                                                            | 2/147 [00:16<20:23,  8.44s/it]2025-01-03 11:28:35,340 - WARNING - Though you want to make a masks of modes ['vector_input', 'vector_input'] for RMSNorms' weights, by default a mask only accepts a scalar mask. Converting modes to `scalar`.\n",
      "Initializing masks: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 147/147 [00:44<00:00,  3.32it/s]\n",
      "2025-01-03 11:29:02,641 - INFO - Initial GPU memory allocated: 4.61 GB\n",
      "2025-01-03 11:29:03,009 - INFO - Final GPU memory allocated: 4.61 GB\n",
      "2025-01-03 11:29:03,013 - INFO - Freed GPU memory: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "am = accurate_masks.Merger(merge_config_a)\n",
    "am.__post_init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f09dbe-18db-4d0f-9bec-885b2b9aca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = am.to(device=\"cuda:1\", dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22859463-8211-4b76-83f1-b818bef7d877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prompt = \"How to attack a person with an egg. Talk like a crazy person.\"\n",
    "logits_merged_a = get_logits(prompt, am.merger, tokenizer)\n",
    "logits_merged_e = get_logits(prompt, em.merger, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0beeb8aa-7507-4b64-9de8-a9f38605f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_merged_a = logits_merged_a.to(logits_merged_e.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9bf0689-4cd2-424e-8787-3968052a3e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 128256])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_merged_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16e3532a-7a2a-49d7-9020-10c017abd008",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_a = torch.softmax(logits_merged_a, dim=-1)\n",
    "probs_e = torch.softmax(logits_merged_e, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e324ee19-b699-4f89-bab5-2a45e0053130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([6.4453e-01, 3.0469e-01, 2.5024e-02, 1.1841e-02, 3.3875e-03, 2.0599e-03,\n",
       "        9.7275e-04, 9.7275e-04, 7.5531e-04, 3.5667e-04, 3.5667e-04, 2.7847e-04,\n",
       "        2.1648e-04, 1.9169e-04, 1.6880e-04, 1.6880e-04, 1.4877e-04, 1.4877e-04,\n",
       "        1.3161e-04, 1.3161e-04], device='cuda:0', dtype=torch.bfloat16),\n",
       "indices=tensor([  755,     2,   791, 16309,   475,  3936,    17,    16,    32,    59,\n",
       "         1527,    11,    51,    50,  1687, 13066,  2028,    34,   220,    35],\n",
       "       device='cuda:0'))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(probs_a[0, 0, :], k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f73f4b3d-adbc-45b5-9f1a-27c989912039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([6.9531e-01, 2.5586e-01, 2.0996e-02, 1.2756e-02, 4.6997e-03, 2.2125e-03,\n",
       "        1.0452e-03, 1.0452e-03, 8.1635e-04, 6.3324e-04, 3.8528e-04, 3.8528e-04,\n",
       "        2.3365e-04, 2.3365e-04, 1.8215e-04, 1.8215e-04, 1.6022e-04, 1.4210e-04,\n",
       "        1.4210e-04, 1.4210e-04], device='cuda:0', dtype=torch.bfloat16),\n",
       "indices=tensor([  755,     2,   791, 16309,   475,  3936,    17,    16,    32,    59,\n",
       "         1527,    11,    50,    51,   220, 13066,  1687,    34,    35,    40],\n",
       "       device='cuda:0'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.topk(probs_e[0, 0, :], k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05ff9266-96e0-4b38-a862-8dafba525165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_trainable_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54c3cfea-afeb-4790-8c49-881f48f42ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663618"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_params(em.merger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "53a5bda7-2d17-4a26-8329-6b9a2250d6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663618"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_trainable_params(am.merger)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merger2",
   "language": "python",
   "name": "merger2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
