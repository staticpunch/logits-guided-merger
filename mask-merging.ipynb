{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "754cc9c2-a335-4612-9409-ab21f754ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "plan = \"\"\"\n",
    "1. prepare data\n",
    "2. define model\n",
    "    - model a, mask a\n",
    "    - model b, mask b\n",
    "make only masks trainable.\n",
    "make sure it has correct inference.\n",
    "3. define loss function in Trainer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c4884f-b796-4384-a2ad-177f2314c3e2",
   "metadata": {},
   "source": [
    "## prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be6baca-8a9b-4a41-8e32-01d6987ae939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "332cf659-c413-4f11-889a-79532efcdd97",
   "metadata": {},
   "source": [
    "## modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6167e22d-21c5-4027-af0b-a029c8acfe0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 04:17:21,067 - INFO - PyTorch version 2.5.1+cu121 available.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import (\n",
    "    PreTrainedModel,\n",
    "    PretrainedConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser\n",
    ")\n",
    "\n",
    "from modeling_qwen2 import (\n",
    "    Qwen2RMSNorm, \n",
    "    Qwen2RotaryEmbedding, \n",
    "    Qwen2MLP, \n",
    "    Qwen2Attention, \n",
    "    Qwen2FlashAttention2, \n",
    "    Qwen2SdpaAttention, \n",
    "    Qwen2DecoderLayer, \n",
    "    Qwen2PreTrainedModel, \n",
    "    Qwen2Model, \n",
    "    Qwen2ForCausalLM\n",
    ")\n",
    "\n",
    "from configuration_qwen2 import Qwen2Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b59dc3-83fc-4345-b4f6-5cf7665fa607",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18fd625a-64ce-4a36-b16d-1b6e61eaa5c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class MergerConfig(PretrainedConfig):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_paths: List[str] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.model_paths = model_paths\n",
    "        super().__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b8256a2-89d0-4cfa-8726-1ac197a04470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MergerConfig {\n",
       "  \"model_paths\": [\n",
       "    \"/workspace/models/Arcee-VyLinh/\",\n",
       "    \"/workspace/models/Qwen2.5-Coder-3B/\"\n",
       "  ],\n",
       "  \"transformers_version\": \"4.46.3\"\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_config = MergerConfig(\n",
    "    model_paths = [\n",
    "        \"/workspace/models/Arcee-VyLinh/\",\n",
    "        \"/workspace/models/Qwen2.5-Coder-3B/\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "merge_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc68586-edfa-465f-a1e8-513541ccac5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/workspace/models/Arcee-VyLinh/', '/workspace/models/Qwen2.5-Coder-3B/']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_config.model_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eca4d1f-96da-4126-bc64-ed531f46d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Merger(PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            config.model_paths[0]\n",
    "        )\n",
    "        \n",
    "        self.models = nn.ModuleList([\n",
    "            Qwen2ForCausalLM.from_pretrained(\n",
    "            # AutoModelForCausalLM.from_pretrained(\n",
    "                model_path,\n",
    "                # torch_dtype=torch.bfloat16,\n",
    "                # device_map={\"\":0}\n",
    "            ) for model_path in config.model_paths\n",
    "        ])\n",
    "        self.__post_init__()\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        # self.masks = torch.nn\n",
    "        pass\n",
    "        \n",
    "    def forward(self, tensor, labels=None):\n",
    "        \"\"\"\n",
    "        activations = []\n",
    "        for i in range(num_layers):\n",
    "            L1 = models[0].layers[i]\n",
    "            L2 = models[1].layers[i]\n",
    "            Lm = alpha * L1 + beta * L2\n",
    "            h1 = L1(h)\n",
    "            h2 = L2(h)\n",
    "            h = Lm(h)\n",
    "            activations.append({\n",
    "                \"1\": h1, \"2\": h2, \"merged\": copy(h)\n",
    "            })\n",
    "        \"\"\"\n",
    "\n",
    "        \"\"\"\n",
    "        - embed_tokens\n",
    "        - norm\n",
    "        - layers\n",
    "            - input_layernorm\n",
    "            - self_attn\n",
    "            - mlp\n",
    "            - post_attention_norm\n",
    "        - lm_head\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd988e00-b69f-4325-bb22-220a26ef033f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "336da23a9c3f412085476e73089dc5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7626fe82064cfd822b91b96860eb13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merger = Merger(merge_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d57ee117-eee6-4233-adfb-58e8b61cd7aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.models[0].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4912f19f-b0cc-49b1-8a2e-14006fc6f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn1 = merger.models[0].model.layers[0].self_attn\n",
    "attn2 = merger.models[1].model.layers[0].self_attn\n",
    "mlp1 = merger.models[0].model.layers[0].mlp\n",
    "mlp2 = merger.models[1].model.layers[0].mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1116d86-d228-4aed-b6ac-1098c044ea62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0159, -0.0432, -0.0080,  ...,  0.0081,  0.0096,  0.0132],\n",
       "        [-0.0330,  0.0110,  0.0085,  ...,  0.0226, -0.0082,  0.0457],\n",
       "        [-0.0092,  0.0111, -0.0134,  ...,  0.0298,  0.0113, -0.0038],\n",
       "        ...,\n",
       "        [-0.0085,  0.0601, -0.0325,  ...,  0.0525, -0.0222,  0.0403],\n",
       "        [-0.0374, -0.0325,  0.0620,  ..., -0.0206,  0.0806,  0.0376],\n",
       "        [ 0.0356,  0.0151,  0.0087,  ..., -0.0306, -0.0072,  0.0378]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn1.q_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ceff9f2-8598-4fa4-99e4-f584ec495af6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "from typing import List, Dict\n",
    "\n",
    "def merge_linear(weights: List[nn.Linear], factors: List[float]) -> nn.Linear:\n",
    "    \"\"\"\n",
    "    Merges multiple linear layers by taking a weighted average of their weights and biases.\n",
    "\n",
    "    Args:\n",
    "        weights: A list of nn.Linear layers to merge.\n",
    "        factors: A list of scaling factors corresponding to each layer in 'weights'.\n",
    "\n",
    "    Returns:\n",
    "        A new nn.Linear layer that is the weighted average of the input layers.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the number of weights and factors don't match, or if the\n",
    "                    layers have incompatible dimensions, device or dtype.\n",
    "    \"\"\"\n",
    "    if len(weights) != len(factors):\n",
    "        raise ValueError(\"The number of weights and factors must be equal.\")\n",
    "\n",
    "    # Check for compatibility, device, and dtype\n",
    "    device = weights[0].weight.device\n",
    "    dtype = weights[0].weight.dtype\n",
    "    if not all(\n",
    "        w.in_features == weights[0].in_features\n",
    "        and w.out_features == weights[0].out_features\n",
    "        and w.weight.device == device\n",
    "        and w.weight.dtype == dtype\n",
    "        for w in weights\n",
    "    ):\n",
    "        raise ValueError(\n",
    "            \"Incompatible linear layers for merging. They must have the same in_features, out_features, device, and dtype.\"\n",
    "        )\n",
    "\n",
    "    # Create a new linear layer with the same dimensions, device and dtype\n",
    "    merged_linear = nn.Linear(\n",
    "        in_features=weights[0].in_features,\n",
    "        out_features=weights[0].out_features,\n",
    "        bias=False,\n",
    "        device=device,\n",
    "        dtype=dtype\n",
    "    )\n",
    "\n",
    "    # Calculate the merged weight and bias\n",
    "    merged_weight = torch.zeros_like(weights[0].weight)\n",
    "    merged_bias = (\n",
    "        torch.zeros_like(weights[0].bias, device=device, dtype=dtype)\n",
    "        if weights[0].bias is not None\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        merged_weight += factors[i] * w.weight\n",
    "        if w.bias is not None:\n",
    "            if merged_bias is None:\n",
    "                raise ValueError(\"Cannot merge linear layers if only some have biases.\")\n",
    "            merged_bias += factors[i] * w.bias\n",
    "\n",
    "    # Assign the merged weight and bias to the new layer\n",
    "    with torch.no_grad():\n",
    "        merged_linear.weight.copy_(merged_weight)\n",
    "        if merged_bias is not None:\n",
    "            merged_linear.bias = nn.Parameter(merged_bias)\n",
    "\n",
    "    return merged_linear\n",
    "\n",
    "def merge_module_recursive(\n",
    "    target_module: nn.Module, modules_dict: Dict[str, List[nn.Module]], factors: List[float]\n",
    "):\n",
    "    \"\"\"\n",
    "    Recursively merges multiple modules by taking a weighted average of their Linear layer weights and biases.\n",
    "\n",
    "    Args:\n",
    "        target_module: The target module where the merged weights will be stored.\n",
    "        modules_dict: A dictionary where keys are module names and values are lists of modules to merge.\n",
    "        factors: A list of scaling factors corresponding to each list of modules.\n",
    "    \"\"\"\n",
    "\n",
    "    for name, module in target_module.named_modules():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if name not in modules_dict:\n",
    "                raise ValueError(\n",
    "                    f\"Missing module {name} in modules_dict. Make sure all linear layer weights are provided\"\n",
    "                )\n",
    "            merged_linear = merge_linear(modules_dict[name], factors)\n",
    "            # Find the parent module\n",
    "            parent_module_name = \".\".join(name.split(\".\")[:-1])\n",
    "            layer_name = name.split(\".\")[-1]\n",
    "\n",
    "            if parent_module_name:\n",
    "                parent_module = target_module.get_submodule(parent_module_name)\n",
    "            else:\n",
    "                parent_module = target_module\n",
    "\n",
    "            # Replace the original Linear layer with merged one\n",
    "            setattr(parent_module, layer_name, merged_linear)\n",
    "\n",
    "def merge_modules(modules: List[nn.Module], factors: List[float]) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Merges multiple modules by taking a weighted average of their Linear layer weights and biases.\n",
    "    The merged weights are stored into a deepcopy of the first module in the list.\n",
    "\n",
    "    Args:\n",
    "        modules: A list of nn.Modules to merge.\n",
    "        factors: A list of scaling factors corresponding to each module in 'modules'.\n",
    "\n",
    "    Returns:\n",
    "        A new nn.Module that is the weighted average of the input modules.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the number of modules and factors don't match.\n",
    "    \"\"\"\n",
    "    if len(modules) != len(factors):\n",
    "        raise ValueError(\"The number of modules and factors must be equal.\")\n",
    "\n",
    "    # Check device and dtype consistency across all modules\n",
    "    device = modules[0].parameters().__next__().device\n",
    "    dtype = modules[0].parameters().__next__().dtype\n",
    "    if not all(p.device == device and p.dtype == dtype for module in modules for p in module.parameters()):\n",
    "        raise ValueError(\"All modules must be on the same device and have the same dtype.\")\n",
    "\n",
    "    # Create a deep copy of the first module to store the merged weights\n",
    "    merged_module = copy.deepcopy(modules[0])\n",
    "\n",
    "    # Dictionary to hold corresponding linear layers from each module\n",
    "    modules_to_merge = {\n",
    "        name: [] for name, _ in merged_module.named_modules() if isinstance(_, nn.Linear)\n",
    "    }\n",
    "    for module in modules:\n",
    "        for name, layer in module.named_modules():\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                modules_to_merge[name].append(layer)\n",
    "\n",
    "    # Merge the modules recursively\n",
    "    merge_module_recursive(merged_module, modules_to_merge, factors)\n",
    "\n",
    "    # Ensure the merged module has the correct device and dtype\n",
    "    merged_module.to(device=device, dtype=dtype)\n",
    "\n",
    "    return merged_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47c6e197-7a64-4c61-ae4c-01ec81fc5191",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_mlp = merge_modules(modules=[mlp1, mlp2], factors=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4f12e66-a7cf-40b4-b099-95d18d57aba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mQwen2MLP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Define the computation performed at every call.\n",
       "\n",
       "Should be overridden by all subclasses.\n",
       "\n",
       ".. note::\n",
       "    Although the recipe for forward pass needs to be defined within\n",
       "    this function, one should call the :class:`Module` instance afterwards\n",
       "    instead of this since the former takes care of running the\n",
       "    registered hooks while the latter silently ignores them.\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdown_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /workspace/merge/modeling_qwen2.py\n",
       "\u001b[0;31mType:\u001b[0m      function"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Qwen2MLP.forward??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc55cde6-7362-43bc-b36e-c0fd8b6371ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_merged_mlp(x: torch.Tensor, modules: List[nn.Module], factors: List[float]) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Performs a forward pass that simulates the behavior of a merged MLP module.\n",
    "\n",
    "    Args:\n",
    "        modules: A list of MLP modules (e.g., Qwen2MLP instances).\n",
    "        factors: A list of scaling factors corresponding to each module in 'modules'.\n",
    "        x: The input tensor.\n",
    "\n",
    "    Returns:\n",
    "        The output tensor after the forward pass.\n",
    "    \"\"\"\n",
    "    factors = torch.tensor(factors).to(x.device, dtype=x.dtype).view(-1, 1, 1, 1)  # Reshape factors for broadcasting\n",
    "    gate_output = torch.stack([m.gate_proj(x) for m in modules]).mul(factors).sum(0)\n",
    "    up_output = torch.stack([m.up_proj(x) for m in modules]).mul(factors).sum(0)\n",
    "    act_output = modules[0].act_fn(gate_output)  # Assuming all modules have the same activation function\n",
    "    result = torch.stack([m.down_proj(act_output * up_output) for m in modules]).mul(factors).sum(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3986afd-841a-4795-b774-2e9758ce1c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = merged_mlp.parameters().__next__().device\n",
    "dtype = merged_mlp.parameters().__next__().dtype\n",
    "x = torch.rand(1, 4, 2048).to(device, dtype=dtype)\n",
    "o1 = merged_mlp(x)\n",
    "o2 = forward_merged_mlp(x, modules=[mlp1, mlp2], factors=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d65bd5d4-2ce1-4e0d-a655-254bc03fc74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.testing.assert_close(o1, o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "65e11c1a-3abb-43f9-81fa-8c25a0a045bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modules[0].down_proj.weight\n",
    "gate_output.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "286a1532-4644-4142-ab2b-029b4d4fefd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.3750, -0.3301, -0.0016,  ..., -0.0093, -0.2695,  0.0986],\n",
       "          [ 0.2930, -0.2949,  0.0933,  ...,  0.0483, -0.2949, -0.0649],\n",
       "          [ 0.2676, -0.3789,  0.1973,  ...,  0.0134, -0.7227,  0.1367],\n",
       "          [ 0.2715, -0.2988, -0.0547,  ..., -0.1777, -0.7695,  0.0850]]],\n",
       "        device='cuda:0', dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>),\n",
       " None,\n",
       " None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = \"cuda:0\"\n",
    "h = torch.rand(1, 4, 2048, dtype=torch.bfloat16).to(device)\n",
    "p = torch.arange(4, dtype=torch.bfloat16, device=device).unsqueeze(0)\n",
    "attn1.forward(h, position_ids=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93147db6-84be-43db-9559-dd03c4c5988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model, param_bits):\n",
    "    total_params = 0\n",
    "    trainable_params = 0\n",
    "    non_trainable_params = 0\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        num_params = param.numel()  # Get the number of elements in the parameter\n",
    "        total_params += num_params\n",
    "        if param.requires_grad:\n",
    "            trainable_params += num_params\n",
    "        else:\n",
    "            non_trainable_params += num_params\n",
    "\n",
    "    total_gigabytes = total_params * (param_bits / 8) / (1024**3)\n",
    "    memory = f\"{total_gigabytes:.2f} GB\"\n",
    "    \n",
    "    return total_params, memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a75cc9e3-c80c-4a70-9d0c-b71da5fa1cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9439744, '0.02 GB'), (67633152, '0.13 GB'))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(attn1, 16), count_parameters(mlp1, 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea59306b-6580-4484-a88a-0c39f30c8bb8",
   "metadata": {},
   "source": [
    "## attemtp 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a618695-55f3-4894-90dc-81a6de0de0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 04:17:12,970 - INFO - Comparing tokenizer at /workspace/models/Arcee-VyLinh/ with tokenizer at /workspace/models/Qwen2.5-Coder-3B/\n",
      "2024-12-12 04:17:12,974 - INFO - Tokenizer at /workspace/models/Arcee-VyLinh/ and /workspace/models/Qwen2.5-Coder-3B/ are the same based on the defined criteria\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import are_tokenizers_same\n",
    "are_tokenizers_same(\n",
    "    paths = [\n",
    "        \"/workspace/models/Arcee-VyLinh/\",\n",
    "        \"/workspace/models/Qwen2.5-Coder-3B/\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540da8fa-c078-4976-8975-5d391cecdfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergerConfig(PretrainedConfig):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_paths: List[str] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.model_paths = model_paths\n",
    "        super().__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07eacc85-1f81-4998-b97d-b19a04edddbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MergerConfig {\n",
       "  \"model_paths\": [\n",
       "    \"/workspace/models/Arcee-VyLinh/\",\n",
       "    \"/workspace/models/Qwen2.5-Coder-3B/\"\n",
       "  ],\n",
       "  \"transformers_version\": \"4.46.3\"\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_config = MergerConfig(\n",
    "    model_paths = [\n",
    "        \"/workspace/models/Arcee-VyLinh/\",\n",
    "        \"/workspace/models/Qwen2.5-Coder-3B/\"\n",
    "    ]\n",
    ")\n",
    "merge_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25550585-74ef-4ba2-9e4e-c6f203fbd053",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskConfig(PretrainedConfig):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = None,\n",
    "        value: Union[float, torch.Tensor] = None,\n",
    "        size: torch.Size = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.mode = mode\n",
    "        self.value = value\n",
    "        self.size = size\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "class Mask(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        mask_config: MaskConfig\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \"\"\"\n",
    "        now only support mode == scalar\n",
    "        \"\"\"\n",
    "        self.mode = mask_config.mode\n",
    "        if mask_config.mode == \"scalar\":\n",
    "            value = mask_config.value if mask_config.value is not None else 1\n",
    "            self.mask = nn.Parameter(torch.tensor(value))\n",
    "            \n",
    "        self.size = mask_config.size ## Full size of the mask after broadcast.\n",
    "        try:\n",
    "            self.mask * torch.rand(self.size)\n",
    "        except RuntimeError:\n",
    "            print(\"mask initialized with an incompatible shape.\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mask * x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60ceee65-d173-4e63-958a-1d7cb423b5b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskConfig {\n",
       "  \"mode\": \"scalar\",\n",
       "  \"size\": null,\n",
       "  \"transformers_version\": \"4.46.3\",\n",
       "  \"value\": 0.5\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_config = MaskConfig(mode=\"scalar\", value=0.5)\n",
    "mask_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97c1c765-7d62-4000-bbcf-34072ab1947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearWithMask(nn.Module):\n",
    "    def __init__(self, linear, mask_config: MaskConfig):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.mask_config = mask_config\n",
    "        if linear.weight.shape != mask_config.size:\n",
    "            print(\"Mask shape is not imcompatible with linear, reinitializing...\")\n",
    "        self.mask_config.size = linear.weight.shape\n",
    "        self.mask = Mask(self.mask_config)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        masked_linear = self.mask(self.linear.weight)\n",
    "        return nn.functional.linear(x, masked_linear, self.linear.bias)\n",
    "\n",
    "class LinearWithActivationMask(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return self.mask(self.linear(x))\n",
    "        pass\n",
    "\n",
    "class LinearsWithMask(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        linears: List[nn.Module], \n",
    "        modes: List[str] = [\"scalar\"], \n",
    "        values: List[float] = None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        sizes = [linear.weight.shape for linear in linears]\n",
    "        mask_configs = [MaskConfig(mode, value, size) \n",
    "                        for mode, value, size in zip(modes, values, sizes)]\n",
    "        self.masked_linears = nn.ModuleList(\n",
    "            [LinearWithMask(linear, mask_config) \n",
    "             for linear, mask_config in zip(linears, mask_configs)]\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = 0.0\n",
    "        for masked_linear in self.masked_linears:\n",
    "            output += masked_linear(x)\n",
    "        return output\n",
    "            \n",
    "def replace_linears_with_masked(module):\n",
    "    \"\"\"\n",
    "    Recursively replaces Linear layers in a module with LinearWithMask layers.\n",
    "    \n",
    "    Args:\n",
    "      module: The module in which to replace layers.\n",
    "    \"\"\"\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, nn.Linear):\n",
    "            setattr(module, name, LinearWithMask(child))\n",
    "        else:\n",
    "            replace_linears_with_masked(child)\n",
    "\n",
    "# def merge_components(linears: List):\n",
    "#     for name, child in linears[0].named_children():\n",
    "        \n",
    "\n",
    "class Merger(PreTrainedModel):\n",
    "    def __init__(self, merge_config):\n",
    "        super().__init__(merge_config)\n",
    "        \"\"\"\n",
    "        Need to check whether models are mergeable (having some sort of the same config)\n",
    "        \"\"\"\n",
    "        self.config = Qwen2Config.from_pretrained(\n",
    "            merge_config.model_paths[0]\n",
    "        )\n",
    "        self.merger = Qwen2ForCausalLM(self.config)\n",
    "        self.__post_init__(merge_config)\n",
    "        \n",
    "    def __post_init__(self, merge_config):\n",
    "        # self.masks = torch.nn\n",
    "        pass\n",
    "        \n",
    "    def forward(self, tensor, labels=None):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc42d400-1dc8-4413-96de-9b0fb0123c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = nn.Linear(4, 8, bias=False)\n",
    "w2 = nn.Linear(4, 8, bias=False)\n",
    "components = [w1, w2]\n",
    "weights_with_masks = LinearsWithMask(\n",
    "    linears=components,\n",
    "    modes=[\"scalar\" for _ in components],\n",
    "    values=[1 / len(components) for _ in components]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d06f5394-0575-46ea-8416-1fa3dcaf8743",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 4)\n",
    "h1 = w1(x)\n",
    "hm = weights_with_masks(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "47cb36ed-1095-4553-b50b-ce6e41282c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2147, -0.4412, -0.4441,  0.3078, -0.1915, -0.2417,  0.3337, -0.1679]],\n",
       "        grad_fn=<MmBackward0>),\n",
       " tensor([[-0.1911, -0.4054, -0.3442,  0.3871, -0.3083, -0.3499,  0.1266,  0.0376]],\n",
       "        grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h1, hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0bf242f4-a5ff-4eec-83ff-4d633fefc40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540bffbe1955494f8bed50cab3d70b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1 = Qwen2ForCausalLM.from_pretrained(\n",
    "    merge_config.model_paths[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "342a9f5b-bf20-42f0-8e4c-d2a04d632347",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp1 = model1.model.layers[0].mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f7f49c66-d524-48a1-b8c9-9d7402500088",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_mlp1 = replace_linears_with_masked(mlp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "df1ce0e6-286f-422e-a909-10caa0059b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2MLP(\n",
       "  (gate_proj): LinearWithMask(\n",
       "    (linear): Linear(in_features=2048, out_features=11008, bias=False)\n",
       "    (mask): Mask()\n",
       "  )\n",
       "  (up_proj): LinearWithMask(\n",
       "    (linear): Linear(in_features=2048, out_features=11008, bias=False)\n",
       "    (mask): Mask()\n",
       "  )\n",
       "  (down_proj): LinearWithMask(\n",
       "    (linear): Linear(in_features=11008, out_features=2048, bias=False)\n",
       "    (mask): Mask()\n",
       "  )\n",
       "  (act_fn): SiLU()\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b4d5091-ec85-4a42-a096-510c88fcaacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merger = Merger(merge_config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merger2",
   "language": "python",
   "name": "merger2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
