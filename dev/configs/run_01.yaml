# Model configuration
model_paths:
  - "/workspace/models/llama-3.2-3b-wizard"
  - "/workspace/models/llama-3.2-3b-math"
mode: "vector_input"
constrain_mode: "identity"

# Dataset configuration
dataset_configs:
  "/workspace/data/wizard-en-10k": 5000
  "/workspace/data/numina-20k": 5000
source_keys: [0, 1]
train_split: "train"
max_length: 3072

# Training parameters
output_dir: "/workspace/logits-guided-merger/results/run_01"
per_device_train_batch_size: 1
per_device_eval_batch_size: 8
gradient_accumulation_steps: 32
learning_rate: 5e-3
num_train_epochs: 3
save_steps: 100
eval_steps: 5000
logging_steps: 10
eval_strategy: "steps"
report_to: "none"
remove_unused_columns: false
logging_first_step: true
bf16: true
gradient_checkpointing: false