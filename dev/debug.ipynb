{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8095e2b8-7c4c-4aeb-b31e-52926bc504e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-18 09:22:15,257] [INFO] [masks.<module>:57] [PID:124456] [RANK:0] --------- ACCURATE MASKS ----------\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Model merging training implementation using PyTorch and Transformers.\n",
    "Implements custom data collation and training for merged language models.\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import (\n",
    "    Any, Callable, Dict, \n",
    "    List, NewType, Optional, \n",
    "    Tuple, Union, Mapping\n",
    ")\n",
    "from abc import ABC, abstractmethod\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from accelerate.logging import get_logger\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import safetensors\n",
    "import math\n",
    "import yaml\n",
    "import logging\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerBase,\n",
    "    PreTrainedModel,\n",
    "    PretrainedConfig,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    HfArgumentParser,\n",
    "    default_data_collator,\n",
    "    is_torch_xla_available,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from transformers.utils import CONFIG_NAME\n",
    "from transformers.pytorch_utils import is_torch_greater_or_equal_than_1_13\n",
    "\n",
    "from merger import (\n",
    "    MergerConfig,\n",
    "    Merger,\n",
    "    # NewMerger,\n",
    "    init_masks,\n",
    "    set_masks\n",
    ")\n",
    "\n",
    "from utils import (\n",
    "    generate, \n",
    "    get_hidden_states, \n",
    "    get_logits,\n",
    "    free_memory\n",
    ")\n",
    "# Configure logger\n",
    "from logging_config import configure_logging\n",
    "configure_logging()\n",
    "logger = logging.getLogger(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1061d6-ab83-4307-a6ed-1e6b7293663c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Save merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a0ca6-3ae9-4f10-a23e-c2237b82fd8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae3d99f-7632-40fe-89ee-12adf5274a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"../results/run_02b\"\n",
    "merger_config = MergerConfig.from_pretrained(\n",
    "    checkpoint_dir,\n",
    "    _configuration_file=\"merger_config.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe88eec-0c36-4479-815d-06a6f7cee11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MergerConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"constrain_mode\": \"identity\",\n",
       "  \"mode\": \"vector_input\",\n",
       "  \"model_paths\": [\n",
       "    \"/workspace/models/llama-3.2-3b-wizard\",\n",
       "    \"/workspace/models/llama-3.2-3b-math\"\n",
       "  ],\n",
       "  \"transformers_version\": \"4.46.3\"\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15df46c9-d623-4668-8147-af65e084e573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-17 12:25:51,932] [INFO] [merger.__init__:222] [PID:3073] [RANK:0] Creating merger with dummy weights ...\u001b[39m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96fb87d414e41dfbbcf520f9e0d44b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4f9550ff9644f5bed2a16a55230ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea4f671e13946288b4db8d4de0d69e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks:   1%|█▎                                                                                                                                                                            | 2/255 [00:07<15:23,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2025-01-17 12:26:01,113] [WARNING] [masks.warning_once:328] [PID:3073] [RANK:0] Though you want to make a masks of modes ['vector_input', 'vector_input'] for RMSNorms' weights, by default a mask only accepts a scalar mask. Converting modes to `scalar`.\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:27<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-17 12:26:26,128] [INFO] [merger.from_pretrained:401] [PID:3073] [RANK:0] Loaded masks from ../results/run_02b\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "merger = Merger.from_pretrained(\n",
    "    checkpoint_dir,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map={\"\":3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bd3be5e-e340-4ddb-af0b-dc53dd9b3a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merger.save_pretrained(\"./haha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d683c28-3e58-42a5-9c6d-c546866f74d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging masked modules: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:02<00:00, 122.62it/s]\n"
     ]
    }
   ],
   "source": [
    "merger.save_merged(\"./haha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c523cc92-e729-4088-8309-23c1302b76ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LlamaForCausalLM'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.models[0].__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c3bfa5-05f0-4277-a48f-58890aaf4149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"/workspace/models/llama-3.2-3b-wizard\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 128000,\n",
       "  \"eos_token_id\": 128001,\n",
       "  \"head_dim\": 128,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 3072,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 8192,\n",
       "  \"max_position_embeddings\": 131072,\n",
       "  \"mlp_bias\": false,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 24,\n",
       "  \"num_hidden_layers\": 28,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": {\n",
       "    \"factor\": 32.0,\n",
       "    \"high_freq_factor\": 4.0,\n",
       "    \"low_freq_factor\": 1.0,\n",
       "    \"original_max_position_embeddings\": 8192,\n",
       "    \"rope_type\": \"llama3\"\n",
       "  },\n",
       "  \"rope_theta\": 500000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.46.3\",\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 128256\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdae5c05-f954-49bc-9487-f1a964a265f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5078, 0.5078, 0.4883, 0.4434, 0.4922, 0.4902, 0.5039, 0.4902, 0.5117,\n",
       "        0.4707, 0.4922, 0.4824, 0.5156, 0.5234, 0.4824, 0.5078, 0.5234, 0.5312,\n",
       "        0.5195, 0.4863, 0.5039, 0.5195, 0.5078, 0.5273, 0.5156, 0.4961, 0.5117,\n",
       "        0.5273, 0.5156, 0.4863, 0.5039, 0.4746, 0.5000, 0.4902, 0.5234, 0.4863,\n",
       "        0.5000, 0.4727, 0.4883, 0.4766, 0.5156, 0.4980, 0.4707, 0.5195, 0.4922,\n",
       "        0.4980, 0.4883, 0.4922, 0.4902, 0.5000, 0.4727, 0.4941, 0.5039, 0.4961,\n",
       "        0.4785, 0.5000, 0.4512, 0.5000, 0.4883, 0.4883, 0.5078, 0.4863, 0.5078,\n",
       "        0.4863, 0.4941, 0.5078, 0.4805, 0.5156, 0.4629, 0.4746, 0.4902, 0.5234,\n",
       "        0.4883, 0.4375, 0.4844, 0.4941, 0.4707, 0.4688, 0.4961, 0.5234, 0.4961,\n",
       "        0.5078, 0.5156, 0.5273, 0.5039, 0.4609, 0.5000, 0.4785, 0.5039, 0.5078,\n",
       "        0.4902, 0.4531, 0.4980, 0.4922, 0.5117, 0.4883, 0.4766, 0.4902, 0.4824,\n",
       "        0.5039], device='cuda:2', dtype=torch.bfloat16,\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.merger.model.layers[0].mlp.up_proj.get_raw_masks()['weight_masks'][0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36144e08-47d3-48db-82c8-ba5b33981511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5078, 0.5078, 0.4883, 0.4453, 0.4941, 0.4902, 0.5039, 0.4961, 0.5117,\n",
       "        0.4707, 0.4902, 0.4824, 0.5156, 0.5234, 0.4824, 0.5039, 0.5234, 0.5312,\n",
       "        0.5234, 0.4863, 0.5039, 0.5195, 0.5078, 0.5273, 0.5156, 0.4961, 0.5117,\n",
       "        0.5234, 0.5156, 0.4863, 0.5039, 0.4746, 0.5000, 0.4922, 0.5234, 0.4863,\n",
       "        0.5000, 0.4727, 0.4883, 0.4785, 0.5156, 0.5000, 0.4707, 0.5195, 0.4922,\n",
       "        0.4980, 0.4941, 0.4922, 0.4922, 0.5000, 0.4746, 0.4941, 0.5039, 0.4961,\n",
       "        0.4766, 0.5000, 0.4551, 0.5000, 0.4883, 0.4883, 0.5078, 0.4844, 0.5078,\n",
       "        0.4863, 0.4941, 0.5078, 0.4824, 0.5156, 0.4648, 0.4746, 0.4922, 0.5234,\n",
       "        0.4922, 0.4375, 0.4844, 0.4941, 0.4727, 0.4688, 0.4961, 0.5234, 0.4961,\n",
       "        0.5078, 0.5156, 0.5273, 0.5039, 0.4629, 0.5000, 0.4805, 0.5039, 0.5078,\n",
       "        0.4922, 0.4551, 0.5000, 0.4941, 0.5117, 0.4883, 0.4766, 0.4922, 0.4922,\n",
       "        0.5039], dtype=torch.bfloat16, grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.merger.model.layers[0].mlp.up_proj.get_raw_masks()['weight_masks'][1][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb6d2f9a-8d28-439e-ac3f-062c7f3a867c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-16 14:52:14,500] [INFO] [merger.from_pretrained:315] [PID:143678] [RANK:0] >>> Merger device: {'': 0}\u001b[39m\n",
      "[2025-01-16 14:52:14,506] [INFO] [merger.__init__:207] [PID:143678] [RANK:0] Creating merger with dummy weights ...\u001b[39m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a680c13d11314a65b69504df8ba88810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ed940db9114a51872427997239fd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e93934a4664acfa8020ec115b0dbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks:   1%|█▎                                                                                                                                                                            | 2/255 [00:18<38:51,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2025-01-16 14:52:36,823] [WARNING] [masks.warning_once:328] [PID:143678] [RANK:0] Though you want to make a masks of modes ['vector_input', 'vector_input'] for RMSNorms' weights, by default a mask only accepts a scalar mask. Converting modes to `scalar`.\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:09<00:00,  3.69it/s]\n"
     ]
    }
   ],
   "source": [
    "device_map={\"\":0}\n",
    "merger = Merger.from_pretrained(\n",
    "    checkpoint_dir,\n",
    "    merge_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device_map,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba7d1f03-3b9c-4998-975a-9346e6cd7e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging masked modules: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:02<00:00, 96.46it/s]\n"
     ]
    }
   ],
   "source": [
    "merger.save_merged(\"/workspace/logits-guided-merger/results/run_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f308f4c-8843-4343-a289-b56f6843c62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/workspace/logits-guided-merger/results/run_01/tokenizer_config.json',\n",
       " '/workspace/logits-guided-merger/results/run_01/special_tokens_map.json',\n",
       " '/workspace/logits-guided-merger/results/run_01/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"/workspace/logits-guided-merger/results/run_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "246a794f-5d3e-41e5-b1b6-6cd6359dc9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"/workspace/models/llama-3.2-3b-wizard\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 128000,\n",
       "  \"eos_token_id\": 128001,\n",
       "  \"head_dim\": 128,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 3072,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 8192,\n",
       "  \"max_position_embeddings\": 131072,\n",
       "  \"mlp_bias\": false,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 24,\n",
       "  \"num_hidden_layers\": 28,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": {\n",
       "    \"factor\": 32.0,\n",
       "    \"high_freq_factor\": 4.0,\n",
       "    \"low_freq_factor\": 1.0,\n",
       "    \"original_max_position_embeddings\": 8192,\n",
       "    \"rope_type\": \"llama3\"\n",
       "  },\n",
       "  \"rope_theta\": 500000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.46.3\",\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 128256\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3a924e-bb10-4403-a55e-b9175605d6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e49ecc155342bf9ac3f419a91246ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged = AutoModelForCausalLM.from_pretrained(\n",
    "    \"hehe\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3216f4b5-d5b8-49fe-a498-e160283dc7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.llama.modeling_llama.LlamaForCausalLM"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba6f1bbd-6153-41f1-88dc-1ca09a378af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/workspace/models/llama-3.2-3b-wizard\")\n",
    "text = \"Lee Min Ho is someone I don't trust.\"\n",
    "merger_logits = get_logits(text, merger.merger, tokenizer)\n",
    "merged_logits = get_logits(text, merged, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52d6ca29-1fca-4903-9486-de0a4e6e727a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(merger_logits, merged_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d7bcb54-6698-45f4-ba87-1399da51257c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 5.0938,  7.5938, 12.3750,  ..., -5.3438, -5.3438, -5.3438],\n",
       "          [ 5.7500,  4.1562,  1.7812,  ..., -5.1875, -5.1875, -5.1875],\n",
       "          [ 5.6562,  4.6875,  4.0312,  ..., -4.3125, -4.3125, -4.3125],\n",
       "          ...,\n",
       "          [ 4.6250,  6.3438,  0.4102,  ..., -3.1719, -3.1719, -3.1719],\n",
       "          [12.2500,  7.4375,  5.3125,  ..., -3.1562, -3.1562, -3.1562],\n",
       "          [ 1.0938, -0.9844,  2.9062,  ..., -2.9688, -2.9688, -2.9688]]],\n",
       "        dtype=torch.bfloat16),\n",
       " tensor([[[ 5.0938,  7.5938, 12.3750,  ..., -5.3438, -5.3438, -5.3438],\n",
       "          [ 5.7500,  4.1562,  1.7812,  ..., -5.1875, -5.1875, -5.1875],\n",
       "          [ 5.6562,  4.6875,  4.0312,  ..., -4.3125, -4.3125, -4.3125],\n",
       "          ...,\n",
       "          [ 4.6250,  6.3438,  0.4102,  ..., -3.1719, -3.1719, -3.1719],\n",
       "          [12.2500,  7.4375,  5.3125,  ..., -3.1562, -3.1562, -3.1562],\n",
       "          [ 1.0938, -0.9844,  2.9062,  ..., -2.9688, -2.9688, -2.9688]]],\n",
       "        dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_logits, merged_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c72ec73-63c6-41c1-a986-5c36aa054a9b",
   "metadata": {},
   "source": [
    "## SLERP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "596a39f3-8982-4a47-8b48-924b9582f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file\n",
    "def load_tensors(path, signature=\"\"):\n",
    "    state_dict = {}\n",
    "    shard_paths = [f for f in os.listdir(path) if (\n",
    "        f.startswith(\"model\") and f.endswith('.safetensors')\n",
    "    )]\n",
    "    for shard_path in sorted(shard_paths, key=lambda x: int(x.split('-')[1])):\n",
    "        apath = os.path.join(path, shard_path)\n",
    "        with safe_open(apath, framework=\"pt\", device=\"cpu\") as f:\n",
    "            for key in f.keys():\n",
    "                if signature in key:\n",
    "                    state_dict[key] = f.get_tensor(key)\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ef63e67b-15d8-4ae2-b2af-9aa6f1261c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd1 = load_tensors(path=\"/workspace/models/baselines/acl-slerp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "312821f9-7ef2-493a-ad83-81dce59bc803",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd2 = load_tensors(path=\"/workspace/models/baselines/acl-slerp-custom/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "119930dd-6ba5-4fde-a058-61c38e92a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd3 = load_tensors(path=\"/workspace/logits-guided-merger/dev/test-slerp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e5ae6c09-54ec-441b-b7e2-bee1368e6d82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ok = []\n",
    "not_ok = []\n",
    "for key in list(sd1.keys()):\n",
    "    if torch.allclose(sd1[key], sd3[key], atol=1e-5, rtol=1e-5):\n",
    "        ok.append(key)\n",
    "    else:\n",
    "        not_ok.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7a4c66dc-777a-4dbe-95bf-1a2780b95702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7127)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = not_ok[1]\n",
    "torch.mean((torch.abs(sd1[k] - sd3[k]) == 0).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "000abd58-518c-441c-becc-5f8719841f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(sd1.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f29f78b0-8bf9-4bd0-aeba-b5da737f60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0111,  0.0116,  0.0130,  ..., -0.0027, -0.0189,  0.0067],\n",
       "         [ 0.0134,  0.0011,  0.0210,  ...,  0.0012,  0.0322, -0.0024],\n",
       "         [ 0.0249,  0.0200,  0.0288,  ..., -0.0013, -0.0009, -0.0074],\n",
       "         ...,\n",
       "         [-0.0071,  0.0018,  0.0047,  ..., -0.0050, -0.0019, -0.0068],\n",
       "         [-0.0071,  0.0018,  0.0047,  ..., -0.0050, -0.0019, -0.0068],\n",
       "         [-0.0071,  0.0018,  0.0047,  ..., -0.0050, -0.0019, -0.0068]],\n",
       "        dtype=torch.bfloat16),\n",
       " tensor([[ 0.0111,  0.0116,  0.0130,  ..., -0.0027, -0.0189,  0.0067],\n",
       "         [ 0.0134,  0.0011,  0.0210,  ...,  0.0012,  0.0322, -0.0024],\n",
       "         [ 0.0249,  0.0200,  0.0288,  ..., -0.0013, -0.0009, -0.0074],\n",
       "         ...,\n",
       "         [-0.0071,  0.0018,  0.0047,  ..., -0.0050, -0.0019, -0.0068],\n",
       "         [-0.0071,  0.0018,  0.0047,  ..., -0.0050, -0.0019, -0.0068],\n",
       "         [-0.0071,  0.0018,  0.0047,  ..., -0.0050, -0.0019, -0.0068]],\n",
       "        dtype=torch.bfloat16),\n",
       " tensor(0., dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd1[key], sd2[key], torch.sum(sd1[key] - sd2[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4757d13d-6779-4a27-b5e8-f71d5a219f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"/workspace/logits-guided-merger/results/run_02b\"\n",
    "merger_config = MergerConfig.from_pretrained(\n",
    "    checkpoint_dir,\n",
    "    _configuration_file=\"merger_config.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddde40a5-1f93-4911-8c14-3554109ce9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MergerConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"constrain_mode\": \"identity\",\n",
       "  \"mode\": \"vector_input\",\n",
       "  \"model_paths\": [\n",
       "    \"/workspace/models/llama-3.2-3b-wizard\",\n",
       "    \"/workspace/models/llama-3.2-3b-math\"\n",
       "  ],\n",
       "  \"transformers_version\": \"4.46.3\"\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4066f410-82dd-4213-8dfe-03493dd22556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-18 09:23:29,144] [INFO] [merger.__init__:222] [PID:124456] [RANK:0] Creating merger with dummy weights ...\u001b[39m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e9eb2044c34ed0b133971a80e40b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f31d208a3914ec08c881ad3e84088a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bd3a48c2dc43368c63af79ab542eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks:   1%|█▎                                                                                                                                                                            | 2/255 [00:07<15:21,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2025-01-18 09:23:39,224] [WARNING] [masks.warning_once:328] [PID:124456] [RANK:0] Though you want to make a masks of modes ['vector_input', 'vector_input'] for RMSNorms' weights, by default a mask only accepts a scalar mask. Converting modes to `scalar`.\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:29<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-18 09:24:01,645] [INFO] [merger.from_pretrained:401] [PID:124456] [RANK:0] Loaded masks from /workspace/logits-guided-merger/results/run_02b\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "merger = Merger.from_pretrained(\n",
    "    checkpoint_dir,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc750b74-ecdb-45ea-8a56-0fa6b2047945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight_masks': [Parameter containing:\n",
       "  tensor([0.5156, 0.5117, 0.5078,  ..., 0.4590, 0.5234, 0.4902],\n",
       "         dtype=torch.bfloat16, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0.5195, 0.5117, 0.5078,  ..., 0.4570, 0.5234, 0.4902],\n",
       "         dtype=torch.bfloat16, requires_grad=True)],\n",
       " 'bias_masks': [None, None]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.merger.lm_head.get_constrained_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9be7cd84-8094-4e46-a000-635717749a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_weight = merger.get_masks_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ffd09f9-4f91-46f6-9ba1-b02514264db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-18 09:28:02,907] [INFO] [merger.set_masks:170] [PID:124456] [RANK:0] Applying uniform masks with factors = [0.5, 0.5].\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up masks: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:00<00:00, 14356.15it/s]\n"
     ]
    }
   ],
   "source": [
    "mask_init = {\n",
    "  \"strategy\": \"uniform\",\n",
    "  \"factors\": [0.5, 0.5]\n",
    "}\n",
    "set_masks(merger, mask_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc7f3641-df73-4933-9897-4c2f18bcb640",
   "metadata": {},
   "outputs": [],
   "source": [
    "merger.load_masks(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9923388-d64a-4039-a47d-7363ab607a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# masks_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b21b1c02-2fd2-4cff-8ef2-f904218b65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_init = {\n",
    "    \"strategy\": \"spherical\",\n",
    "    \"parameters\": {\n",
    "        \"self_attn\": [0, 0.3, 0.5, 0.7, 1],\n",
    "        \"mlp\": [1, 0.7, 0.5, 0.3, 0],\n",
    "        \"default\": 0.5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5979dfde-0a0f-4c06-b234-61284fef694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "def lerp(\n",
    "    t: float, v0: Union[np.ndarray, torch.Tensor], v1: Union[np.ndarray, torch.Tensor]\n",
    ") -> Union[np.ndarray, torch.Tensor]:\n",
    "    return (1 - t) * v0 + t * v1\n",
    "\n",
    "\n",
    "def slerp(\n",
    "    t: Union[float, np.ndarray],\n",
    "    v0: Union[np.ndarray, torch.Tensor],\n",
    "    v1: Union[np.ndarray, torch.Tensor],\n",
    "    DOT_THRESHOLD: float = 0.9995,\n",
    "    eps: float = 1e-8,\n",
    "):\n",
    "    \"\"\"\n",
    "    Spherical linear interpolation\n",
    "\n",
    "    From: https://gist.github.com/dvschultz/3af50c40df002da3b751efab1daddf2c\n",
    "    Args:\n",
    "        t (float/np.ndarray): Float value between 0.0 and 1.0\n",
    "        v0 (np.ndarray): Starting vector\n",
    "        v1 (np.ndarray): Final vector\n",
    "        DOT_THRESHOLD (float): Threshold for considering the two vectors as\n",
    "                               colinear. Not recommended to alter this.\n",
    "    Returns:\n",
    "        v2 (np.ndarray): Interpolation vector between v0 and v1\n",
    "    \"\"\"\n",
    "    is_torch = False\n",
    "    if not isinstance(v0, np.ndarray):\n",
    "        is_torch = True\n",
    "        v0 = v0.detach().cpu().float().numpy()\n",
    "    if not isinstance(v1, np.ndarray):\n",
    "        is_torch = True\n",
    "        v1 = v1.detach().cpu().float().numpy()\n",
    "\n",
    "    # Copy the vectors to reuse them later\n",
    "    v0_copy = np.copy(v0)\n",
    "    v1_copy = np.copy(v1)\n",
    "\n",
    "    # Normalize the vectors to get the directions and angles\n",
    "    v0 = normalize(v0, eps)\n",
    "    v1 = normalize(v1, eps)\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "\n",
    "    # Dot product with the normalized vectors (can't use np.dot in W)\n",
    "    dot = np.sum(v0 * v1)\n",
    "\n",
    "    # If absolute value of dot product is almost 1, vectors are ~colinear, so use lerp\n",
    "    if np.abs(dot) > DOT_THRESHOLD:\n",
    "        s0, s1 = 1 - t, t\n",
    "        return s0, s1\n",
    "        # res = lerp(t, v0_copy, v1_copy)\n",
    "        # return maybe_torch(res, is_torch)\n",
    "\n",
    "    # Calculate initial angle between v0 and v1\n",
    "    theta_0 = np.arccos(dot)\n",
    "    sin_theta_0 = np.sin(theta_0)\n",
    "\n",
    "    # Angle at timestep t\n",
    "    theta_t = theta_0 * t\n",
    "    sin_theta_t = np.sin(theta_t)\n",
    "\n",
    "    # Finish the slerp algorithm\n",
    "    s0 = np.sin(theta_0 - theta_t) / sin_theta_0\n",
    "    s1 = sin_theta_t / sin_theta_0\n",
    "\n",
    "    return s0, s1\n",
    "    # res = s0 * v0_copy + s1 * v1_copy\n",
    "\n",
    "    # return maybe_torch(res, is_torch)\n",
    "\n",
    "\n",
    "def maybe_torch(v: np.ndarray, is_torch: bool):\n",
    "    if is_torch:\n",
    "        return torch.from_numpy(v)\n",
    "    return v\n",
    "\n",
    "\n",
    "def normalize(v: np.ndarray, eps: float):\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    if norm_v > eps:\n",
    "        v = v / norm_v\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd9ff492-24fb-484c-a2d2-5f6588013b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from masks import Mask, MaskConfig\n",
    "from masks import LinearsWithMasks, EmbeddingsWithMasks, RMSNormsWithMasks\n",
    "\n",
    "def odd_one_out(masked_module: nn.Module, selected_idx: int):  \n",
    "    assert selected_idx is not None and isinstance(selected_idx, int), (\n",
    "        \"Must provide valid model index. Check whether passed index is `int`\"\n",
    "    )\n",
    "    masks_modules = []\n",
    "    for name, child in masked_module.named_children():\n",
    "        if not isinstance(child, nn.ModuleList): continue\n",
    "        assert selected_idx < len(child), (\n",
    "            f\"There are only {len(child)} component models, \"\n",
    "            f\"passed model index is {selected_idx}\"\n",
    "        )\n",
    "        ## exclude sub_module that is None, aka bias_masks.\n",
    "        if all(isinstance(sub_module, Mask) for sub_module in child):\n",
    "            masks_modules.append(child)\n",
    "        \n",
    "    for masks in masks_modules:\n",
    "        for i, mask in enumerate(masks):\n",
    "            value = 1.0 if i == selected_idx else 0.0\n",
    "            with torch.no_grad():\n",
    "                mask.weight.data.fill_(value)\n",
    "\n",
    "def random_init(masked_module: nn.Module):\n",
    "    masks_modules = []\n",
    "    for name, child in masked_module.named_children():\n",
    "        if not isinstance(child, nn.ModuleList): continue\n",
    "        ## exclude sub_module that is None, aka bias_masks.\n",
    "        if all(isinstance(sub_module, Mask) for sub_module in child):\n",
    "            masks_modules.append(child)\n",
    "        \n",
    "    for masks in masks_modules:\n",
    "        for i, mask in enumerate(masks):\n",
    "            with torch.no_grad():\n",
    "                random_value = torch.rand_like(mask.weight.data)\n",
    "                mask.weight.data = random_value\n",
    "                \n",
    "def uniform_init(masked_module: nn.Module, factors: List[float]):  \n",
    "    masks_modules = []\n",
    "    for name, child in masked_module.named_children():\n",
    "        if not isinstance(child, nn.ModuleList): continue\n",
    "        assert len(factors) == len(child), (\n",
    "            f\"There are {len(child)} component models, \"\n",
    "            f\"but your passed factors have {len(factors)} values.\"\n",
    "        )\n",
    "        ## exclude sub_module that is None, aka bias_masks.\n",
    "        if all(isinstance(sub_module, Mask) for sub_module in child):\n",
    "            masks_modules.append(child)\n",
    "\n",
    "    for masks in masks_modules:\n",
    "        for factor, mask in zip(factors, masks):\n",
    "            with torch.no_grad():\n",
    "                mask.weight.data.fill_(factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e05e2f51-bcc0-49f4-97d5-fe6780cd7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_t(weight_name, parameters, num_layers):\n",
    "    \"\"\"\n",
    "    Computes the blending factor for a weight based on layer index and conditions.\n",
    "    \n",
    "    Args:\n",
    "        weight_name (str): Name of the weight.\n",
    "        parameters (dict): Mapping of conditions to blending values.\n",
    "        num_layers (int): Total number of layers in the model.\n",
    "        \n",
    "    Returns:\n",
    "        float: Computed blending value.\n",
    "    \"\"\"\n",
    "    anchors = parameters.get(\"default\")\n",
    "    if not isinstance(anchors, list):\n",
    "        anchors = [anchors]\n",
    "\n",
    "    for filter_name in parameters.keys():\n",
    "        if filter_name in weight_name:\n",
    "            anchors = parameters.get(filter_name)\n",
    "            break\n",
    "            \n",
    "    match = re.search(r\"layers\\.([^\\.]*)\\.\", weight_name)\n",
    "    if match:\n",
    "        layer_idx = int(match.group(1))\n",
    "        layer_t = layer_idx / (num_layers - 1)\n",
    "        scaled = layer_t * (len(anchors) - 1)\n",
    "        i0 = math.floor(scaled)\n",
    "        i1 = min(len(anchors) - 1, i0 + 1)\n",
    "        frac = scaled - i0\n",
    "        \n",
    "        blend_value = (1 - frac) * anchors[i0] + frac * anchors[i1]\n",
    "    else:\n",
    "        blend_value = anchors[0]\n",
    "        \n",
    "    return blend_value\n",
    "\n",
    "def assign_spherical_masks(masks, s0, s1):\n",
    "    assert len(masks) == 2, (\n",
    "        \"Spherical initialization only supports 2 models. \"\n",
    "        f\"Found {len(masks)}.\"\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        masks[0].weight.data.fill_(s0)\n",
    "        masks[1].weight.data.fill_(s1)\n",
    "        \n",
    "def spherical_init(\n",
    "    masked_module: nn.Module, \n",
    "    module_name: str,\n",
    "    parameters: Mapping = None,\n",
    "    num_layers: int  = None,\n",
    "):      \n",
    "    t = compute_t(module_name, parameters, num_layers)\n",
    "    if isinstance(masked_module, LinearsWithMasks):\n",
    "        weight_masks = masked_module.weight_masks\n",
    "        bias_masks = masked_module.bias_masks\n",
    "        v0, v1 = (x.weight.data for x in masked_module.linears)\n",
    "        s0, s1 = slerp(t, v0, v1)\n",
    "        assign_spherical_masks(weight_masks, s0, s1)\n",
    "        \n",
    "        if all(isinstance(mask, Mask) for mask in bias_masks):\n",
    "            v0, v1 = (x.bias.data for x in masked_module.linears)\n",
    "            s0, s1 = slerp(t, v0, v1)\n",
    "            assign_spherical_masks(bias_masks, s0, s1)\n",
    "        \n",
    "    elif isinstance(masked_module, EmbeddingsWithMasks):\n",
    "        masks = masked_module.masks\n",
    "        v0, v1 = (x.weight.data for x in masked_module.embeddings)\n",
    "        s0, s1 = slerp(t, v0, v1)\n",
    "        assign_spherical_masks(masks, s0, s1)\n",
    "        \n",
    "    elif isinstance(masked_module, RMSNormsWithMasks):\n",
    "        masks = masked_module.masks\n",
    "        v0, v1 = (x.weight.data for x in masked_module.rms_norms)\n",
    "        s0, s1 = slerp(t, v0, v1)\n",
    "        assign_spherical_masks(masks, s0, s1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Does not support class {type(masked_module).__name__} yet.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fef0158d-e0f3-49fe-b1e5-227bf1ac099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_masked_modules(module):\n",
    "    masked_module_names = []\n",
    "    for parent_name, parent_module in module.named_modules():\n",
    "        for name, child in parent_module.named_children():\n",
    "            full_child_name = f\"{parent_name}.{name}\" if parent_name else name\n",
    "            if (\"WithMasks\" in type(child).__name__):\n",
    "                masked_module_names.append(full_child_name)\n",
    "\n",
    "    return masked_module_names\n",
    "\n",
    "INIT_MAP = dict(\n",
    "    random=random_init,\n",
    "    odd_one_out=odd_one_out,\n",
    "    uniform=uniform_init,\n",
    "    spherical=spherical_init\n",
    ")\n",
    "\n",
    "def init_(root_module, strategy=\"random\", **kwargs):\n",
    "    init_method = INIT_MAP[strategy]\n",
    "    masked_module_names = find_masked_modules(root_module)\n",
    "    \n",
    "    for module_name in tqdm(masked_module_names, desc=\"Setting up masks\"):\n",
    "        module_names = module_name.split(\".\")\n",
    "        target_module = root_module\n",
    "        for m_name in module_names:\n",
    "            target_module = getattr(target_module, m_name)\n",
    "\n",
    "        if strategy == \"spherical\":\n",
    "            kwargs[\"module_name\"] = module_name\n",
    "            \n",
    "        init_method(target_module, **kwargs)\n",
    "\n",
    "def initialize_masks(merger, mask_init):\n",
    "    # Initialize masks based on config\n",
    "    mask_strategy = mask_init[\"strategy\"]\n",
    "    if mask_strategy == \"uniform\":\n",
    "        if not mask_init[\"factors\"]:\n",
    "            raise ValueError(\n",
    "                \"Factors must be provided for uniform strategy\"\n",
    "            )\n",
    "        logger.info(f\"Applying uniform masks with factors = {factors}.\")\n",
    "        factors = mask_init[\"factors\"]\n",
    "        init_(merger.merger, strategy=\"uniform\", factors=factors)\n",
    "        \n",
    "    elif mask_strategy == \"random\":\n",
    "        logger.info(f\"Applying random masks.\")\n",
    "        init_(merger.merger, strategy=\"random\")\n",
    "        \n",
    "    elif mask_strategy == \"spherical\":\n",
    "        logger.info(f\"Applying spherical masks.\")\n",
    "        parameters = mask_init[\"parameters\"]\n",
    "        num_layers = len(merger.merger.model.layers)\n",
    "        init_(merger.merger, strategy=\"spherical\", \n",
    "              parameters=parameters, num_layers=num_layers)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unknown mask initialization strategy: {mask_strategy}.\"\n",
    "        )\n",
    "\n",
    "# _set_masks(merger.merger, strategy=\"uniform\", factors=factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "74de52e2-bc34-4809-8538-85a4b366441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-18 13:19:04,016] [INFO] [train.initialize_masks:50] [PID:124456] [RANK:0] Applying spherical masks.\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up masks: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:24<00:00, 10.56it/s]\n"
     ]
    }
   ],
   "source": [
    "initialize_masks(merger, mask_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c66e7d3e-6fef-4682-b87a-cead1e826d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging masked modules: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:02<00:00, 96.26it/s]\n"
     ]
    }
   ],
   "source": [
    "merger.save_merged(\"./test-slerp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7aa38a75-f7cc-47f5-9ed8-ce10536cd3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up masks:   0%|                                                                                                                                                                                        | 0/255 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "module_name, target_module = _set_masks(merger.merger, strategy=\"uniform\", factors=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afccc30a-9c39-4232-b9f7-574336eb1151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lm_head',\n",
       " LinearsWithMasks(\n",
       "   (linears): ModuleList(\n",
       "     (0-1): 2 x Linear(in_features=3072, out_features=128256, bias=False)\n",
       "   )\n",
       "   (weight_masks): ModuleList(\n",
       "     (0-1): 2 x Mask(mask_mode=vector_input)\n",
       "   )\n",
       "   (weight_masks_constrainer): Constrainer(constrain_mode=identity)\n",
       "   (bias_masks): ModuleList(\n",
       "     (0-1): 2 x None\n",
       "   )\n",
       "   (bias_masks_constrainer): Constrainer(constrain_mode=identity)\n",
       " ))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_name, target_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "623d1cb2-7e70-4f05-9725-3783d918ed8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'merger.model.embed_tokens.masks.0.weight': tensor([0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.embed_tokens.masks.1.weight': tensor([0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.q_proj.weight_masks.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.q_proj.weight_masks.1.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.k_proj.weight_masks.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.k_proj.weight_masks.1.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.v_proj.weight_masks.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.v_proj.weight_masks.1.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.o_proj.weight_masks.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.o_proj.weight_masks.1.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.mlp.gate_proj.weight_masks.0.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.mlp.gate_proj.weight_masks.1.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.mlp.up_proj.weight_masks.0.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.mlp.up_proj.weight_masks.1.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.mlp.down_proj.weight_masks.0.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.mlp.down_proj.weight_masks.1.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.q_proj.weight_masks.0.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.q_proj.weight_masks.1.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.k_proj.weight_masks.0.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.k_proj.weight_masks.1.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.v_proj.weight_masks.0.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.v_proj.weight_masks.1.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.o_proj.weight_masks.0.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.o_proj.weight_masks.1.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.mlp.gate_proj.weight_masks.0.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.mlp.gate_proj.weight_masks.1.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.mlp.up_proj.weight_masks.0.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.mlp.up_proj.weight_masks.1.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.mlp.down_proj.weight_masks.0.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.mlp.down_proj.weight_masks.1.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.q_proj.weight_masks.0.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.q_proj.weight_masks.1.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.k_proj.weight_masks.0.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.k_proj.weight_masks.1.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.v_proj.weight_masks.0.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.v_proj.weight_masks.1.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.o_proj.weight_masks.0.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.o_proj.weight_masks.1.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.mlp.gate_proj.weight_masks.0.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.mlp.gate_proj.weight_masks.1.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.mlp.up_proj.weight_masks.0.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.mlp.up_proj.weight_masks.1.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.mlp.down_proj.weight_masks.0.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.mlp.down_proj.weight_masks.1.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.q_proj.weight_masks.0.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.q_proj.weight_masks.1.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.k_proj.weight_masks.0.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.k_proj.weight_masks.1.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.v_proj.weight_masks.0.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.v_proj.weight_masks.1.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.o_proj.weight_masks.0.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.o_proj.weight_masks.1.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.mlp.gate_proj.weight_masks.0.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.mlp.gate_proj.weight_masks.1.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.mlp.up_proj.weight_masks.0.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.mlp.up_proj.weight_masks.1.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.mlp.down_proj.weight_masks.0.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.mlp.down_proj.weight_masks.1.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.q_proj.weight_masks.0.weight': tensor([0.8203, 0.8203, 0.8203,  ..., 0.8203, 0.8203, 0.8203],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.q_proj.weight_masks.1.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.k_proj.weight_masks.0.weight': tensor([0.8203, 0.8203, 0.8203,  ..., 0.8203, 0.8203, 0.8203],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.k_proj.weight_masks.1.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.v_proj.weight_masks.0.weight': tensor([0.8242, 0.8242, 0.8242,  ..., 0.8242, 0.8242, 0.8242],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.v_proj.weight_masks.1.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.o_proj.weight_masks.0.weight': tensor([0.8242, 0.8242, 0.8242,  ..., 0.8242, 0.8242, 0.8242],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.o_proj.weight_masks.1.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.mlp.gate_proj.weight_masks.0.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.mlp.gate_proj.weight_masks.1.weight': tensor([0.8203, 0.8203, 0.8203,  ..., 0.8203, 0.8203, 0.8203],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.mlp.up_proj.weight_masks.0.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.mlp.up_proj.weight_masks.1.weight': tensor([0.8242, 0.8242, 0.8242,  ..., 0.8242, 0.8242, 0.8242],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.mlp.down_proj.weight_masks.0.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.mlp.down_proj.weight_masks.1.weight': tensor([0.8242, 0.8242, 0.8242,  ..., 0.8242, 0.8242, 0.8242],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.q_proj.weight_masks.0.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.q_proj.weight_masks.1.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.k_proj.weight_masks.0.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.k_proj.weight_masks.1.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.v_proj.weight_masks.0.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.v_proj.weight_masks.1.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.o_proj.weight_masks.0.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.o_proj.weight_masks.1.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.mlp.gate_proj.weight_masks.0.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.mlp.gate_proj.weight_masks.1.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.mlp.up_proj.weight_masks.0.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.mlp.up_proj.weight_masks.1.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.mlp.down_proj.weight_masks.0.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.mlp.down_proj.weight_masks.1.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.q_proj.weight_masks.0.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.q_proj.weight_masks.1.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.k_proj.weight_masks.0.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.k_proj.weight_masks.1.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.v_proj.weight_masks.0.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.v_proj.weight_masks.1.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.o_proj.weight_masks.0.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.o_proj.weight_masks.1.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.mlp.gate_proj.weight_masks.0.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.mlp.gate_proj.weight_masks.1.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.mlp.up_proj.weight_masks.0.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.mlp.up_proj.weight_masks.1.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.mlp.down_proj.weight_masks.0.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.mlp.down_proj.weight_masks.1.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.q_proj.weight_masks.0.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.q_proj.weight_masks.1.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.k_proj.weight_masks.0.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.k_proj.weight_masks.1.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.v_proj.weight_masks.0.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.v_proj.weight_masks.1.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.o_proj.weight_masks.0.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.o_proj.weight_masks.1.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.mlp.gate_proj.weight_masks.0.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.mlp.gate_proj.weight_masks.1.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.mlp.up_proj.weight_masks.0.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.mlp.up_proj.weight_masks.1.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.mlp.down_proj.weight_masks.0.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.mlp.down_proj.weight_masks.1.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.q_proj.weight_masks.0.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.q_proj.weight_masks.1.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.k_proj.weight_masks.0.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.k_proj.weight_masks.1.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.v_proj.weight_masks.0.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.v_proj.weight_masks.1.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.o_proj.weight_masks.0.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.o_proj.weight_masks.1.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.mlp.gate_proj.weight_masks.0.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.mlp.gate_proj.weight_masks.1.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.mlp.up_proj.weight_masks.0.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.mlp.up_proj.weight_masks.1.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.mlp.down_proj.weight_masks.0.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.mlp.down_proj.weight_masks.1.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.q_proj.weight_masks.0.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.q_proj.weight_masks.1.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.k_proj.weight_masks.0.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.k_proj.weight_masks.1.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.v_proj.weight_masks.0.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.v_proj.weight_masks.1.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.o_proj.weight_masks.0.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.o_proj.weight_masks.1.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.mlp.gate_proj.weight_masks.0.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.mlp.gate_proj.weight_masks.1.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.mlp.up_proj.weight_masks.0.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.mlp.up_proj.weight_masks.1.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.mlp.down_proj.weight_masks.0.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.mlp.down_proj.weight_masks.1.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.q_proj.weight_masks.0.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.q_proj.weight_masks.1.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.k_proj.weight_masks.0.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.k_proj.weight_masks.1.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.v_proj.weight_masks.0.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.v_proj.weight_masks.1.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.o_proj.weight_masks.0.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.o_proj.weight_masks.1.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.mlp.gate_proj.weight_masks.0.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.mlp.gate_proj.weight_masks.1.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.mlp.up_proj.weight_masks.0.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.mlp.up_proj.weight_masks.1.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.mlp.down_proj.weight_masks.0.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.mlp.down_proj.weight_masks.1.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.q_proj.weight_masks.0.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.q_proj.weight_masks.1.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.k_proj.weight_masks.0.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.k_proj.weight_masks.1.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.v_proj.weight_masks.0.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.v_proj.weight_masks.1.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.o_proj.weight_masks.0.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.o_proj.weight_masks.1.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.mlp.gate_proj.weight_masks.0.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.mlp.gate_proj.weight_masks.1.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.mlp.up_proj.weight_masks.0.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.mlp.up_proj.weight_masks.1.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.mlp.down_proj.weight_masks.0.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.mlp.down_proj.weight_masks.1.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.q_proj.weight_masks.0.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.q_proj.weight_masks.1.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.k_proj.weight_masks.0.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.k_proj.weight_masks.1.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.v_proj.weight_masks.0.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.v_proj.weight_masks.1.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.o_proj.weight_masks.0.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.o_proj.weight_masks.1.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.mlp.gate_proj.weight_masks.0.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.mlp.gate_proj.weight_masks.1.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.mlp.up_proj.weight_masks.0.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.mlp.up_proj.weight_masks.1.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.mlp.down_proj.weight_masks.0.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.mlp.down_proj.weight_masks.1.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.q_proj.weight_masks.0.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.q_proj.weight_masks.1.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.k_proj.weight_masks.0.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.k_proj.weight_masks.1.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.v_proj.weight_masks.0.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.v_proj.weight_masks.1.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.o_proj.weight_masks.0.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.o_proj.weight_masks.1.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.mlp.gate_proj.weight_masks.0.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.mlp.gate_proj.weight_masks.1.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.mlp.up_proj.weight_masks.0.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.mlp.up_proj.weight_masks.1.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.mlp.down_proj.weight_masks.0.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.mlp.down_proj.weight_masks.1.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.q_proj.weight_masks.0.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.q_proj.weight_masks.1.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.k_proj.weight_masks.0.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.k_proj.weight_masks.1.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.v_proj.weight_masks.0.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.v_proj.weight_masks.1.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.o_proj.weight_masks.0.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.o_proj.weight_masks.1.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.mlp.gate_proj.weight_masks.0.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.mlp.gate_proj.weight_masks.1.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.mlp.up_proj.weight_masks.0.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.mlp.up_proj.weight_masks.1.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.mlp.down_proj.weight_masks.0.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.mlp.down_proj.weight_masks.1.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.q_proj.weight_masks.0.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.q_proj.weight_masks.1.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.k_proj.weight_masks.0.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.k_proj.weight_masks.1.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.v_proj.weight_masks.0.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.v_proj.weight_masks.1.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.o_proj.weight_masks.0.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.o_proj.weight_masks.1.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.mlp.gate_proj.weight_masks.0.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.mlp.gate_proj.weight_masks.1.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.mlp.up_proj.weight_masks.0.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.mlp.up_proj.weight_masks.1.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.mlp.down_proj.weight_masks.0.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.mlp.down_proj.weight_masks.1.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.q_proj.weight_masks.0.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.q_proj.weight_masks.1.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.k_proj.weight_masks.0.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.k_proj.weight_masks.1.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.v_proj.weight_masks.0.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.v_proj.weight_masks.1.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.o_proj.weight_masks.0.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.o_proj.weight_masks.1.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.mlp.gate_proj.weight_masks.0.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.mlp.gate_proj.weight_masks.1.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.mlp.up_proj.weight_masks.0.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.mlp.up_proj.weight_masks.1.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.mlp.down_proj.weight_masks.0.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.mlp.down_proj.weight_masks.1.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.q_proj.weight_masks.0.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.q_proj.weight_masks.1.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.k_proj.weight_masks.0.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.k_proj.weight_masks.1.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.v_proj.weight_masks.0.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.v_proj.weight_masks.1.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.o_proj.weight_masks.0.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.o_proj.weight_masks.1.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.mlp.gate_proj.weight_masks.0.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.mlp.gate_proj.weight_masks.1.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.mlp.up_proj.weight_masks.0.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.mlp.up_proj.weight_masks.1.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.mlp.down_proj.weight_masks.0.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.mlp.down_proj.weight_masks.1.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.q_proj.weight_masks.0.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.q_proj.weight_masks.1.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.k_proj.weight_masks.0.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.k_proj.weight_masks.1.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.v_proj.weight_masks.0.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.v_proj.weight_masks.1.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.o_proj.weight_masks.0.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.o_proj.weight_masks.1.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.mlp.gate_proj.weight_masks.0.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.mlp.gate_proj.weight_masks.1.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.mlp.up_proj.weight_masks.0.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.mlp.up_proj.weight_masks.1.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.mlp.down_proj.weight_masks.0.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.mlp.down_proj.weight_masks.1.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.q_proj.weight_masks.0.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.q_proj.weight_masks.1.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.k_proj.weight_masks.0.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.k_proj.weight_masks.1.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.v_proj.weight_masks.0.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.v_proj.weight_masks.1.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.o_proj.weight_masks.0.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.o_proj.weight_masks.1.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.mlp.gate_proj.weight_masks.0.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.mlp.gate_proj.weight_masks.1.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.mlp.up_proj.weight_masks.0.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.mlp.up_proj.weight_masks.1.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.mlp.down_proj.weight_masks.0.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.mlp.down_proj.weight_masks.1.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.q_proj.weight_masks.0.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.q_proj.weight_masks.1.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.k_proj.weight_masks.0.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.k_proj.weight_masks.1.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.v_proj.weight_masks.0.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.v_proj.weight_masks.1.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.o_proj.weight_masks.0.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.o_proj.weight_masks.1.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.mlp.gate_proj.weight_masks.0.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.mlp.gate_proj.weight_masks.1.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.mlp.up_proj.weight_masks.0.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.mlp.up_proj.weight_masks.1.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.mlp.down_proj.weight_masks.0.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.mlp.down_proj.weight_masks.1.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.q_proj.weight_masks.0.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.q_proj.weight_masks.1.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.k_proj.weight_masks.0.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.k_proj.weight_masks.1.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.v_proj.weight_masks.0.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.v_proj.weight_masks.1.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.o_proj.weight_masks.0.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.o_proj.weight_masks.1.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.mlp.gate_proj.weight_masks.0.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.mlp.gate_proj.weight_masks.1.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.mlp.up_proj.weight_masks.0.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.mlp.up_proj.weight_masks.1.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.mlp.down_proj.weight_masks.0.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.mlp.down_proj.weight_masks.1.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.q_proj.weight_masks.0.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.q_proj.weight_masks.1.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.k_proj.weight_masks.0.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.k_proj.weight_masks.1.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.v_proj.weight_masks.0.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.v_proj.weight_masks.1.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.o_proj.weight_masks.0.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.o_proj.weight_masks.1.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.mlp.gate_proj.weight_masks.0.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.mlp.gate_proj.weight_masks.1.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.mlp.up_proj.weight_masks.0.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.mlp.up_proj.weight_masks.1.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.mlp.down_proj.weight_masks.0.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.mlp.down_proj.weight_masks.1.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.q_proj.weight_masks.0.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.q_proj.weight_masks.1.weight': tensor([0.8203, 0.8203, 0.8203,  ..., 0.8203, 0.8203, 0.8203],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.k_proj.weight_masks.0.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.k_proj.weight_masks.1.weight': tensor([0.8203, 0.8203, 0.8203,  ..., 0.8203, 0.8203, 0.8203],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.v_proj.weight_masks.0.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.v_proj.weight_masks.1.weight': tensor([0.8203, 0.8203, 0.8203,  ..., 0.8203, 0.8203, 0.8203],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.o_proj.weight_masks.0.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.o_proj.weight_masks.1.weight': tensor([0.8242, 0.8242, 0.8242,  ..., 0.8242, 0.8242, 0.8242],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.mlp.gate_proj.weight_masks.0.weight': tensor([0.8203, 0.8203, 0.8203,  ..., 0.8203, 0.8203, 0.8203],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.mlp.gate_proj.weight_masks.1.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.mlp.up_proj.weight_masks.0.weight': tensor([0.8242, 0.8242, 0.8242,  ..., 0.8242, 0.8242, 0.8242],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.mlp.up_proj.weight_masks.1.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.mlp.down_proj.weight_masks.0.weight': tensor([0.8242, 0.8242, 0.8242,  ..., 0.8242, 0.8242, 0.8242],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.mlp.down_proj.weight_masks.1.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.q_proj.weight_masks.0.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.q_proj.weight_masks.1.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.k_proj.weight_masks.0.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.k_proj.weight_masks.1.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.v_proj.weight_masks.0.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.v_proj.weight_masks.1.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.o_proj.weight_masks.0.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.o_proj.weight_masks.1.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.mlp.gate_proj.weight_masks.0.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.mlp.gate_proj.weight_masks.1.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.mlp.up_proj.weight_masks.0.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.mlp.up_proj.weight_masks.1.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.mlp.down_proj.weight_masks.0.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.mlp.down_proj.weight_masks.1.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.q_proj.weight_masks.0.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.q_proj.weight_masks.1.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.k_proj.weight_masks.0.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.k_proj.weight_masks.1.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.v_proj.weight_masks.0.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.v_proj.weight_masks.1.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.o_proj.weight_masks.0.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.o_proj.weight_masks.1.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.mlp.gate_proj.weight_masks.0.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.mlp.gate_proj.weight_masks.1.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.mlp.up_proj.weight_masks.0.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.mlp.up_proj.weight_masks.1.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.mlp.down_proj.weight_masks.0.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.mlp.down_proj.weight_masks.1.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.q_proj.weight_masks.0.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.q_proj.weight_masks.1.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.k_proj.weight_masks.0.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.k_proj.weight_masks.1.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.v_proj.weight_masks.0.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.v_proj.weight_masks.1.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.o_proj.weight_masks.0.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.o_proj.weight_masks.1.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.mlp.gate_proj.weight_masks.0.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.mlp.gate_proj.weight_masks.1.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.mlp.up_proj.weight_masks.0.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.mlp.up_proj.weight_masks.1.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.mlp.down_proj.weight_masks.0.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.mlp.down_proj.weight_masks.1.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.q_proj.weight_masks.0.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.q_proj.weight_masks.1.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.k_proj.weight_masks.0.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.k_proj.weight_masks.1.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.v_proj.weight_masks.0.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.v_proj.weight_masks.1.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.o_proj.weight_masks.0.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.o_proj.weight_masks.1.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.mlp.gate_proj.weight_masks.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.mlp.gate_proj.weight_masks.1.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.mlp.up_proj.weight_masks.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.mlp.up_proj.weight_masks.1.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.mlp.down_proj.weight_masks.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.mlp.down_proj.weight_masks.1.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.norm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.norm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.lm_head.weight_masks.0.weight': tensor([0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.lm_head.weight_masks.1.weight': tensor([0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        dtype=torch.bfloat16)}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.get_masks_state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ee6b34-c3d2-40cc-b34c-1bef4c673abe",
   "metadata": {},
   "source": [
    "## Keep testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880be051-7fd5-4f9f-8979-24ff7099d691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-19 16:50:39,144] [INFO] [masks.<module>:16] [PID:84] [RANK:0] --------- ACCURATE MASKS ----------\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Model merging training implementation using PyTorch and Transformers.\n",
    "Implements custom data collation and training for merged language models.\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import (\n",
    "    Any, Callable, Dict, \n",
    "    List, NewType, Optional, \n",
    "    Tuple, Union, Mapping\n",
    ")\n",
    "from abc import ABC, abstractmethod\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from accelerate.logging import get_logger\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import safetensors\n",
    "import math\n",
    "import yaml\n",
    "import logging\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerBase,\n",
    "    PreTrainedModel,\n",
    "    PretrainedConfig,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    HfArgumentParser,\n",
    "    default_data_collator,\n",
    "    is_torch_xla_available,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from merger import (\n",
    "    MergerConfig,\n",
    "    Merger,\n",
    ")\n",
    "from initializer import MaskInitializer\n",
    "# Configure logger\n",
    "from logging_config import configure_logging\n",
    "configure_logging()\n",
    "logger = logging.getLogger(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f15c8c2d-4b2f-4eb4-911a-2ea022749d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_init = {\n",
    "    \"strategy\": \"spherical\",\n",
    "    \"parameters\": {\n",
    "        \"self_attn\": [0, 0.3, 0.5, 0.7, 1],\n",
    "        \"mlp\": [1, 0.7, 0.5, 0.3, 0],\n",
    "        \"default\": 0.5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa07ed6-d362-4795-b97a-4e063532b927",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"/workspace/logits-guided-merger/results/run_slerp\"\n",
    "merger_config = MergerConfig.from_pretrained(\n",
    "    checkpoint_dir,\n",
    "    _configuration_file=\"merger_config.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "010608a5-f752-4a60-95c0-7a336cabbb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MergerConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"constrain_mode\": \"identity\",\n",
       "  \"mode\": \"vector_input\",\n",
       "  \"model_paths\": [\n",
       "    \"/workspace/models/llama-3.2-3b-wizard\",\n",
       "    \"/workspace/models/llama-3.2-3b-math\"\n",
       "  ],\n",
       "  \"transformers_version\": \"4.46.3\"\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8810938-0f84-424f-bc3c-c049306a3e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-19 16:55:19,638] [INFO] [merger.__init__:85] [PID:84] [RANK:0] Creating merger with dummy weights ...\u001b[39m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "defae735722a43c3aa7e6c33589d894f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db87890a9be4f42a5df2a6d2c155f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6c07f029fa40f4a28a30badbf9b184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating masks:   1%|█▍                                                                                                                                                                                | 2/255 [00:07<15:31,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2025-01-19 16:55:31,692] [WARNING] [masks.warning_once:328] [PID:84] [RANK:0] Though you want to make a masks of modes ['vector_input', 'vector_input'] for RMSNorms' weights, by default only scalar masks are acceptable. Converting modes to `scalar`.\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating masks: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:40<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-19 16:56:04,324] [INFO] [merger.from_pretrained:264] [PID:84] [RANK:0] Loaded masks from /workspace/logits-guided-merger/results/run_slerp\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "merger = Merger.from_pretrained(\n",
    "    checkpoint_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c06ba86-2f88-47ff-a384-ab69e46ffdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = MaskInitializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "41e2872f-e510-43b9-a86d-80d456b7df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Any, Dict, List, Optional, Union\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import math\n",
    "import yaml\n",
    "import re\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file\n",
    "\n",
    "def slerp(\n",
    "    t: Union[float, np.ndarray],\n",
    "    v0: Union[np.ndarray, torch.Tensor],\n",
    "    v1: Union[np.ndarray, torch.Tensor],\n",
    "    DOT_THRESHOLD: float = 0.9999,\n",
    "    eps: float = 1e-8,\n",
    "):\n",
    "    \"\"\"\n",
    "    Spherical linear interpolation\n",
    "\n",
    "    From: https://gist.github.com/dvschultz/3af50c40df002da3b751efab1daddf2c\n",
    "    Args:\n",
    "        t (float/np.ndarray): Float value between 0.0 and 1.0\n",
    "        v0 (np.ndarray): Starting vector\n",
    "        v1 (np.ndarray): Final vector\n",
    "        DOT_THRESHOLD (float): Threshold for considering the two vectors as\n",
    "                               colinear. Not recommended to alter this.\n",
    "    Returns:\n",
    "        s0, s1 (float): Interpolation factors between v0 and v1\n",
    "    \"\"\"\n",
    "    is_torch = False\n",
    "    if not isinstance(v0, np.ndarray):\n",
    "        is_torch = True\n",
    "        v0 = v0.detach().cpu().float().numpy()\n",
    "    if not isinstance(v1, np.ndarray):\n",
    "        is_torch = True\n",
    "        v1 = v1.detach().cpu().float().numpy()\n",
    "\n",
    "    # Copy the vectors to reuse them later\n",
    "    v0_copy = np.copy(v0)\n",
    "    v1_copy = np.copy(v1)\n",
    "\n",
    "    # Normalize the vectors to get the directions and angles\n",
    "    v0 = normalize(v0, eps)\n",
    "    v1 = normalize(v1, eps)\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "\n",
    "    # Dot product with the normalized vectors (can't use np.dot in W)\n",
    "    dot = np.sum(v0 * v1)\n",
    "\n",
    "    # If absolute value of dot product is almost 1, vectors are ~colinear, so use lerp\n",
    "    if np.abs(dot) > DOT_THRESHOLD:\n",
    "        s0, s1 = 1 - t, t\n",
    "        return s0, s1\n",
    "\n",
    "    # Calculate initial angle between v0 and v1\n",
    "    theta_0 = np.arccos(dot)\n",
    "    sin_theta_0 = np.sin(theta_0)\n",
    "\n",
    "    # Angle at timestep t\n",
    "    theta_t = theta_0 * t\n",
    "    sin_theta_t = np.sin(theta_t)\n",
    "\n",
    "    # Finish the slerp algorithm\n",
    "    s0 = np.sin(theta_0 - theta_t) / sin_theta_0\n",
    "    s1 = sin_theta_t / sin_theta_0\n",
    "\n",
    "    return s0, s1\n",
    "\n",
    "def maybe_torch(v: np.ndarray, is_torch: bool):\n",
    "    if is_torch:\n",
    "        return torch.from_numpy(v)\n",
    "    return v\n",
    "\n",
    "def normalize(v: np.ndarray, eps: float):\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    if norm_v > eps:\n",
    "        v = v / norm_v\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3dd9b28f-ecee-4911-af5e-91cca1e2f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug = []\n",
    "from slerp import compute_t\n",
    "from masks import LinearsWithMasks, EmbeddingsWithMasks, RMSNormsWithMasks, Mask\n",
    "\n",
    "def _spherical_init(\n",
    "    self,\n",
    "    masked_module: nn.Module,\n",
    "    module_name: str,\n",
    "    parameters: Mapping = None,\n",
    "    num_layers: int = None,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Initialize masks using spherical interpolation.\"\"\"\n",
    "    logger.info_once(\"You are playing with `SLURRRRRP`\")\n",
    "    t = compute_t(module_name, parameters, num_layers)\n",
    "    \n",
    "    if isinstance(masked_module, LinearsWithMasks):\n",
    "        weight_masks = masked_module.weight_masks\n",
    "        bias_masks = masked_module.bias_masks\n",
    "        v0, v1 = (x.weight.data for x in masked_module.linears)\n",
    "        s0, s1 = slerp(t, v0, v1)\n",
    "        self._assign_spherical_masks(weight_masks, s0, s1)\n",
    "        debug.append((module_name + \".weight_masks\", t, s0, s1))\n",
    "        \n",
    "        if all(isinstance(mask, Mask) for mask in bias_masks):\n",
    "            v0, v1 = (x.bias.data for x in masked_module.linears)\n",
    "            s0, s1 = slerp(t, v0, v1)\n",
    "            self._assign_spherical_masks(bias_masks, s0, s1)\n",
    "            debug.append((module_name + \".bias_masks\", t, s0, s1))\n",
    "        \n",
    "    elif isinstance(masked_module, EmbeddingsWithMasks):\n",
    "        masks = masked_module.masks\n",
    "        v0, v1 = (x.weight.data for x in masked_module.embeddings)\n",
    "        s0, s1 = slerp(t, v0, v1)\n",
    "        self._assign_spherical_masks(masks, s0, s1)\n",
    "        debug.append((module_name + \".masks\", t, s0, s1))\n",
    "        \n",
    "    elif isinstance(masked_module, RMSNormsWithMasks):\n",
    "        masks = masked_module.masks\n",
    "        v0, v1 = (x.weight.data for x in masked_module.rms_norms)\n",
    "        s0, s1 = slerp(t, v0, v1)\n",
    "        self._assign_spherical_masks(masks, s0, s1)\n",
    "        debug.append((module_name + \".masks\", t, s0, s1))\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Does not support class {type(masked_module).__name__} yet.\"\n",
    "        )\n",
    "initializer._spherical_init = _spherical_init.__get__(initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ae69ce3-1df4-4a13-af6b-67fda46c36bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_module(self, root_module, strategy, **kwargs):\n",
    "    \"\"\"Initialize masks for all masked modules using specified strategy.\"\"\"\n",
    "    init_method = _spherical_init\n",
    "    masked_module_names = self._find_masked_modules(root_module)\n",
    "    \n",
    "    for module_name in tqdm(masked_module_names, desc=\"Setting up masks\"):\n",
    "        target_module = self._get_target_module(root_module, module_name)\n",
    "        \n",
    "        if strategy == \"spherical\":\n",
    "            kwargs[\"module_name\"] = module_name\n",
    "            \n",
    "        init_method(initializer, target_module, **kwargs)\n",
    "        \n",
    "def slerp_init(initializer, merger, mask_init):\n",
    "    logger.info(\"Applying spherical masks.\")\n",
    "    parameters = mask_init[\"parameters\"]\n",
    "    num_layers = len(merger.merger.model.layers)\n",
    "    _init_module(\n",
    "        initializer,\n",
    "        merger.merger,\n",
    "        strategy=\"spherical\",\n",
    "        parameters=parameters,\n",
    "        num_layers=num_layers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "122a3e43-4fc6-427a-849d-e93b4825b8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-19 17:24:16,443] [INFO] [train.slerp_init:15] [PID:84] [RANK:0] Applying spherical masks.\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up masks: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:24<00:00, 10.45it/s]\n"
     ]
    }
   ],
   "source": [
    "slerp_init(initializer, merger, mask_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4b8c6cbb-7c44-48c9-9fe3-04bba64efa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sim(\n",
    "    v0: Union[np.ndarray, torch.Tensor],\n",
    "    v1: Union[np.ndarray, torch.Tensor],\n",
    "    DOT_THRESHOLD: float = 0.9995,\n",
    "    eps: float = 1e-8,\n",
    "):\n",
    "    \"\"\"\n",
    "    Spherical linear interpolation\n",
    "\n",
    "    From: https://gist.github.com/dvschultz/3af50c40df002da3b751efab1daddf2c\n",
    "    Args:\n",
    "        t (float/np.ndarray): Float value between 0.0 and 1.0\n",
    "        v0 (np.ndarray): Starting vector\n",
    "        v1 (np.ndarray): Final vector\n",
    "        DOT_THRESHOLD (float): Threshold for considering the two vectors as\n",
    "                               colinear. Not recommended to alter this.\n",
    "    Returns:\n",
    "        s0, s1 (float): Interpolation factors between v0 and v1\n",
    "    \"\"\"\n",
    "    is_torch = False\n",
    "    if not isinstance(v0, np.ndarray):\n",
    "        is_torch = True\n",
    "        v0 = v0.detach().cpu().float().numpy()\n",
    "    if not isinstance(v1, np.ndarray):\n",
    "        is_torch = True\n",
    "        v1 = v1.detach().cpu().float().numpy()\n",
    "\n",
    "    # Copy the vectors to reuse them later\n",
    "    v0_copy = np.copy(v0)\n",
    "    v1_copy = np.copy(v1)\n",
    "\n",
    "    # Normalize the vectors to get the directions and angles\n",
    "    v0 = normalize(v0, eps)\n",
    "    v1 = normalize(v1, eps)\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "\n",
    "    # Dot product with the normalized vectors (can't use np.dot in W)\n",
    "    dot = np.sum(v0 * v1)\n",
    "\n",
    "    # If absolute value of dot product is almost 1, vectors are ~colinear, so use lerp\n",
    "    dis = np.abs(dot)\n",
    "    if dis > DOT_THRESHOLD:\n",
    "        return (dis, True)\n",
    "    return (dis, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c045120c-a86f-4d7d-9fa9-55356ac71194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f26d012a6aef4b7497ccefdb632a1d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm as nb_tqdm\n",
    "sd1 = merger.models[0].state_dict()\n",
    "sd2 = merger.models[1].state_dict()\n",
    "nears = []\n",
    "fars = []\n",
    "for name, param in nb_tqdm(merger.models[0].named_parameters()):\n",
    "    dis, isnear = check_sim(\n",
    "        v0=sd1[name],\n",
    "        v1=sd2[name]\n",
    "    )\n",
    "    if isnear:\n",
    "        nears.append((name, dis))\n",
    "    else:\n",
    "        fars.append((name, dis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2b86632e-3160-4071-aebd-79b16f3d8880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model.layers.0.self_attn.v_proj.weight', 0.99926174),\n",
       " ('model.layers.0.self_attn.o_proj.weight', 0.9991531),\n",
       " ('model.layers.0.mlp.down_proj.weight', 0.99944454),\n",
       " ('model.layers.1.self_attn.v_proj.weight', 0.9992527),\n",
       " ('model.layers.1.self_attn.o_proj.weight', 0.99933434),\n",
       " ('model.layers.1.mlp.down_proj.weight', 0.99702275),\n",
       " ('model.layers.2.self_attn.v_proj.weight', 0.99908763),\n",
       " ('model.layers.2.self_attn.o_proj.weight', 0.9991588),\n",
       " ('model.layers.2.mlp.up_proj.weight', 0.9994739),\n",
       " ('model.layers.2.mlp.down_proj.weight', 0.99943),\n",
       " ('model.layers.3.self_attn.v_proj.weight', 0.9993169),\n",
       " ('model.layers.3.self_attn.o_proj.weight', 0.9993511),\n",
       " ('model.layers.3.mlp.up_proj.weight', 0.99945956),\n",
       " ('model.layers.3.mlp.down_proj.weight', 0.9994157),\n",
       " ('model.layers.4.self_attn.v_proj.weight', 0.9994289),\n",
       " ('model.layers.4.self_attn.o_proj.weight', 0.9994537),\n",
       " ('model.layers.4.mlp.up_proj.weight', 0.99944663),\n",
       " ('model.layers.4.mlp.down_proj.weight', 0.9994176),\n",
       " ('model.layers.5.self_attn.v_proj.weight', 0.9991397),\n",
       " ('model.layers.5.self_attn.o_proj.weight', 0.99927574),\n",
       " ('model.layers.5.mlp.up_proj.weight', 0.9994482),\n",
       " ('model.layers.5.mlp.down_proj.weight', 0.99942833),\n",
       " ('model.layers.6.self_attn.v_proj.weight', 0.9992574),\n",
       " ('model.layers.6.self_attn.o_proj.weight', 0.9993163),\n",
       " ('model.layers.6.mlp.up_proj.weight', 0.9994359),\n",
       " ('model.layers.6.mlp.down_proj.weight', 0.99942267),\n",
       " ('model.layers.7.self_attn.v_proj.weight', 0.99926287),\n",
       " ('model.layers.7.self_attn.o_proj.weight', 0.99936014),\n",
       " ('model.layers.7.mlp.gate_proj.weight', 0.9994795),\n",
       " ('model.layers.7.mlp.up_proj.weight', 0.9994097),\n",
       " ('model.layers.7.mlp.down_proj.weight', 0.99941504),\n",
       " ('model.layers.8.self_attn.v_proj.weight', 0.99914527),\n",
       " ('model.layers.8.self_attn.o_proj.weight', 0.99935275),\n",
       " ('model.layers.8.mlp.gate_proj.weight', 0.999453),\n",
       " ('model.layers.8.mlp.up_proj.weight', 0.999373),\n",
       " ('model.layers.8.mlp.down_proj.weight', 0.9993877),\n",
       " ('model.layers.9.self_attn.v_proj.weight', 0.99929696),\n",
       " ('model.layers.9.self_attn.o_proj.weight', 0.99939287),\n",
       " ('model.layers.9.mlp.gate_proj.weight', 0.9994279),\n",
       " ('model.layers.9.mlp.up_proj.weight', 0.99937385),\n",
       " ('model.layers.9.mlp.down_proj.weight', 0.9993897),\n",
       " ('model.layers.10.self_attn.v_proj.weight', 0.9990714),\n",
       " ('model.layers.10.self_attn.o_proj.weight', 0.9992993),\n",
       " ('model.layers.10.mlp.gate_proj.weight', 0.9993868),\n",
       " ('model.layers.10.mlp.up_proj.weight', 0.99935406),\n",
       " ('model.layers.10.mlp.down_proj.weight', 0.9993763),\n",
       " ('model.layers.11.self_attn.v_proj.weight', 0.99932355),\n",
       " ('model.layers.11.self_attn.o_proj.weight', 0.9993643),\n",
       " ('model.layers.11.mlp.gate_proj.weight', 0.99933445),\n",
       " ('model.layers.11.mlp.up_proj.weight', 0.99934393),\n",
       " ('model.layers.11.mlp.down_proj.weight', 0.99936885),\n",
       " ('model.layers.12.self_attn.v_proj.weight', 0.9991),\n",
       " ('model.layers.12.self_attn.o_proj.weight', 0.9992665),\n",
       " ('model.layers.12.mlp.gate_proj.weight', 0.9993115),\n",
       " ('model.layers.12.mlp.up_proj.weight', 0.99934596),\n",
       " ('model.layers.12.mlp.down_proj.weight', 0.99935824),\n",
       " ('model.layers.13.self_attn.v_proj.weight', 0.99914086),\n",
       " ('model.layers.13.self_attn.o_proj.weight', 0.9993152),\n",
       " ('model.layers.13.mlp.gate_proj.weight', 0.99933213),\n",
       " ('model.layers.13.mlp.up_proj.weight', 0.99935997),\n",
       " ('model.layers.13.mlp.down_proj.weight', 0.9993241),\n",
       " ('model.layers.14.self_attn.v_proj.weight', 0.99919677),\n",
       " ('model.layers.14.self_attn.o_proj.weight', 0.9993374),\n",
       " ('model.layers.14.mlp.gate_proj.weight', 0.99934477),\n",
       " ('model.layers.14.mlp.up_proj.weight', 0.9993757),\n",
       " ('model.layers.14.mlp.down_proj.weight', 0.9993545),\n",
       " ('model.layers.15.self_attn.v_proj.weight', 0.99925786),\n",
       " ('model.layers.15.self_attn.o_proj.weight', 0.9993667),\n",
       " ('model.layers.15.mlp.gate_proj.weight', 0.99941593),\n",
       " ('model.layers.15.mlp.up_proj.weight', 0.99938774),\n",
       " ('model.layers.15.mlp.down_proj.weight', 0.999378),\n",
       " ('model.layers.16.self_attn.v_proj.weight', 0.9992196),\n",
       " ('model.layers.16.self_attn.o_proj.weight', 0.9993511),\n",
       " ('model.layers.16.mlp.gate_proj.weight', 0.99944204),\n",
       " ('model.layers.16.mlp.up_proj.weight', 0.9993855),\n",
       " ('model.layers.16.mlp.down_proj.weight', 0.99935293),\n",
       " ('model.layers.17.self_attn.v_proj.weight', 0.9991782),\n",
       " ('model.layers.17.self_attn.o_proj.weight', 0.9993038),\n",
       " ('model.layers.17.mlp.gate_proj.weight', 0.99946725),\n",
       " ('model.layers.17.mlp.up_proj.weight', 0.9993973),\n",
       " ('model.layers.17.mlp.down_proj.weight', 0.9993724),\n",
       " ('model.layers.18.self_attn.v_proj.weight', 0.99929184),\n",
       " ('model.layers.18.self_attn.o_proj.weight', 0.9993125),\n",
       " ('model.layers.18.mlp.gate_proj.weight', 0.9994801),\n",
       " ('model.layers.18.mlp.up_proj.weight', 0.99941516),\n",
       " ('model.layers.18.mlp.down_proj.weight', 0.99938583),\n",
       " ('model.layers.19.self_attn.v_proj.weight', 0.99931496),\n",
       " ('model.layers.19.self_attn.o_proj.weight', 0.99937063),\n",
       " ('model.layers.19.mlp.gate_proj.weight', 0.99949574),\n",
       " ('model.layers.19.mlp.up_proj.weight', 0.9994464),\n",
       " ('model.layers.19.mlp.down_proj.weight', 0.999406),\n",
       " ('model.layers.20.self_attn.v_proj.weight', 0.99935496),\n",
       " ('model.layers.20.self_attn.o_proj.weight', 0.9993253),\n",
       " ('model.layers.20.mlp.gate_proj.weight', 0.9994985),\n",
       " ('model.layers.20.mlp.up_proj.weight', 0.99945587),\n",
       " ('model.layers.20.mlp.down_proj.weight', 0.99941593),\n",
       " ('model.layers.21.self_attn.v_proj.weight', 0.99948484),\n",
       " ('model.layers.21.self_attn.o_proj.weight', 0.99942523),\n",
       " ('model.layers.21.mlp.up_proj.weight', 0.9994575),\n",
       " ('model.layers.21.mlp.down_proj.weight', 0.9994136),\n",
       " ('model.layers.22.self_attn.v_proj.weight', 0.9994895),\n",
       " ('model.layers.22.self_attn.o_proj.weight', 0.9994451),\n",
       " ('model.layers.22.mlp.up_proj.weight', 0.9994723),\n",
       " ('model.layers.22.mlp.down_proj.weight', 0.9994391),\n",
       " ('model.layers.23.self_attn.o_proj.weight', 0.99946785),\n",
       " ('model.layers.23.mlp.up_proj.weight', 0.99948454),\n",
       " ('model.layers.23.mlp.down_proj.weight', 0.9994525),\n",
       " ('model.layers.24.mlp.up_proj.weight', 0.99949896),\n",
       " ('model.layers.24.mlp.down_proj.weight', 0.9994661),\n",
       " ('model.layers.25.mlp.down_proj.weight', 0.99944973)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0a13827f-f486-4680-a6cd-1f638bea8efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MergerConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"constrain_mode\": \"identity\",\n",
       "  \"mode\": \"vector_input\",\n",
       "  \"model_paths\": [\n",
       "    \"/workspace/models/llama-3.2-3b-wizard\",\n",
       "    \"/workspace/models/llama-3.2-3b-math\"\n",
       "  ],\n",
       "  \"transformers_version\": \"4.46.3\"\n",
       "}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b16b94ad-c6a9-4d24-b78c-359f8e93aaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 144)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fars), len(nears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2d95ad4a-3aea-4b55-a56d-54f89b828693",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_sd = merger.get_masks_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "06bf3a84-79c6-41c3-b8c4-03bc11d87c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0001, 1.0001, 1.0001,  ..., 1.0001, 1.0001, 1.0001])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_sd['merger.model.layers.10.self_attn.k_proj.weight_masks.0.weight'] \\\n",
    "+ mask_sd['merger.model.layers.10.self_attn.k_proj.weight_masks.1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "04dba985-f539-4777-a706-d94642a67440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5445, 0.5445, 0.5445,  ..., 0.5445, 0.5445, 0.5445])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_sd['merger.model.layers.12.mlp.down_proj.weight_masks.1.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "881ac19d-191f-4ef2-be83-3c37586c0c0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LlamaForCausalLM' object has no attribute 'model.embed_tokens.weight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmerger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel.embed_tokens.weight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1931\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1930\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1931\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1933\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LlamaForCausalLM' object has no attribute 'model.embed_tokens.weight'"
     ]
    }
   ],
   "source": [
    "getattr(merger.models[0], 'model.embed_tokens.weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c8bd2811-c59e-470a-81b6-4274e0d4cdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0109,  0.0117,  0.0131,  ..., -0.0028, -0.0189,  0.0069],\n",
       "        [ 0.0132,  0.0011,  0.0214,  ...,  0.0011,  0.0322, -0.0023],\n",
       "        [ 0.0254,  0.0206,  0.0287,  ..., -0.0016, -0.0009, -0.0078],\n",
       "        ...,\n",
       "        [-0.0074,  0.0023,  0.0045,  ..., -0.0047, -0.0018, -0.0067],\n",
       "        [-0.0074,  0.0023,  0.0045,  ..., -0.0047, -0.0018, -0.0067],\n",
       "        [-0.0074,  0.0023,  0.0045,  ..., -0.0047, -0.0018, -0.0067]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.models[0].state_dict()[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf46dd7e-92f2-46b2-8b84-112e2b9060aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0114,  0.0115,  0.0129,  ..., -0.0026, -0.0189,  0.0064],\n",
       "        [ 0.0136,  0.0010,  0.0208,  ...,  0.0013,  0.0325, -0.0026],\n",
       "        [ 0.0244,  0.0195,  0.0288,  ..., -0.0010, -0.0008, -0.0071],\n",
       "        ...,\n",
       "        [-0.0069,  0.0014,  0.0049,  ..., -0.0053, -0.0019, -0.0069],\n",
       "        [-0.0069,  0.0014,  0.0049,  ..., -0.0053, -0.0019, -0.0069],\n",
       "        [-0.0069,  0.0014,  0.0049,  ..., -0.0053, -0.0019, -0.0069]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.models[1].state_dict()[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3b115682-f980-4823-9aaf-ca82d58dc8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-19 17:06:40,687] [INFO] [merger.initialize:94] [PID:84] [RANK:0] Applying spherical masks.\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up masks: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:27<00:00,  9.27it/s]\n"
     ]
    }
   ],
   "source": [
    "initializer.initialize(merger, mask_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96cf9f1e-546d-41a2-8703-9092aefe2e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lerp_modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20909f77-89c1-4e1a-839a-28f38a8b1a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0minitializer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spherical_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmasked_module\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_layers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "\u001b[0;32mdef\u001b[0m \u001b[0m_spherical_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmasked_module\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_layers\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"Initialize masks using spherical interpolation.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You are playing with `SLURRRRRP`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLinearsWithMasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mweight_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_masks\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mbias_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_masks\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mv0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmasked_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinears\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslerp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_spherical_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0ms0\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlerp_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".weight_masks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbias_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mv0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmasked_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinears\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslerp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_spherical_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0ms0\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlerp_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".bias_masks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEmbeddingsWithMasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mv0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmasked_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslerp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_spherical_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0ms0\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlerp_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".masks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasked_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRMSNormsWithMasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mmasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmasked_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mv0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmasked_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrms_norms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslerp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_spherical_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0ms0\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlerp_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".masks\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34mf\"Does not support class {type(masked_module).__name__} yet.\"\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_84/2771344862.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initializer._spherical_init??"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merger2",
   "language": "python",
   "name": "merger2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
