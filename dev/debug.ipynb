{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51b2510d-fa08-4efe-aa96-e8e0be795433",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model merging training implementation using PyTorch and Transformers.\n",
    "Implements custom data collation and training for merged language models.\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import (\n",
    "    Any, Callable, Dict, \n",
    "    List, NewType, Optional, \n",
    "    Tuple, Union, Mapping\n",
    ")\n",
    "from abc import ABC, abstractmethod\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from accelerate.logging import get_logger\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import safetensors\n",
    "import math\n",
    "import yaml\n",
    "import logging\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerBase,\n",
    "    PreTrainedModel,\n",
    "    PretrainedConfig,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    HfArgumentParser,\n",
    "    default_data_collator,\n",
    "    is_torch_xla_available,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from transformers.utils import CONFIG_NAME\n",
    "from transformers.pytorch_utils import is_torch_greater_or_equal_than_1_13\n",
    "\n",
    "from merger import (\n",
    "    MergerConfig,\n",
    "    Merger,\n",
    "    # NewMerger,\n",
    "    init_masks,\n",
    "    set_masks\n",
    ")\n",
    "\n",
    "from utils import (\n",
    "    generate, \n",
    "    get_hidden_states, \n",
    "    get_logits,\n",
    "    free_memory\n",
    ")\n",
    "# Configure logger\n",
    "from logging_config import configure_logging\n",
    "configure_logging()\n",
    "logger = logging.getLogger(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76222498-9333-4ad2-84aa-2f71b7ebb961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MergerConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"constrain_mode\": \"identity\",\n",
       "  \"mode\": \"vector_input\",\n",
       "  \"model_paths\": [\n",
       "    \"/workspace/models/llama-3.2-3b-wizard\",\n",
       "    \"/workspace/models/llama-3.2-3b-math\"\n",
       "  ],\n",
       "  \"transformers_version\": \"4.46.3\"\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MergerConfig.from_pretrained(\"../results/run_03/checkpoint-702/merger_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f5c5972-b76e-41f3-bbae-0220fb78b532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from masks import LinearsWithMasks, RMSNormsWithMasks, EmbeddingsWithMasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e8917ad-2df5-495f-80eb-4ebca78b10be",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"../results/run_01/checkpoint-200/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe988e9-8244-45c9-86b8-59ff9a587e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file as safe_load_file\n",
    "masks_path = os.path.join(checkpoint_dir, \"masks.safetensors\")\n",
    "state_dict = safe_load_file(masks_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2786e78a-b707-4bc4-b8cf-ec1d87a4ed9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MergerConfig {\n",
       "  \"architectures\": [\n",
       "    \"NewMerger\"\n",
       "  ],\n",
       "  \"constrain_mode\": \"identity\",\n",
       "  \"mode\": \"vector_input\",\n",
       "  \"model_paths\": [\n",
       "    \"/workspace/models/llama-3.2-3b-wizard\",\n",
       "    \"/workspace/models/llama-3.2-3b-math\"\n",
       "  ],\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.46.3\"\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_config = MergerConfig.from_pretrained(checkpoint_dir)\n",
    "merge_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a51eca90-e9de-4dbd-8c82-ce2df9edfbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-16 13:12:34,175] [INFO] [merger.from_pretrained:311] [PID:135561] [RANK:0] >>> Merger device: {'': 0}\u001b[39m\n",
      "[2025-01-16 13:12:34,186] [INFO] [merger.__init__:205] [PID:135561] [RANK:0] Creating merger with dummy weights ...\u001b[39m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a87529851144c0a352d08ba9b8f33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d451bcce534d43ad8a1913542e062e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe1d4fda94a14fbcb3f91027aa42211e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks:   1%|█▎                                                                                                                                                                            | 2/255 [00:18<38:16,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2025-01-16 13:12:56,553] [WARNING] [masks.warning_once:328] [PID:135561] [RANK:0] Though you want to make a masks of modes ['vector_input', 'vector_input'] for RMSNorms' weights, by default a mask only accepts a scalar mask. Converting modes to `scalar`.\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:05<00:00,  3.92it/s]\n"
     ]
    }
   ],
   "source": [
    "device_map={\"\":0}\n",
    "merger = Merger.from_pretrained(\n",
    "    checkpoint_dir,\n",
    "    merge_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device_map,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc0b087b-665b-4056-b5a8-cbc0f150f809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c7ba3de-287b-4144-8f99-d4ecf4806314",
   "metadata": {},
   "outputs": [],
   "source": [
    "merger = merger.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e045376-3335-4472-824e-749241b2edd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-16 10:41:02,317] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-01-16 10:41:02,430] [INFO] [root.spawn:61] [PID:121910] [RANK:0] gcc -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c /tmp/tmpj3ei8cdl/test.c -o /tmp/tmpj3ei8cdl/test.o\u001b[39m\n",
      "[2025-01-16 10:41:02,454] [INFO] [root.spawn:61] [PID:121910] [RANK:0] gcc -pthread -B /opt/conda/compiler_compat /tmp/tmpj3ei8cdl/test.o -laio -o /tmp/tmpj3ei8cdl/a.out\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-16 10:41:03,287] [INFO] [root.spawn:61] [PID:121910] [RANK:0] gcc -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c /tmp/tmpmvz3o6s6/test.c -o /tmp/tmpmvz3o6s6/test.o\u001b[39m\n",
      "[2025-01-16 10:41:03,309] [INFO] [root.spawn:61] [PID:121910] [RANK:0] gcc -pthread -B /opt/conda/compiler_compat /tmp/tmpmvz3o6s6/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmpmvz3o6s6/a.out\u001b[39m\n",
      "[2025-01-16 10:41:03,415] [INFO] [root.spawn:61] [PID:121910] [RANK:0] gcc -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c /tmp/tmp7mw2hk4j/test.c -o /tmp/tmp7mw2hk4j/test.o\u001b[39m\n",
      "[2025-01-16 10:41:03,441] [INFO] [root.spawn:61] [PID:121910] [RANK:0] gcc -pthread -B /opt/conda/compiler_compat /tmp/tmp7mw2hk4j/test.o -laio -o /tmp/tmp7mw2hk4j/a.out\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "merger.save_pretrained(\"./hehe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22534e8a-bdb1-4a95-8dec-2cf438469f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging masked modules: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:04<00:00, 62.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-16 13:13:54,659] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-01-16 13:13:54,784] [INFO] [root.spawn:61] [PID:135561] [RANK:0] gcc -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c /tmp/tmplh1mmkt3/test.c -o /tmp/tmplh1mmkt3/test.o\u001b[39m\n",
      "[2025-01-16 13:13:54,808] [INFO] [root.spawn:61] [PID:135561] [RANK:0] gcc -pthread -B /opt/conda/compiler_compat /tmp/tmplh1mmkt3/test.o -laio -o /tmp/tmplh1mmkt3/a.out\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-16 13:13:55,856] [INFO] [root.spawn:61] [PID:135561] [RANK:0] gcc -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c /tmp/tmp108089z2/test.c -o /tmp/tmp108089z2/test.o\u001b[39m\n",
      "[2025-01-16 13:13:55,885] [INFO] [root.spawn:61] [PID:135561] [RANK:0] gcc -pthread -B /opt/conda/compiler_compat /tmp/tmp108089z2/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmp108089z2/a.out\u001b[39m\n",
      "[2025-01-16 13:13:55,994] [INFO] [root.spawn:61] [PID:135561] [RANK:0] gcc -pthread -B /opt/conda/compiler_compat -DNDEBUG -fwrapv -O2 -Wall -fPIC -O2 -isystem /opt/conda/include -fPIC -O2 -isystem /opt/conda/include -fPIC -c /tmp/tmprpnrx6w9/test.c -o /tmp/tmprpnrx6w9/test.o\u001b[39m\n",
      "[2025-01-16 13:13:56,019] [INFO] [root.spawn:61] [PID:135561] [RANK:0] gcc -pthread -B /opt/conda/compiler_compat /tmp/tmprpnrx6w9/test.o -laio -o /tmp/tmprpnrx6w9/a.out\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    }
   ],
   "source": [
    "merger.save_merged(\"./hehe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ff0c1cd-031d-47ea-a6b5-c084bfc12b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d0663d195bb4aedad22976180b51be8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "ckpt = \"./hehe\"\n",
    "config = AutoConfig.from_pretrained(ckpt)\n",
    "config.tie_word_embeddings = False\n",
    "merged = AutoModelForCausalLM.from_pretrained(\n",
    "    ckpt,\n",
    "    config=config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8913f802-2f66-44af-9ac0-38894b9929fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0106,  0.0116,  0.0130,  ..., -0.0029, -0.0182,  0.0064],\n",
       "        [ 0.0128,  0.0011,  0.0210,  ...,  0.0013,  0.0310, -0.0023],\n",
       "        [ 0.0238,  0.0200,  0.0288,  ..., -0.0014, -0.0008, -0.0072],\n",
       "        ...,\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066]],\n",
       "       dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.model.embed_tokens.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11421c5a-8349-4d9d-81f0-f9dbb554665a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0115,  0.0122,  0.0132,  ..., -0.0026, -0.0195,  0.0071],\n",
       "        [ 0.0138,  0.0011,  0.0212,  ...,  0.0012,  0.0332, -0.0026],\n",
       "        [ 0.0256,  0.0212,  0.0291,  ..., -0.0013, -0.0009, -0.0079],\n",
       "        ...,\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073]],\n",
       "       dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad409af-9522-4091-8bb9-9b5f38d50742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "333c9021-8a1a-49b4-9ce4-4bbd3dbdeb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d077be4-8d0b-4ea4-ba94-dee7ca159747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0115,  0.0122,  0.0132,  ..., -0.0026, -0.0195,  0.0071],\n",
       "        [ 0.0138,  0.0011,  0.0212,  ...,  0.0012,  0.0332, -0.0026],\n",
       "        [ 0.0256,  0.0212,  0.0291,  ..., -0.0013, -0.0009, -0.0079],\n",
       "        ...,\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.lm_head.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87603b41-dc5b-4da3-9046-f2282a63db8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SafetensorError",
     "evalue": "File does not contain tensor lm_head.weight",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSafetensorError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msafetensors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m safe_open\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m safe_open(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./hehe/model-00002-of-00002.safetensors\u001b[39m\u001b[38;5;124m\"\u001b[39m, framework\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 3\u001b[0m     lm_head \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlm_head.weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mSafetensorError\u001b[0m: File does not contain tensor lm_head.weight"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "with safe_open(\"./hehe/model-00002-of-00002.safetensors\", framework=\"pt\", device=\"cpu\") as f:\n",
    "    lm_head = f.get_tensor(\"lm_head.weight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b48996-fe38-4533-a4c8-7d1fdf147122",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lm_head' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlm_head\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lm_head' is not defined"
     ]
    }
   ],
   "source": [
    "lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "413b62ef-a41d-4ca2-8d3a-e7441121db92",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.to(device=\"cuda:0\", dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "899d52d9-d17c-4114-ba0c-a0c4e7a6faac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lm_head' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlm_head\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lm_head' is not defined"
     ]
    }
   ],
   "source": [
    "lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b66e2b0-98e4-48b8-b76a-9a8713b04f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0115,  0.0122,  0.0132,  ..., -0.0026, -0.0195,  0.0071],\n",
       "        [ 0.0138,  0.0011,  0.0212,  ...,  0.0012,  0.0332, -0.0026],\n",
       "        [ 0.0256,  0.0212,  0.0291,  ..., -0.0013, -0.0009, -0.0079],\n",
       "        ...,\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b2f2673-06c1-4e54-b204-00f7f52ab1f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0120,  0.0148, -0.0029,  ...,  0.0238, -0.0004,  0.0036],\n",
       "        [-0.0034,  0.0145, -0.0186,  ..., -0.0273, -0.0190,  0.0065],\n",
       "        [-0.0107, -0.0087,  0.0237,  ...,  0.0056, -0.0081, -0.0094],\n",
       "        ...,\n",
       "        [-0.0273,  0.0020,  0.0060,  ..., -0.0080,  0.0002, -0.0166],\n",
       "        [ 0.0193,  0.0087,  0.0069,  ...,  0.0099,  0.0134, -0.0220],\n",
       "        [-0.0126,  0.0120, -0.0019,  ..., -0.0112, -0.0142, -0.0146]],\n",
       "       dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.model.layers[0].mlp.up_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98203013-f6c1-4431-9098-471a986e8c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0106,  0.0116,  0.0130,  ..., -0.0029, -0.0182,  0.0064],\n",
       "        [ 0.0128,  0.0011,  0.0210,  ...,  0.0013,  0.0310, -0.0023],\n",
       "        [ 0.0238,  0.0200,  0.0288,  ..., -0.0014, -0.0008, -0.0072],\n",
       "        ...,\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066]],\n",
       "       dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dee823d7-b82e-4c3d-b05c-fd87e8b1c4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged.to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f4c99c7-572b-4952-8fd1-cb227a972463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "184464fd-0cc1-4791-ae61-e1d1ce72683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(merge_config.model_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f1b6c13-38c8-4d6c-93dd-93aef241368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Lee Min Ho is someone I don't trust.\"\n",
    "merger_logits = get_logits(text, merger.merger, tokenizer)\n",
    "merged_logits = get_logits(text, merged, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "673a750f-8368-4965-9248-d06046eebe00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(merger_logits, merged_logits, atol=0, rtol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e7c5c9a-397d-4bcd-b873-0acf46277129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputs(text, model, tokenizer):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_ids, output_hidden_states=True)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fc3aee8-0b27-4a83-9e92-ce10be3e4621",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Lee Min Ho is someone I don't trust.\"\n",
    "merger_outputs = get_outputs(text, merger.merger, tokenizer)\n",
    "merged_outputs = get_outputs(text, merged, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f74d2bb-9ed0-4924-9717-a793e4167d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "outhead = merger.merger.lm_head\n",
    "weight_masks = outhead.get_constrained_masks()[\"weight_masks\"]\n",
    "merged_outhead = sum((mask * linear.weight).to(\"cpu\") for mask, linear in zip(weight_masks, outhead.linears))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6fcb032-ea16-409f-bfaa-19ca7662bada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outhead.get_constrained_masks()[\"bias_masks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9b207909-21a8-4dc0-a2cc-6d2a97ac3621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0115,  0.0122,  0.0132,  ..., -0.0026, -0.0195,  0.0071],\n",
       "        [ 0.0138,  0.0011,  0.0212,  ...,  0.0012,  0.0332, -0.0026],\n",
       "        [ 0.0256,  0.0212,  0.0291,  ..., -0.0013, -0.0009, -0.0079],\n",
       "        ...,\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073]],\n",
       "       dtype=torch.bfloat16, grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_outhead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e507303a-760e-47e4-9063-8cc5738dc763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0115,  0.0122,  0.0132,  ..., -0.0026, -0.0195,  0.0071],\n",
       "        [ 0.0138,  0.0011,  0.0212,  ...,  0.0012,  0.0332, -0.0026],\n",
       "        [ 0.0256,  0.0212,  0.0291,  ..., -0.0013, -0.0009, -0.0079],\n",
       "        ...,\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073]],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.lm_head.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4011add6-9f5e-4224-a7b0-c54d4eb507ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "up_proj = merger.merger.model.layers[0].mlp.up_proj\n",
    "weight_masks = up_proj.get_constrained_masks()[\"weight_masks\"]\n",
    "up_proj_a = sum((mask * linear.weight).to(\"cpu\") for mask, linear in zip(weight_masks, up_proj.linears))\n",
    "up_proj_merged = merged.model.layers[0].mlp.up_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5e48eb9-f463-4d11-b1d7-30c09140b4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0120,  0.0148, -0.0029,  ...,  0.0238, -0.0004,  0.0036],\n",
       "         [-0.0034,  0.0145, -0.0186,  ..., -0.0273, -0.0190,  0.0065],\n",
       "         [-0.0107, -0.0087,  0.0237,  ...,  0.0056, -0.0081, -0.0094],\n",
       "         ...,\n",
       "         [-0.0273,  0.0020,  0.0060,  ..., -0.0080,  0.0002, -0.0166],\n",
       "         [ 0.0193,  0.0087,  0.0069,  ...,  0.0099,  0.0134, -0.0220],\n",
       "         [-0.0126,  0.0120, -0.0019,  ..., -0.0112, -0.0142, -0.0146]],\n",
       "        dtype=torch.bfloat16, grad_fn=<AddBackward0>),\n",
       " tensor([[-0.0120,  0.0148, -0.0029,  ...,  0.0238, -0.0004,  0.0036],\n",
       "         [-0.0034,  0.0145, -0.0186,  ..., -0.0273, -0.0190,  0.0065],\n",
       "         [-0.0107, -0.0087,  0.0237,  ...,  0.0056, -0.0081, -0.0094],\n",
       "         ...,\n",
       "         [-0.0273,  0.0020,  0.0060,  ..., -0.0080,  0.0002, -0.0166],\n",
       "         [ 0.0193,  0.0087,  0.0069,  ...,  0.0099,  0.0134, -0.0220],\n",
       "         [-0.0126,  0.0120, -0.0019,  ..., -0.0112, -0.0142, -0.0146]],\n",
       "        dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_proj_a, up_proj_merged.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "38c85be7-b974-4eb9-8f4e-da3553571af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3730, -0.4844,  0.3320,  ...,  0.5938,  1.2500,  0.9961],\n",
       "         [-1.2969, -1.4219, -4.4062,  ..., -3.0781, -2.0156,  0.8320],\n",
       "         [-1.8516, -0.3418, -0.3828,  ...,  1.4453, -2.2812, -0.0574],\n",
       "         ...,\n",
       "         [ 0.6016, -0.2266, -0.2129,  ..., -0.8672, -0.5391,  0.1826],\n",
       "         [-1.0547, -0.4297,  3.0312,  ..., -0.7539, -1.3359, -0.7773],\n",
       "         [-2.9219, -0.6211, -3.6250,  ..., -1.2812, -0.0154, -2.7500]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_outputs.hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "943b3afe-5dac-4b55-ba80-918ccc6878f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3730, -0.4844,  0.3320,  ...,  0.5938,  1.2500,  0.9961],\n",
       "         [-1.2969, -1.4219, -4.4062,  ..., -3.0781, -2.0156,  0.8320],\n",
       "         [-1.8516, -0.3418, -0.3828,  ...,  1.4453, -2.2812, -0.0574],\n",
       "         ...,\n",
       "         [ 0.6016, -0.2266, -0.2129,  ..., -0.8672, -0.5391,  0.1826],\n",
       "         [-1.0547, -0.4297,  3.0312,  ..., -0.7539, -1.3359, -0.7773],\n",
       "         [-2.9219, -0.6211, -3.6250,  ..., -1.2812, -0.0154, -2.7500]]],\n",
       "       device='cuda:1', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_outputs.hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "94154305-6732-40a8-a708-001490786439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_merged(\n",
    "    self\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute merged weights using masks and component weights, then save to directory.\n",
    "    Removes component weights and masks from the final state dict.\n",
    "    \"\"\"\n",
    "    def compute(mask, weight):\n",
    "        computed = mask * weight\n",
    "        return computed\n",
    "\n",
    "    def merge_linears(name, module):\n",
    "        merged_state = {}\n",
    "        keys_to_remove = set()\n",
    "        for i in range(len(module.linears)):\n",
    "            keys_to_remove.add(f\"{name}.linears.{i}.weight\")\n",
    "            if module.linears[i].bias is not None:\n",
    "                keys_to_remove.add(f\"{name}.linears.{i}.bias\")\n",
    "            keys_to_remove.add(f\"{name}.weight_masks.{i}.weight\")\n",
    "            if module.bias_masks[i] is not None:\n",
    "                keys_to_remove.add(f\"{name}.bias_masks.{i}.weight\")\n",
    "        \n",
    "        # Get merged weights\n",
    "        weight_masks = module.get_constrained_masks()[\"weight_masks\"]\n",
    "        merged_weight = sum(\n",
    "            compute(mask, linear.weight)\n",
    "            for mask, linear in zip(weight_masks, module.linears)\n",
    "        ).cpu().detach()\n",
    "        merged_state[f\"{name}.weight\"] = merged_weight\n",
    "        \n",
    "        # Get merged biases if they exist\n",
    "        if hasattr(module, \"bias_masks\") and module.bias_masks[0] is not None:\n",
    "            bias_masks = module.get_constrained_masks()[\"bias_masks\"]\n",
    "            merged_bias = sum(\n",
    "                compute(mask, linear.bias) if linear.bias is not None else 0\n",
    "                for mask, linear in zip(bias_masks, module.linears)\n",
    "            )\n",
    "            merged_state[f\"{name}.bias\"] = merged_bias\n",
    "        return merged_state, keys_to_remove\n",
    "\n",
    "    def merge_embeddings(name, module):\n",
    "        merged_state = {}\n",
    "        keys_to_remove = set()\n",
    "        # Remove component embeddings and their masks\n",
    "        for i in range(len(module.embeddings)):\n",
    "            keys_to_remove.add(f\"{name}.embeddings.{i}.weight\")\n",
    "            keys_to_remove.add(f\"{name}.masks.{i}.weight\")\n",
    "        \n",
    "        # Get merged weights\n",
    "        masks = module.get_constrained_masks()[\"masks\"]\n",
    "        merged_weight = sum(\n",
    "            compute(mask, emb.weight)\n",
    "            for mask, emb in zip(masks, module.embeddings)\n",
    "        ).cpu().detach()\n",
    "        merged_state[f\"{name}.weight\"] = merged_weight\n",
    "        return merged_state, keys_to_remove\n",
    "\n",
    "    def merge_rmsnorms(name, module):\n",
    "        merged_state = {}\n",
    "        keys_to_remove = set()\n",
    "        # Remove component norms and their masks\n",
    "        for i in range(len(module.rms_norms)):\n",
    "            keys_to_remove.add(f\"{name}.rms_norms.{i}.weight\")\n",
    "            keys_to_remove.add(f\"{name}.masks.{i}.weight\")\n",
    "        \n",
    "        # Get merged weights\n",
    "        masks = module.get_constrained_masks()[\"masks\"]\n",
    "        merged_weight = sum(\n",
    "            compute(mask, norm.weight)\n",
    "            for mask, norm in zip(masks, module.rms_norms)\n",
    "        ).cpu().detach()\n",
    "        merged_state[f\"{name}.weight\"] = merged_weight\n",
    "        return merged_state, keys_to_remove\n",
    "\n",
    "    # Initialization.\n",
    "    merged_state = {}\n",
    "    keys_to_remove = set()\n",
    "    masked_modules = []\n",
    "    for name, module in self.merger.named_modules():\n",
    "        if any(mask_type in type(module).__name__ for mask_type in [\n",
    "            \"LinearsWithMasks\", \"EmbeddingsWithMasks\", \"RMSNormsWithMasks\"\n",
    "        ]):\n",
    "            masked_modules.append((name, module))\n",
    "\n",
    "    # Work, bitches. Mark component and mask keys for removal\n",
    "    for name, module in tqdm(masked_modules, desc=\"Merging masked modules\"):\n",
    "        if isinstance(module, LinearsWithMasks):\n",
    "            state, keys = merge_linears(name, module)\n",
    "            if \"lm_head\" in name:\n",
    "                logger.info(f\"Dit con me may, {name}\")\n",
    "        elif isinstance(module, EmbeddingsWithMasks):\n",
    "            state, keys = merge_embeddings(name, module)\n",
    "        elif isinstance(module, RMSNormsWithMasks):\n",
    "            state, keys = merge_rmsnorms(name, module)\n",
    "        merged_state.update(state)\n",
    "        keys_to_remove = keys_to_remove | keys\n",
    "\n",
    "    # Copy over non-masked parameters\n",
    "    full_state = self.merger.state_dict()\n",
    "    keys_to_copy = set()\n",
    "    \n",
    "    for key, value in full_state.items():\n",
    "        if any(remove_key in key for remove_key in keys_to_remove): continue\n",
    "        if any(mask_key in key for mask_key in [\n",
    "            \"masks\", \"linears.\", \"embeddings.\", \"rms_norms.\"\n",
    "        ]): continue\n",
    "        keys_to_copy.add(key)\n",
    "\n",
    "    if len(keys_to_copy) > 0:\n",
    "        for key in tqdm(keys_to_copy, desc=\"Copying non-masked parameters\"):\n",
    "            merged_state[key] = full_state[key].to(\"cpu\")\n",
    "\n",
    "    \n",
    "    # merged_model = AutoModelForCausalLM.from_pretrained(\n",
    "    #     self.merger_config.model_paths[0],\n",
    "    #     torch_dtype=self.merger.dtype,\n",
    "    #     device_map=\"cpu\"\n",
    "    # )\n",
    "    # merged_model.load_state_dict(merged_state)\n",
    "    # merged_model.save_pretrained(\"./lala\")\n",
    "    return merged_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ebd463bb-f6ba-42d6-bf19-982fb4edad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.tie_weights = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "520c371e-1975-4711-ba25-33a06e5e8e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.tie_word_embeddings = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "404ca45d-9a04-4a54-ab54-2e44bdbedb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ea4c20096cd4b51b9ed5136024bb9a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging masked modules:   0%|          | 0/255 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-16 12:17:35,357] [INFO] [train.save_merged:90] [PID:126987] [RANK:0] Dit con me may, lm_head\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "merged_state = save_merged(merger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "fa9296a7-9058-4184-9de0-638912e29607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0106,  0.0116,  0.0130,  ..., -0.0029, -0.0182,  0.0064],\n",
       "        [ 0.0128,  0.0011,  0.0210,  ...,  0.0013,  0.0310, -0.0023],\n",
       "        [ 0.0238,  0.0200,  0.0288,  ..., -0.0014, -0.0008, -0.0072],\n",
       "        ...,\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_state[\"model.embed_tokens.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "3ee5f6e8-6743-4d9e-93c7-1cc5a661e699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0115,  0.0122,  0.0132,  ..., -0.0026, -0.0195,  0.0071],\n",
       "        [ 0.0138,  0.0011,  0.0212,  ...,  0.0012,  0.0332, -0.0026],\n",
       "        [ 0.0256,  0.0212,  0.0291,  ..., -0.0013, -0.0009, -0.0079],\n",
       "        ...,\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_state[\"lm_head.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4d6667b8-4243-4008-803e-b9efba9051b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(merged_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "e324f29a-aa5d-43c3-959d-e02263c8d136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_state[\"lm_head.weight\"] == merged_state[\"model.embed_tokens.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "8789175c-0560-4359-84f1-6746b9f23437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0106,  0.0116,  0.0130,  ..., -0.0029, -0.0182,  0.0064],\n",
       "        [ 0.0128,  0.0011,  0.0210,  ...,  0.0013,  0.0310, -0.0023],\n",
       "        [ 0.0238,  0.0200,  0.0288,  ..., -0.0014, -0.0008, -0.0072],\n",
       "        ...,\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_state[\"model.embed_tokens.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "20353388-f55b-4503-90fe-7f9a19cb34f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embed_tokens.weight.data_ptr() ==  model.lm_head.weight.data_ptr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "320eb856-ee15-4453-a7b5-2eb5750a7627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c221587f104f33a48bbc470c68f68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LlamaForCausalLM were not initialized from the model checkpoint at /workspace/models/llama-3.2-3b-wizard/ and are newly initialized: ['lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ckpt = \"/workspace/models/llama-3.2-3b-wizard/\"\n",
    "config = AutoConfig.from_pretrained(ckpt)\n",
    "config.tie_word_embeddings = False\n",
    "mm = AutoModelForCausalLM.from_pretrained(ckpt, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "679f4945-4815-47f1-aa0a-a7c8158d4a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.load_state_dict(merged_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0a15c8ec-e9c8-4530-9feb-ddc7948103bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.model.embed_tokens.weight.data_ptr() ==  mm.lm_head.weight.data_ptr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b7c9eb48-5d3c-4ab7-9066-cb90607987c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0106,  0.0116,  0.0130,  ..., -0.0029, -0.0182,  0.0064],\n",
       "        [ 0.0128,  0.0011,  0.0210,  ...,  0.0013,  0.0310, -0.0023],\n",
       "        [ 0.0238,  0.0200,  0.0288,  ..., -0.0014, -0.0008, -0.0072],\n",
       "        ...,\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.model.embed_tokens.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "ee3003b1-36ff-4a8d-9a59-c2ee69647236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0115,  0.0122,  0.0132,  ..., -0.0026, -0.0195,  0.0071],\n",
       "        [ 0.0138,  0.0011,  0.0212,  ...,  0.0012,  0.0332, -0.0026],\n",
       "        [ 0.0256,  0.0212,  0.0291,  ..., -0.0013, -0.0009, -0.0079],\n",
       "        ...,\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm.lm_head.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "fb74e751-7846-4ed0-8334-2e335e878da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = mm.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c62979ee-5b61-44d1-942b-4a17687dad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Lee Min Ho is someone I don't trust.\"\n",
    "merger_logits = get_logits(text, merger.merger, tokenizer)\n",
    "merged_logits = get_logits(text, mm, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "004e3aed-6313-462e-9668-724e54b28949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 5.0938,  7.5938, 12.3125,  ..., -5.3125, -5.3125, -5.3125],\n",
       "          [ 5.6875,  4.1562,  1.7500,  ..., -5.1875, -5.1875, -5.1875],\n",
       "          [ 5.6875,  4.6875,  4.0625,  ..., -4.3125, -4.3125, -4.3125],\n",
       "          ...,\n",
       "          [ 4.6250,  6.3438,  0.4199,  ..., -3.1562, -3.1562, -3.1562],\n",
       "          [12.2500,  7.4375,  5.3438,  ..., -3.1406, -3.1406, -3.1406],\n",
       "          [ 1.1328, -0.9492,  2.9375,  ..., -2.9375, -2.9219, -2.9219]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[ 5.0938,  7.5938, 12.3125,  ..., -5.3125, -5.3125, -5.3125],\n",
       "          [ 5.6875,  4.1562,  1.7500,  ..., -5.1875, -5.1875, -5.1875],\n",
       "          [ 5.6875,  4.6875,  4.0625,  ..., -4.3125, -4.3125, -4.3125],\n",
       "          ...,\n",
       "          [ 4.6250,  6.3438,  0.4199,  ..., -3.1562, -3.1562, -3.1562],\n",
       "          [12.2500,  7.4375,  5.3438,  ..., -3.1406, -3.1406, -3.1406],\n",
       "          [ 1.1328, -0.9492,  2.9375,  ..., -2.9375, -2.9219, -2.9219]]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_logits, merged_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346e0f3b-e7f2-4e05-bbb2-67361701110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm.load_state_dict(merged_state, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd476fb-0ba9-443d-896c-3a2e0af0015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_input_embeddings().weight.data_ptr() == model.lm_head.weight.data_ptr()) # Should print False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "49c6588d-e3fe-461d-8d4b-9fd8fcd1e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    param.data = merged_state[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5143149a-9362-48e8-a112-9e45413aecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73db0dc6-fb11-4bdc-aca5-f71f0446bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = [merger.merger.lm_head.weight_masks[i].weight.data for i in range(2)]\n",
    "weights = [merger.merger.lm_head.linears[i].weight.data for i in range(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f795a3d2-004c-4cad-8f76-29bcd239e659",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0115,  0.0122,  0.0132,  ..., -0.0026, -0.0195,  0.0071],\n",
       "        [ 0.0138,  0.0011,  0.0212,  ...,  0.0012,  0.0332, -0.0026],\n",
       "        [ 0.0256,  0.0212,  0.0291,  ..., -0.0013, -0.0009, -0.0079],\n",
       "        ...,\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073]],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(mask * weight for mask, weight in zip(masks, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ef5cd3de-2d26-42b0-b277-e3dc6e408155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0adca7cb4c446da343a96a891d77a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"/workspace/models/llama-3.2-3b-wizard/\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35df7b64-3f43-4e46-8a9a-f6496ea22aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(merged_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e789d4bc-4daf-46a9-95b6-779bf21a91bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e64ffd9f-bd00-42cc-93c9-f278f593840b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0447, -0.0486,  0.3223,  ..., -0.1196, -0.1187, -0.1196],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<SqueezeBackward4>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand(3072, device=\"cuda:0\", dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "72100c1c-759b-4bd3-b3e4-489d5dee8ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingsWithMasks(\n",
       "  (embeddings): ModuleList(\n",
       "    (0-1): 2 x Embedding(128256, 3072)\n",
       "  )\n",
       "  (masks): ModuleList(\n",
       "    (0-1): 2 x Mask(mask_mode=vector_input)\n",
       "  )\n",
       "  (masks_constrainer): Constrainer(constrain_mode=identity)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.merger.model.embed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae8035ba-0111-4776-9ae5-5d6a7a557b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin = nn.Linear(in_features=3072, out_features=128256, bias=False)\n",
    "lin.weight.data = merged_state[\"lm_head.weight\"].to(device=\"cuda:0\", dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e70ad0fa-6151-445d-bc7b-543272f95fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hihi haha hoho\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6c04aa0a-3568-46f2-b60b-81b3e49d88be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in merged_state.items():\n",
    "    merged_state[k] = merged_state[k].detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "740f70af-2602-487a-a21f-b5ec30749838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0115,  0.0122,  0.0132,  ..., -0.0026, -0.0195,  0.0071],\n",
       "        [ 0.0138,  0.0011,  0.0212,  ...,  0.0012,  0.0332, -0.0026],\n",
       "        [ 0.0256,  0.0212,  0.0291,  ..., -0.0013, -0.0009, -0.0079],\n",
       "        ...,\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_state[\"lm_head.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "9df7f257-a9cd-4b6f-84cc-55365ebd14a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0106,  0.0116,  0.0130,  ..., -0.0029, -0.0182,  0.0064],\n",
       "        [ 0.0128,  0.0011,  0.0210,  ...,  0.0013,  0.0310, -0.0023],\n",
       "        [ 0.0238,  0.0200,  0.0288,  ..., -0.0014, -0.0008, -0.0072],\n",
       "        ...,\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_state[\"model.embed_tokens.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "43b9234f-0502-4637-ab0e-e47da639ea8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0115,  0.0122,  0.0132,  ..., -0.0026, -0.0195,  0.0071],\n",
       "        [ 0.0138,  0.0011,  0.0212,  ...,  0.0012,  0.0332, -0.0026],\n",
       "        [ 0.0256,  0.0212,  0.0291,  ..., -0.0013, -0.0009, -0.0079],\n",
       "        ...,\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embed_tokens.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "518072d1-96da-43fe-b301-f15440aee520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7112c48969ce49e4b13a41974fd0cfbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"/workspace/models/llama-3.2-3b-math/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "60a8642d-566b-4bb8-808b-beb49316f47d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(merged_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ea631226-887a-40ce-868b-caa43c698b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0012, -0.0006, -0.0046,  ..., -0.0015, -0.0019,  0.0018],\n",
       "         [-0.0371, -0.0003,  0.0327,  ..., -0.0513,  0.0242,  0.0132],\n",
       "         [-0.0371, -0.0003,  0.0327,  ..., -0.0513,  0.0242,  0.0132],\n",
       "         [-0.0133,  0.0154,  0.0067,  ..., -0.0052, -0.0019, -0.0182],\n",
       "         [ 0.0217,  0.0108,  0.0002,  ...,  0.0023, -0.0049, -0.0134],\n",
       "         [ 0.0110,  0.0327, -0.0332,  ...,  0.0342,  0.0166,  0.0005]]],\n",
       "       device='cuda:0', grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.merger.model.embed_tokens(input_ids.to(merger.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "23c95469-e959-43a9-b135-96efdd6b8ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0013, -0.0007, -0.0046,  ..., -0.0014, -0.0021,  0.0020],\n",
       "         [-0.0400, -0.0003,  0.0332,  ..., -0.0459,  0.0259,  0.0145],\n",
       "         [-0.0400, -0.0003,  0.0332,  ..., -0.0459,  0.0259,  0.0145],\n",
       "         [-0.0143,  0.0161,  0.0067,  ..., -0.0047, -0.0021, -0.0201],\n",
       "         [ 0.0234,  0.0114,  0.0002,  ...,  0.0021, -0.0053, -0.0148],\n",
       "         [ 0.0118,  0.0344, -0.0337,  ...,  0.0304,  0.0178,  0.0005]]],\n",
       "       device='cuda:0', grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embed_tokens(input_ids.to(model.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e36ff947-3cf5-498d-8aa7-0ac38522efb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "copied_embeds = copy.deepcopy(model.model.embed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "78ca414e-7746-4635-bf91-679641279bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "copied_embeds.weight.data = merged_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3f5302a-89fc-46e6-ad03-8c02136094e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "merger_embeds = merger.merger.model.embed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e7cf89c4-24b5-4ce0-8364-65b4e54ad265",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_masks = merger_embeds.get_constrained_masks()[\"masks\"]\n",
    "merged_embeds = sum((mask * linear.weight) for mask, linear in zip(weight_masks, merger_embeds.embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "fec4937e-5dab-4a97-90a6-b0e20ff84ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0012, -0.0006, -0.0046,  ..., -0.0015, -0.0019,  0.0018],\n",
       "         [-0.0371, -0.0003,  0.0327,  ..., -0.0513,  0.0242,  0.0132],\n",
       "         [-0.0371, -0.0003,  0.0327,  ..., -0.0513,  0.0242,  0.0132],\n",
       "         [-0.0133,  0.0154,  0.0067,  ..., -0.0052, -0.0019, -0.0182],\n",
       "         [ 0.0217,  0.0108,  0.0002,  ...,  0.0023, -0.0049, -0.0134],\n",
       "         [ 0.0110,  0.0327, -0.0332,  ...,  0.0342,  0.0166,  0.0005]]],\n",
       "       device='cuda:0', grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copied_embeds(input_ids.to(copied_embeds.weight.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "56c950f2-2441-4de9-8232-17d750e4fce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0106,  0.0116,  0.0130,  ..., -0.0029, -0.0182,  0.0064],\n",
       "        [ 0.0128,  0.0011,  0.0210,  ...,  0.0013,  0.0310, -0.0023],\n",
       "        [ 0.0238,  0.0200,  0.0288,  ..., -0.0014, -0.0008, -0.0072],\n",
       "        ...,\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066]],\n",
       "       device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e8f50d2-5ffd-4a03-a1ca-66aa1f326387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = merger.merger.lm_head(X)\n",
    "b = lin(X)\n",
    "c = model.lm_head(X)\n",
    "sum(a - c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c4933cb-65e7-43f6-9c51-048375f62e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128256, 3072])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_state[\"lm_head.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "318bc343-bbe0-4a44-b66b-bda08aecfd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1688a682766348809bfcb9b7ab146824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging masked modules:   0%|          | 0/255 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-16 11:02:13,619] [INFO] [train.save_merged:90] [PID:122984] [RANK:0] Dit con me may, lm_head\u001b[39m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3e50c4bc134a1b9e9699c30efaeccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged_model = save_merged(merger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dbb9fdbf-aeb0-4f44-adab-afa877cb11b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0115,  0.0122,  0.0132,  ..., -0.0026, -0.0195,  0.0071],\n",
       "        [ 0.0138,  0.0011,  0.0212,  ...,  0.0012,  0.0332, -0.0026],\n",
       "        [ 0.0256,  0.0212,  0.0291,  ..., -0.0013, -0.0009, -0.0079],\n",
       "        ...,\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073],\n",
       "        [-0.0074,  0.0019,  0.0047,  ..., -0.0049, -0.0019, -0.0073]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model.lm_head.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1a326617-0102-4c91-823d-962fbfcf9717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0077,  0.0273, -0.0027,  ..., -0.0005,  0.0198, -0.0300],\n",
       "        [ 0.0099, -0.0146, -0.0056,  ..., -0.0087,  0.0151,  0.0212],\n",
       "        [ 0.0151,  0.0176,  0.0459,  ..., -0.0229,  0.0100, -0.0233],\n",
       "        ...,\n",
       "        [ 0.0039, -0.0030,  0.0223,  ...,  0.0173, -0.0176, -0.0020],\n",
       "        [ 0.0193,  0.0197,  0.0047,  ...,  0.0123,  0.0146, -0.0078],\n",
       "        [-0.0332,  0.0251, -0.0092,  ..., -0.0079,  0.0087, -0.0132]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, requires_grad=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_model.model.layers[2].mlp.up_proj.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3fb79858-15bf-4aab-a995-b68c4cc72c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model = merged_model.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4835cb11-bd28-41b4-bf27-ab676df8e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "merger = merger.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5818daa8-860f-4aec-9d27-b6e387e4b48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Lee Min Ho is someone I don't trust.\"\n",
    "merger_logits = get_logits(text, merger.merger, tokenizer)\n",
    "merged_logits = get_logits(text, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "7776c50b-cc9a-4bac-a594-45b2b8540f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 5.0938,  7.5938, 12.3125,  ..., -5.3125, -5.3125, -5.3125],\n",
       "          [ 5.6875,  4.1562,  1.7500,  ..., -5.1875, -5.1875, -5.1875],\n",
       "          [ 5.6875,  4.6875,  4.0625,  ..., -4.3125, -4.3125, -4.3125],\n",
       "          ...,\n",
       "          [ 4.6250,  6.3438,  0.4199,  ..., -3.1562, -3.1562, -3.1562],\n",
       "          [12.2500,  7.4375,  5.3438,  ..., -3.1406, -3.1406, -3.1406],\n",
       "          [ 1.1328, -0.9492,  2.9375,  ..., -2.9375, -2.9219, -2.9219]]],\n",
       "        device='cuda:0'),\n",
       " tensor([[[ 5.2188,  7.7188, 12.2500,  ..., -5.4062, -5.4062, -5.4062],\n",
       "          [ 5.5938,  4.2188,  1.7422,  ..., -5.3125, -5.3125, -5.3125],\n",
       "          [ 5.6875,  4.7812,  3.9844,  ..., -4.4375, -4.4375, -4.4375],\n",
       "          ...,\n",
       "          [ 4.5312,  6.2188,  0.4707,  ..., -3.2812, -3.2812, -3.2812],\n",
       "          [12.1250,  7.3125,  5.3438,  ..., -3.3906, -3.3906, -3.3906],\n",
       "          [ 1.1719, -0.7891,  2.9688,  ..., -3.2031, -3.2031, -3.2031]]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_logits, merged_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "ba5bd3a6-b251-459b-ae50-38606c11ff0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0106,  0.0116,  0.0130,  ..., -0.0029, -0.0182,  0.0064],\n",
       "        [ 0.0128,  0.0011,  0.0210,  ...,  0.0013,  0.0310, -0.0023],\n",
       "        [ 0.0238,  0.0200,  0.0288,  ..., -0.0014, -0.0008, -0.0072],\n",
       "        ...,\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cfc533c2-51c3-4b21-82b6-935855398b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0106,  0.0116,  0.0130,  ..., -0.0029, -0.0182,  0.0064],\n",
       "        [ 0.0128,  0.0011,  0.0210,  ...,  0.0013,  0.0310, -0.0023],\n",
       "        [ 0.0238,  0.0200,  0.0288,  ..., -0.0014, -0.0008, -0.0072],\n",
       "        ...,\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066],\n",
       "        [-0.0068,  0.0018,  0.0047,  ..., -0.0054, -0.0018, -0.0066]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.embed_tokens.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3798517-09c3-4081-945d-cd9c45a856ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-16 09:44:04,646] [INFO] [train.<module>:4] [PID:116815] [RANK:0] Integrety test\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file\n",
    "save_directory = \"./hihi\"\n",
    "logger.info(\"Integrety test\")\n",
    "sd = {}\n",
    "signature = \"lm_head.weight\"\n",
    "shard_paths = [f for f in os.listdir(save_directory) if f.endswith('.safetensors')]\n",
    "for shard_path in sorted(shard_paths, key=lambda x: int(x.split('-')[1])):\n",
    "    apath = os.path.join(save_directory, shard_path)\n",
    "    with safe_open(apath, framework=\"pt\", device=\"cpu\") as f:\n",
    "        for key in f.keys():\n",
    "            if signature in key:\n",
    "                sd[key] = f.get_tensor(key)\n",
    "# torch.testing.assert_close(sd[signature], merged_state[signature], atol=0, rtol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f304d7b1-49c3-4875-934a-d182a1b398ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPast,\n",
    ")\n",
    "\n",
    "def decoder_forward(\n",
    "    decoder,\n",
    "    hidden_states: torch.Tensor,\n",
    "    attention_mask: Optional[torch.Tensor] = None,\n",
    "    position_ids: Optional[torch.LongTensor] = None,\n",
    "    past_key_value: Optional[Tuple[torch.Tensor]] = None,\n",
    "    output_attentions: Optional[bool] = False,\n",
    "    use_cache: Optional[bool] = False,\n",
    "    cache_position: Optional[torch.LongTensor] = None,\n",
    "    position_embeddings: Optional[Tuple[torch.Tensor, torch.Tensor]] = None,  # will become mandatory in v4.46\n",
    "    **kwargs,\n",
    ") -> Tuple[torch.FloatTensor, Optional[Tuple[torch.FloatTensor, torch.FloatTensor]]]:\n",
    "\n",
    "    steps = {}\n",
    "    # logger.warning(f\"-------- Logging hidden_states in decoder forward:\")\n",
    "    residual = hidden_states\n",
    "    # logger.warning(f\" hidden_states step 1 (as input): {hidden_states}\")\n",
    "    steps.update({\"step 1\": hidden_states})\n",
    "\n",
    "    hidden_states = decoder.input_layernorm(hidden_states)\n",
    "    # logger.warning(f\" hidden_states step 2 (after input_layernorm): {hidden_states}\")\n",
    "    steps.update({\"step 2\": hidden_states})\n",
    "    # Self Attention\n",
    "    hidden_states, self_attn_weights, present_key_value = decoder.self_attn(\n",
    "        hidden_states=hidden_states,\n",
    "        attention_mask=attention_mask,\n",
    "        position_ids=position_ids,\n",
    "        past_key_value=past_key_value,\n",
    "        output_attentions=output_attentions,\n",
    "        use_cache=use_cache,\n",
    "        cache_position=cache_position,\n",
    "        position_embeddings=position_embeddings,\n",
    "    )\n",
    "    # logger.warning(f\" hidden_states step 3 (after self_attn): {hidden_states}\")\n",
    "    steps.update({\"step 3\": hidden_states})\n",
    "    \n",
    "    hidden_states = residual + hidden_states\n",
    "    # logger.warning(f\" hidden_states step 4 (after first skip connection): {hidden_states}\")\n",
    "    steps.update({\"step 4\": hidden_states})\n",
    "    # Fully Connected\n",
    "    residual = hidden_states\n",
    "    hidden_states = decoder.post_attention_layernorm(hidden_states)\n",
    "    # logger.warning(f\" hidden_states step 5 (after post_attention_layernorm): {hidden_states}\")\n",
    "    steps.update({\"step 5\": hidden_states})\n",
    "    \n",
    "    hidden_states = decoder.mlp(hidden_states)\n",
    "    # logger.warning(f\" hidden_states step 6 (after mlp): {hidden_states}\")\n",
    "    steps.update({\"step 6\": hidden_states})\n",
    "    \n",
    "    hidden_states = residual + hidden_states\n",
    "    # logger.warning(f\" hidden_states step 7 (after second skip connection): {hidden_states}\")\n",
    "    steps.update({\"step 7\": hidden_states})\n",
    "\n",
    "    outputs = (hidden_states,)\n",
    "\n",
    "    if output_attentions:\n",
    "        outputs += (self_attn_weights,)\n",
    "\n",
    "    if use_cache:\n",
    "        outputs += (present_key_value,)\n",
    "\n",
    "    outputs += (steps,)\n",
    "    return outputs\n",
    "\n",
    "def model_forward(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    input_ids = inputs[\"input_ids\"]\n",
    "    attention_mask = inputs[\"attention_mask\"]\n",
    "    past_key_values = None\n",
    "    cache_position = None\n",
    "    position_ids = None\n",
    "    output_hidden_states = True\n",
    "    output_attentions = False\n",
    "    use_cache = False\n",
    "    return_dict = True\n",
    "    #############\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        # kept for BC (non `Cache` `past_key_values` inputs)\n",
    "        return_legacy_cache = False\n",
    "        inputs_embeds = model.embed_tokens(input_ids)\n",
    "\n",
    "        if cache_position is None:\n",
    "            past_seen_tokens = past_key_values.get_seq_length() if past_key_values is not None else 0\n",
    "            cache_position = torch.arange(\n",
    "                past_seen_tokens, past_seen_tokens + inputs_embeds.shape[1], device=inputs_embeds.device\n",
    "            )\n",
    "        if position_ids is None:\n",
    "            position_ids = cache_position.unsqueeze(0)\n",
    "\n",
    "        causal_mask = model._update_causal_mask(\n",
    "            attention_mask, inputs_embeds, cache_position, past_key_values, output_attentions\n",
    "        )\n",
    "\n",
    "        hidden_states = inputs_embeds\n",
    "\n",
    "        # create position embeddings to be shared across the decoder layers\n",
    "        position_embeddings = model.rotary_emb(hidden_states, position_ids)\n",
    "\n",
    "        # decoder layers\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_self_attns = () if output_attentions else None\n",
    "        next_decoder_cache = None\n",
    "        all_decoder_steps = ()\n",
    "\n",
    "        for i, decoder_layer in enumerate(model.layers[:2]):   \n",
    "            if output_hidden_states:\n",
    "                all_hidden_states += (hidden_states,)\n",
    "          \n",
    "            layer_outputs = decoder_forward(\n",
    "                decoder_layer,\n",
    "                hidden_states,\n",
    "                attention_mask=causal_mask,\n",
    "                position_ids=position_ids,\n",
    "                past_key_value=past_key_values,\n",
    "                output_attentions=output_attentions,\n",
    "                use_cache=use_cache,\n",
    "                cache_position=cache_position,\n",
    "                position_embeddings=position_embeddings,\n",
    "            )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "            steps = layer_outputs[-1]\n",
    "\n",
    "            if use_cache:\n",
    "                next_decoder_cache = layer_outputs[2 if output_attentions else 1]\n",
    "\n",
    "            if output_attentions:\n",
    "                all_self_attns += (layer_outputs[1],)\n",
    "\n",
    "            all_decoder_steps += (steps,)\n",
    "\n",
    "        hidden_states = model.norm(hidden_states)\n",
    "\n",
    "        # add hidden states from the last decoder layer\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states += (hidden_states,)\n",
    "\n",
    "        next_cache = next_decoder_cache if use_cache else None\n",
    "        if return_legacy_cache:\n",
    "            next_cache = next_cache.to_legacy_cache()\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(v for v in [hidden_states, next_cache, all_hidden_states, all_self_attns] if v is not None)\n",
    "        return BaseModelOutputWithPast(\n",
    "            last_hidden_state=hidden_states,\n",
    "            past_key_values=(),\n",
    "            hidden_states=all_hidden_states,\n",
    "            attentions=all_decoder_steps,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37fdf774-c999-402e-ba88-3260ede53f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2025-01-16 11:18:13,026] [WARNING] [accelerate.big_modeling.wrapper:455] [PID:122984] [RANK:0] You shouldn't move a model that is dispatched using accelerate hooks.\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "merged = merged.to(\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e42a2329-3d85-4f41-a460-3235d0b17351",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Lee Min Ho is someone I don't trust.\"\n",
    "merger_outputs = model_forward(text, merger.merger.model, tokenizer)\n",
    "merged_outputs = model_forward(text, model.model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "63d33f9c-9c9d-403c-b5eb-510c8d8a8b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAIL AT layer 0, step 1\n",
      "FAIL AT layer 0, step 2\n",
      "FAIL AT layer 0, step 3\n",
      "FAIL AT layer 0, step 4\n",
      "FAIL AT layer 0, step 5\n",
      "FAIL AT layer 0, step 6\n",
      "FAIL AT layer 0, step 7\n",
      "FAIL AT layer 1, step 1\n",
      "FAIL AT layer 1, step 2\n",
      "FAIL AT layer 1, step 3\n",
      "FAIL AT layer 1, step 4\n",
      "FAIL AT layer 1, step 5\n",
      "FAIL AT layer 1, step 6\n",
      "FAIL AT layer 1, step 7\n"
     ]
    }
   ],
   "source": [
    "device=\"cuda:0\"\n",
    "for j, layer_output in enumerate(merger_outputs.attentions):\n",
    "    other_output = merged_outputs.attentions[j]\n",
    "    for i in range(7):\n",
    "        key = f\"step {i+1}\"\n",
    "        if torch.allclose(layer_output[key], other_output[key], atol=0, rtol=0):\n",
    "            print(f\"layer {j}, step {i+1} passed!\")\n",
    "        else:\n",
    "            print(f\"FAIL AT layer {j}, step {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c378049f-4559-49b4-8ea3-50319107e541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0012, -0.0006, -0.0046,  ..., -0.0015, -0.0019,  0.0018],\n",
       "         [ 0.0060, -0.0327, -0.0078,  ...,  0.0146, -0.0061,  0.0006],\n",
       "         [-0.0200, -0.0303, -0.0104,  ..., -0.0227, -0.0084,  0.0063],\n",
       "         ...,\n",
       "         [ 0.0139, -0.0105, -0.0154,  ..., -0.0018,  0.0156,  0.0078],\n",
       "         [ 0.0010, -0.0153,  0.0620,  ...,  0.0317, -0.0289, -0.0111],\n",
       "         [ 0.0092, -0.0027,  0.0277,  ...,  0.0127, -0.0079,  0.0093]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_outputs.attentions[0]['step 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ab6d4599-b80c-4b6e-b30a-a963e422f6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0013, -0.0007, -0.0046,  ..., -0.0014, -0.0021,  0.0020],\n",
       "         [ 0.0065, -0.0344, -0.0079,  ...,  0.0131, -0.0065,  0.0007],\n",
       "         [-0.0215, -0.0317, -0.0105,  ..., -0.0203, -0.0090,  0.0070],\n",
       "         ...,\n",
       "         [ 0.0150, -0.0110, -0.0156,  ..., -0.0016,  0.0167,  0.0085],\n",
       "         [ 0.0011, -0.0161,  0.0625,  ...,  0.0283, -0.0310, -0.0123],\n",
       "         [ 0.0099, -0.0029,  0.0281,  ...,  0.0114, -0.0085,  0.0103]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_outputs.attentions[0]['step 1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4385fc4d-69e4-44b4-99c1-866749d7b29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8768e-03,  1.1658e-02,  2.3926e-01,  ...,  2.6172e-01,\n",
       "           4.9072e-02,  1.3000e-02],\n",
       "         [ 4.0234e-01, -9.9121e-02, -6.7188e+00,  ..., -1.3203e+00,\n",
       "          -7.0703e-01,  4.3213e-02],\n",
       "         [ 5.4688e-01, -3.2500e+00,  2.8281e+00,  ..., -3.2969e+00,\n",
       "           1.0703e+00,  6.3281e-01],\n",
       "         ...,\n",
       "         [-6.2500e-01,  8.0859e-01, -5.3438e+00,  ...,  9.6875e-01,\n",
       "           1.2500e+00, -8.3203e-01],\n",
       "         [ 7.3438e-01, -1.6250e+00,  2.8281e+00,  ...,  2.5625e+00,\n",
       "          -2.7656e+00, -5.4297e-01],\n",
       "         [ 4.0039e-01,  2.7222e-02,  1.4766e+00,  ..., -9.5312e-01,\n",
       "           8.7500e-01, -7.3047e-01]]], device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b6697c82-266f-4c0c-b836-701697e2bddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.8768e-03,  1.1658e-02,  2.3926e-01,  ...,  2.6172e-01,\n",
       "           4.9072e-02,  1.3000e-02],\n",
       "         [ 4.0234e-01, -9.9121e-02, -6.7188e+00,  ..., -1.3203e+00,\n",
       "          -7.0703e-01,  4.3213e-02],\n",
       "         [ 5.4688e-01, -3.2500e+00,  2.8281e+00,  ..., -3.2969e+00,\n",
       "           1.0703e+00,  6.3281e-01],\n",
       "         ...,\n",
       "         [-6.2500e-01,  8.0859e-01, -5.3438e+00,  ...,  9.6875e-01,\n",
       "           1.2500e+00, -8.3203e-01],\n",
       "         [ 7.3438e-01, -1.6250e+00,  2.8281e+00,  ...,  2.5625e+00,\n",
       "          -2.7656e+00, -5.4297e-01],\n",
       "         [ 4.0039e-01,  2.7222e-02,  1.4766e+00,  ..., -9.5312e-01,\n",
       "           8.7500e-01, -7.3047e-01]]], device='cuda:1', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_outputs.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f541a2d1-5abc-4f49-a7e4-813e8d6cb33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SET = set({3})\n",
    "sa = set({1,2,3})\n",
    "sb = set({1,2,4})\n",
    "SET | sa | sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7eb846a-1776-47f8-ac01-4174298f2f94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "170c0e63-142f-46d3-899d-b4d445ef4b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "merger.save_merged = save_merged.__get__(merger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76f9c34f-45dd-49eb-a441-f5e5b62b89f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merger.NewMerger"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9dd74556-c062-468f-b555-115b511582c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82cd12d60da44bcb6148cf98dcd71de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Merging masked modules:   0%|          | 0/255 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48eb01734a12416c9ec0a2d39238eccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Copying non-masked parameters: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "super(): __class__ cell not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmerger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_merged\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./hehe\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 118\u001b[0m, in \u001b[0;36msave_merged\u001b[0;34m(self, save_directory, state_dict, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m tqdm(keys_to_copy, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCopying non-masked parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    116\u001b[0m     merged_state[key] \u001b[38;5;241m=\u001b[39m full_state[key]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msave_pretrained(\n\u001b[1;32m    119\u001b[0m     save_directory\u001b[38;5;241m=\u001b[39msave_directory,\n\u001b[1;32m    120\u001b[0m     state_dict\u001b[38;5;241m=\u001b[39mmerged_state,\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    122\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: super(): __class__ cell not found"
     ]
    }
   ],
   "source": [
    "merger.save_merged(\"./hehe\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merger2",
   "language": "python",
   "name": "merger2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
