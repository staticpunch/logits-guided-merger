{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8095e2b8-7c4c-4aeb-b31e-52926bc504e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-18 09:22:15,257] [INFO] [masks.<module>:57] [PID:124456] [RANK:0] --------- ACCURATE MASKS ----------\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Model merging training implementation using PyTorch and Transformers.\n",
    "Implements custom data collation and training for merged language models.\n",
    "\"\"\"\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import (\n",
    "    Any, Callable, Dict, \n",
    "    List, NewType, Optional, \n",
    "    Tuple, Union, Mapping\n",
    ")\n",
    "from abc import ABC, abstractmethod\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from accelerate.logging import get_logger\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import safetensors\n",
    "import math\n",
    "import yaml\n",
    "import logging\n",
    "import copy\n",
    "import gc\n",
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerBase,\n",
    "    PreTrainedModel,\n",
    "    PretrainedConfig,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    HfArgumentParser,\n",
    "    default_data_collator,\n",
    "    is_torch_xla_available,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from transformers.utils import CONFIG_NAME\n",
    "from transformers.pytorch_utils import is_torch_greater_or_equal_than_1_13\n",
    "\n",
    "from merger import (\n",
    "    MergerConfig,\n",
    "    Merger,\n",
    "    # NewMerger,\n",
    "    init_masks,\n",
    "    set_masks\n",
    ")\n",
    "\n",
    "from utils import (\n",
    "    generate, \n",
    "    get_hidden_states, \n",
    "    get_logits,\n",
    "    free_memory\n",
    ")\n",
    "# Configure logger\n",
    "from logging_config import configure_logging\n",
    "configure_logging()\n",
    "logger = logging.getLogger(\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1061d6-ab83-4307-a6ed-1e6b7293663c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Save merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a0ca6-3ae9-4f10-a23e-c2237b82fd8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ae3d99f-7632-40fe-89ee-12adf5274a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"../results/run_02b\"\n",
    "merger_config = MergerConfig.from_pretrained(\n",
    "    checkpoint_dir,\n",
    "    _configuration_file=\"merger_config.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe88eec-0c36-4479-815d-06a6f7cee11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MergerConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"constrain_mode\": \"identity\",\n",
       "  \"mode\": \"vector_input\",\n",
       "  \"model_paths\": [\n",
       "    \"/workspace/models/llama-3.2-3b-wizard\",\n",
       "    \"/workspace/models/llama-3.2-3b-math\"\n",
       "  ],\n",
       "  \"transformers_version\": \"4.46.3\"\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15df46c9-d623-4668-8147-af65e084e573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-17 12:25:51,932] [INFO] [merger.__init__:222] [PID:3073] [RANK:0] Creating merger with dummy weights ...\u001b[39m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96fb87d414e41dfbbcf520f9e0d44b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4f9550ff9644f5bed2a16a55230ef9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea4f671e13946288b4db8d4de0d69e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks:   1%|█▎                                                                                                                                                                            | 2/255 [00:07<15:23,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2025-01-17 12:26:01,113] [WARNING] [masks.warning_once:328] [PID:3073] [RANK:0] Though you want to make a masks of modes ['vector_input', 'vector_input'] for RMSNorms' weights, by default a mask only accepts a scalar mask. Converting modes to `scalar`.\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:27<00:00,  9.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-17 12:26:26,128] [INFO] [merger.from_pretrained:401] [PID:3073] [RANK:0] Loaded masks from ../results/run_02b\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "merger = Merger.from_pretrained(\n",
    "    checkpoint_dir,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map={\"\":3}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bd3be5e-e340-4ddb-af0b-dc53dd9b3a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merger.save_pretrained(\"./haha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d683c28-3e58-42a5-9c6d-c546866f74d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging masked modules: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:02<00:00, 122.62it/s]\n"
     ]
    }
   ],
   "source": [
    "merger.save_merged(\"./haha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c523cc92-e729-4088-8309-23c1302b76ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LlamaForCausalLM'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.models[0].__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73c3bfa5-05f0-4277-a48f-58890aaf4149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"/workspace/models/llama-3.2-3b-wizard\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 128000,\n",
       "  \"eos_token_id\": 128001,\n",
       "  \"head_dim\": 128,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 3072,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 8192,\n",
       "  \"max_position_embeddings\": 131072,\n",
       "  \"mlp_bias\": false,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 24,\n",
       "  \"num_hidden_layers\": 28,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": {\n",
       "    \"factor\": 32.0,\n",
       "    \"high_freq_factor\": 4.0,\n",
       "    \"low_freq_factor\": 1.0,\n",
       "    \"original_max_position_embeddings\": 8192,\n",
       "    \"rope_type\": \"llama3\"\n",
       "  },\n",
       "  \"rope_theta\": 500000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.46.3\",\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 128256\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdae5c05-f954-49bc-9487-f1a964a265f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5078, 0.5078, 0.4883, 0.4434, 0.4922, 0.4902, 0.5039, 0.4902, 0.5117,\n",
       "        0.4707, 0.4922, 0.4824, 0.5156, 0.5234, 0.4824, 0.5078, 0.5234, 0.5312,\n",
       "        0.5195, 0.4863, 0.5039, 0.5195, 0.5078, 0.5273, 0.5156, 0.4961, 0.5117,\n",
       "        0.5273, 0.5156, 0.4863, 0.5039, 0.4746, 0.5000, 0.4902, 0.5234, 0.4863,\n",
       "        0.5000, 0.4727, 0.4883, 0.4766, 0.5156, 0.4980, 0.4707, 0.5195, 0.4922,\n",
       "        0.4980, 0.4883, 0.4922, 0.4902, 0.5000, 0.4727, 0.4941, 0.5039, 0.4961,\n",
       "        0.4785, 0.5000, 0.4512, 0.5000, 0.4883, 0.4883, 0.5078, 0.4863, 0.5078,\n",
       "        0.4863, 0.4941, 0.5078, 0.4805, 0.5156, 0.4629, 0.4746, 0.4902, 0.5234,\n",
       "        0.4883, 0.4375, 0.4844, 0.4941, 0.4707, 0.4688, 0.4961, 0.5234, 0.4961,\n",
       "        0.5078, 0.5156, 0.5273, 0.5039, 0.4609, 0.5000, 0.4785, 0.5039, 0.5078,\n",
       "        0.4902, 0.4531, 0.4980, 0.4922, 0.5117, 0.4883, 0.4766, 0.4902, 0.4824,\n",
       "        0.5039], device='cuda:2', dtype=torch.bfloat16,\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.merger.model.layers[0].mlp.up_proj.get_raw_masks()['weight_masks'][0][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36144e08-47d3-48db-82c8-ba5b33981511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5078, 0.5078, 0.4883, 0.4453, 0.4941, 0.4902, 0.5039, 0.4961, 0.5117,\n",
       "        0.4707, 0.4902, 0.4824, 0.5156, 0.5234, 0.4824, 0.5039, 0.5234, 0.5312,\n",
       "        0.5234, 0.4863, 0.5039, 0.5195, 0.5078, 0.5273, 0.5156, 0.4961, 0.5117,\n",
       "        0.5234, 0.5156, 0.4863, 0.5039, 0.4746, 0.5000, 0.4922, 0.5234, 0.4863,\n",
       "        0.5000, 0.4727, 0.4883, 0.4785, 0.5156, 0.5000, 0.4707, 0.5195, 0.4922,\n",
       "        0.4980, 0.4941, 0.4922, 0.4922, 0.5000, 0.4746, 0.4941, 0.5039, 0.4961,\n",
       "        0.4766, 0.5000, 0.4551, 0.5000, 0.4883, 0.4883, 0.5078, 0.4844, 0.5078,\n",
       "        0.4863, 0.4941, 0.5078, 0.4824, 0.5156, 0.4648, 0.4746, 0.4922, 0.5234,\n",
       "        0.4922, 0.4375, 0.4844, 0.4941, 0.4727, 0.4688, 0.4961, 0.5234, 0.4961,\n",
       "        0.5078, 0.5156, 0.5273, 0.5039, 0.4629, 0.5000, 0.4805, 0.5039, 0.5078,\n",
       "        0.4922, 0.4551, 0.5000, 0.4941, 0.5117, 0.4883, 0.4766, 0.4922, 0.4922,\n",
       "        0.5039], dtype=torch.bfloat16, grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.merger.model.layers[0].mlp.up_proj.get_raw_masks()['weight_masks'][1][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb6d2f9a-8d28-439e-ac3f-062c7f3a867c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-16 14:52:14,500] [INFO] [merger.from_pretrained:315] [PID:143678] [RANK:0] >>> Merger device: {'': 0}\u001b[39m\n",
      "[2025-01-16 14:52:14,506] [INFO] [merger.__init__:207] [PID:143678] [RANK:0] Creating merger with dummy weights ...\u001b[39m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a680c13d11314a65b69504df8ba88810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ed940db9114a51872427997239fd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e93934a4664acfa8020ec115b0dbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks:   1%|█▎                                                                                                                                                                            | 2/255 [00:18<38:51,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2025-01-16 14:52:36,823] [WARNING] [masks.warning_once:328] [PID:143678] [RANK:0] Though you want to make a masks of modes ['vector_input', 'vector_input'] for RMSNorms' weights, by default a mask only accepts a scalar mask. Converting modes to `scalar`.\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:09<00:00,  3.69it/s]\n"
     ]
    }
   ],
   "source": [
    "device_map={\"\":0}\n",
    "merger = Merger.from_pretrained(\n",
    "    checkpoint_dir,\n",
    "    merge_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=device_map,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba7d1f03-3b9c-4998-975a-9346e6cd7e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging masked modules: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:02<00:00, 96.46it/s]\n"
     ]
    }
   ],
   "source": [
    "merger.save_merged(\"/workspace/logits-guided-merger/results/run_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f308f4c-8843-4343-a289-b56f6843c62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/workspace/logits-guided-merger/results/run_01/tokenizer_config.json',\n",
       " '/workspace/logits-guided-merger/results/run_01/special_tokens_map.json',\n",
       " '/workspace/logits-guided-merger/results/run_01/tokenizer.json')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"/workspace/logits-guided-merger/results/run_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "246a794f-5d3e-41e5-b1b6-6cd6359dc9b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"/workspace/models/llama-3.2-3b-wizard\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 128000,\n",
       "  \"eos_token_id\": 128001,\n",
       "  \"head_dim\": 128,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 3072,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 8192,\n",
       "  \"max_position_embeddings\": 131072,\n",
       "  \"mlp_bias\": false,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 24,\n",
       "  \"num_hidden_layers\": 28,\n",
       "  \"num_key_value_heads\": 8,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": {\n",
       "    \"factor\": 32.0,\n",
       "    \"high_freq_factor\": 4.0,\n",
       "    \"low_freq_factor\": 1.0,\n",
       "    \"original_max_position_embeddings\": 8192,\n",
       "    \"rope_type\": \"llama3\"\n",
       "  },\n",
       "  \"rope_theta\": 500000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.46.3\",\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 128256\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e3a924e-bb10-4403-a55e-b9175605d6a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e49ecc155342bf9ac3f419a91246ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "merged = AutoModelForCausalLM.from_pretrained(\n",
    "    \"hehe\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3216f4b5-d5b8-49fe-a498-e160283dc7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.llama.modeling_llama.LlamaForCausalLM"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba6f1bbd-6153-41f1-88dc-1ca09a378af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/workspace/models/llama-3.2-3b-wizard\")\n",
    "text = \"Lee Min Ho is someone I don't trust.\"\n",
    "merger_logits = get_logits(text, merger.merger, tokenizer)\n",
    "merged_logits = get_logits(text, merged, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52d6ca29-1fca-4903-9486-de0a4e6e727a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(merger_logits, merged_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d7bcb54-6698-45f4-ba87-1399da51257c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 5.0938,  7.5938, 12.3750,  ..., -5.3438, -5.3438, -5.3438],\n",
       "          [ 5.7500,  4.1562,  1.7812,  ..., -5.1875, -5.1875, -5.1875],\n",
       "          [ 5.6562,  4.6875,  4.0312,  ..., -4.3125, -4.3125, -4.3125],\n",
       "          ...,\n",
       "          [ 4.6250,  6.3438,  0.4102,  ..., -3.1719, -3.1719, -3.1719],\n",
       "          [12.2500,  7.4375,  5.3125,  ..., -3.1562, -3.1562, -3.1562],\n",
       "          [ 1.0938, -0.9844,  2.9062,  ..., -2.9688, -2.9688, -2.9688]]],\n",
       "        dtype=torch.bfloat16),\n",
       " tensor([[[ 5.0938,  7.5938, 12.3750,  ..., -5.3438, -5.3438, -5.3438],\n",
       "          [ 5.7500,  4.1562,  1.7812,  ..., -5.1875, -5.1875, -5.1875],\n",
       "          [ 5.6562,  4.6875,  4.0312,  ..., -4.3125, -4.3125, -4.3125],\n",
       "          ...,\n",
       "          [ 4.6250,  6.3438,  0.4102,  ..., -3.1719, -3.1719, -3.1719],\n",
       "          [12.2500,  7.4375,  5.3125,  ..., -3.1562, -3.1562, -3.1562],\n",
       "          [ 1.0938, -0.9844,  2.9062,  ..., -2.9688, -2.9688, -2.9688]]],\n",
       "        dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_logits, merged_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c72ec73-63c6-41c1-a986-5c36aa054a9b",
   "metadata": {},
   "source": [
    "## SLERP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "596a39f3-8982-4a47-8b48-924b9582f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors import safe_open\n",
    "from safetensors.torch import save_file\n",
    "def load_tensors(path, signature=\"\"):\n",
    "    state_dict = {}\n",
    "    shard_paths = [f for f in os.listdir(path) if (\n",
    "        f.startswith(\"model\") and f.endswith('.safetensors')\n",
    "    )]\n",
    "    for shard_path in sorted(shard_paths, key=lambda x: int(x.split('-')[1])):\n",
    "        apath = os.path.join(path, shard_path)\n",
    "        with safe_open(apath, framework=\"pt\", device=\"cpu\") as f:\n",
    "            for key in f.keys():\n",
    "                if signature in key:\n",
    "                    state_dict[key] = f.get_tensor(key)\n",
    "    return state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ef63e67b-15d8-4ae2-b2af-9aa6f1261c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd1 = load_tensors(path=\"/workspace/models/baselines/acl-slerp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "312821f9-7ef2-493a-ad83-81dce59bc803",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd2 = load_tensors(path=\"/workspace/models/baselines/acl-slerp-custom/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "119930dd-6ba5-4fde-a058-61c38e92a938",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd3 = load_tensors(path=\"/workspace/logits-guided-merger/dev/test-slerp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e5ae6c09-54ec-441b-b7e2-bee1368e6d82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ok = []\n",
    "not_ok = []\n",
    "for key in list(sd1.keys()):\n",
    "    if torch.allclose(sd1[key], sd3[key], atol=1e-5, rtol=1e-5):\n",
    "        ok.append(key)\n",
    "    else:\n",
    "        not_ok.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7a4c66dc-777a-4dbe-95bf-1a2780b95702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7127)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = not_ok[1]\n",
    "torch.mean((torch.abs(sd1[k] - sd3[k]) == 0).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "000abd58-518c-441c-becc-5f8719841f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = list(sd1.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f29f78b0-8bf9-4bd0-aeba-b5da737f60a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0111,  0.0116,  0.0130,  ..., -0.0027, -0.0189,  0.0067],\n",
       "         [ 0.0134,  0.0011,  0.0210,  ...,  0.0012,  0.0322, -0.0024],\n",
       "         [ 0.0249,  0.0200,  0.0288,  ..., -0.0013, -0.0009, -0.0074],\n",
       "         ...,\n",
       "         [-0.0071,  0.0018,  0.0047,  ..., -0.0050, -0.0019, -0.0068],\n",
       "         [-0.0071,  0.0018,  0.0047,  ..., -0.0050, -0.0019, -0.0068],\n",
       "         [-0.0071,  0.0018,  0.0047,  ..., -0.0050, -0.0019, -0.0068]],\n",
       "        dtype=torch.bfloat16),\n",
       " tensor([[ 0.0111,  0.0116,  0.0130,  ..., -0.0027, -0.0189,  0.0067],\n",
       "         [ 0.0134,  0.0011,  0.0210,  ...,  0.0012,  0.0322, -0.0024],\n",
       "         [ 0.0249,  0.0200,  0.0288,  ..., -0.0013, -0.0009, -0.0074],\n",
       "         ...,\n",
       "         [-0.0071,  0.0018,  0.0047,  ..., -0.0050, -0.0019, -0.0068],\n",
       "         [-0.0071,  0.0018,  0.0047,  ..., -0.0050, -0.0019, -0.0068],\n",
       "         [-0.0071,  0.0018,  0.0047,  ..., -0.0050, -0.0019, -0.0068]],\n",
       "        dtype=torch.bfloat16),\n",
       " tensor(0., dtype=torch.bfloat16))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd1[key], sd2[key], torch.sum(sd1[key] - sd2[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4757d13d-6779-4a27-b5e8-f71d5a219f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"/workspace/logits-guided-merger/results/run_02b\"\n",
    "merger_config = MergerConfig.from_pretrained(\n",
    "    checkpoint_dir,\n",
    "    _configuration_file=\"merger_config.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddde40a5-1f93-4911-8c14-3554109ce9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MergerConfig {\n",
       "  \"_attn_implementation_autoset\": true,\n",
       "  \"constrain_mode\": \"identity\",\n",
       "  \"mode\": \"vector_input\",\n",
       "  \"model_paths\": [\n",
       "    \"/workspace/models/llama-3.2-3b-wizard\",\n",
       "    \"/workspace/models/llama-3.2-3b-math\"\n",
       "  ],\n",
       "  \"transformers_version\": \"4.46.3\"\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4066f410-82dd-4213-8dfe-03493dd22556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-18 09:23:29,144] [INFO] [merger.__init__:222] [PID:124456] [RANK:0] Creating merger with dummy weights ...\u001b[39m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24e9eb2044c34ed0b133971a80e40b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f31d208a3914ec08c881ad3e84088a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bd3a48c2dc43368c63af79ab542eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks:   1%|█▎                                                                                                                                                                            | 2/255 [00:07<15:21,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[2025-01-18 09:23:39,224] [WARNING] [masks.warning_once:328] [PID:124456] [RANK:0] Though you want to make a masks of modes ['vector_input', 'vector_input'] for RMSNorms' weights, by default a mask only accepts a scalar mask. Converting modes to `scalar`.\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:29<00:00,  8.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-18 09:24:01,645] [INFO] [merger.from_pretrained:401] [PID:124456] [RANK:0] Loaded masks from /workspace/logits-guided-merger/results/run_02b\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "merger = Merger.from_pretrained(\n",
    "    checkpoint_dir,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc750b74-ecdb-45ea-8a56-0fa6b2047945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight_masks': [Parameter containing:\n",
       "  tensor([0.5156, 0.5117, 0.5078,  ..., 0.4590, 0.5234, 0.4902],\n",
       "         dtype=torch.bfloat16, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0.5195, 0.5117, 0.5078,  ..., 0.4570, 0.5234, 0.4902],\n",
       "         dtype=torch.bfloat16, requires_grad=True)],\n",
       " 'bias_masks': [None, None]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.merger.lm_head.get_constrained_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9be7cd84-8094-4e46-a000-635717749a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "masks_weight = merger.get_masks_state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ffd09f9-4f91-46f6-9ba1-b02514264db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-18 09:28:02,907] [INFO] [merger.set_masks:170] [PID:124456] [RANK:0] Applying uniform masks with factors = [0.5, 0.5].\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up masks: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:00<00:00, 14356.15it/s]\n"
     ]
    }
   ],
   "source": [
    "mask_init = {\n",
    "  \"strategy\": \"uniform\",\n",
    "  \"factors\": [0.5, 0.5]\n",
    "}\n",
    "set_masks(merger, mask_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc7f3641-df73-4933-9897-4c2f18bcb640",
   "metadata": {},
   "outputs": [],
   "source": [
    "merger.load_masks(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9923388-d64a-4039-a47d-7363ab607a92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# masks_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b21b1c02-2fd2-4cff-8ef2-f904218b65ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_init = {\n",
    "    \"strategy\": \"spherical\",\n",
    "    \"parameters\": {\n",
    "        \"self_attn\": [0, 0.3, 0.5, 0.7, 1],\n",
    "        \"mlp\": [1, 0.7, 0.5, 0.3, 0],\n",
    "        \"default\": 0.5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5979dfde-0a0f-4c06-b234-61284fef694d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "def lerp(\n",
    "    t: float, v0: Union[np.ndarray, torch.Tensor], v1: Union[np.ndarray, torch.Tensor]\n",
    ") -> Union[np.ndarray, torch.Tensor]:\n",
    "    return (1 - t) * v0 + t * v1\n",
    "\n",
    "\n",
    "def slerp(\n",
    "    t: Union[float, np.ndarray],\n",
    "    v0: Union[np.ndarray, torch.Tensor],\n",
    "    v1: Union[np.ndarray, torch.Tensor],\n",
    "    DOT_THRESHOLD: float = 0.9995,\n",
    "    eps: float = 1e-8,\n",
    "):\n",
    "    \"\"\"\n",
    "    Spherical linear interpolation\n",
    "\n",
    "    From: https://gist.github.com/dvschultz/3af50c40df002da3b751efab1daddf2c\n",
    "    Args:\n",
    "        t (float/np.ndarray): Float value between 0.0 and 1.0\n",
    "        v0 (np.ndarray): Starting vector\n",
    "        v1 (np.ndarray): Final vector\n",
    "        DOT_THRESHOLD (float): Threshold for considering the two vectors as\n",
    "                               colinear. Not recommended to alter this.\n",
    "    Returns:\n",
    "        v2 (np.ndarray): Interpolation vector between v0 and v1\n",
    "    \"\"\"\n",
    "    is_torch = False\n",
    "    if not isinstance(v0, np.ndarray):\n",
    "        is_torch = True\n",
    "        v0 = v0.detach().cpu().float().numpy()\n",
    "    if not isinstance(v1, np.ndarray):\n",
    "        is_torch = True\n",
    "        v1 = v1.detach().cpu().float().numpy()\n",
    "\n",
    "    # Copy the vectors to reuse them later\n",
    "    v0_copy = np.copy(v0)\n",
    "    v1_copy = np.copy(v1)\n",
    "\n",
    "    # Normalize the vectors to get the directions and angles\n",
    "    v0 = normalize(v0, eps)\n",
    "    v1 = normalize(v1, eps)\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "\n",
    "    # Dot product with the normalized vectors (can't use np.dot in W)\n",
    "    dot = np.sum(v0 * v1)\n",
    "\n",
    "    # If absolute value of dot product is almost 1, vectors are ~colinear, so use lerp\n",
    "    if np.abs(dot) > DOT_THRESHOLD:\n",
    "        s0, s1 = 1 - t, t\n",
    "        return s0, s1\n",
    "        # res = lerp(t, v0_copy, v1_copy)\n",
    "        # return maybe_torch(res, is_torch)\n",
    "\n",
    "    # Calculate initial angle between v0 and v1\n",
    "    theta_0 = np.arccos(dot)\n",
    "    sin_theta_0 = np.sin(theta_0)\n",
    "\n",
    "    # Angle at timestep t\n",
    "    theta_t = theta_0 * t\n",
    "    sin_theta_t = np.sin(theta_t)\n",
    "\n",
    "    # Finish the slerp algorithm\n",
    "    s0 = np.sin(theta_0 - theta_t) / sin_theta_0\n",
    "    s1 = sin_theta_t / sin_theta_0\n",
    "\n",
    "    return s0, s1\n",
    "    # res = s0 * v0_copy + s1 * v1_copy\n",
    "\n",
    "    # return maybe_torch(res, is_torch)\n",
    "\n",
    "\n",
    "def maybe_torch(v: np.ndarray, is_torch: bool):\n",
    "    if is_torch:\n",
    "        return torch.from_numpy(v)\n",
    "    return v\n",
    "\n",
    "\n",
    "def normalize(v: np.ndarray, eps: float):\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    if norm_v > eps:\n",
    "        v = v / norm_v\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd9ff492-24fb-484c-a2d2-5f6588013b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from masks import Mask, MaskConfig\n",
    "from masks import LinearsWithMasks, EmbeddingsWithMasks, RMSNormsWithMasks\n",
    "\n",
    "def odd_one_out(masked_module: nn.Module, selected_idx: int):  \n",
    "    assert selected_idx is not None and isinstance(selected_idx, int), (\n",
    "        \"Must provide valid model index. Check whether passed index is `int`\"\n",
    "    )\n",
    "    masks_modules = []\n",
    "    for name, child in masked_module.named_children():\n",
    "        if not isinstance(child, nn.ModuleList): continue\n",
    "        assert selected_idx < len(child), (\n",
    "            f\"There are only {len(child)} component models, \"\n",
    "            f\"passed model index is {selected_idx}\"\n",
    "        )\n",
    "        ## exclude sub_module that is None, aka bias_masks.\n",
    "        if all(isinstance(sub_module, Mask) for sub_module in child):\n",
    "            masks_modules.append(child)\n",
    "        \n",
    "    for masks in masks_modules:\n",
    "        for i, mask in enumerate(masks):\n",
    "            value = 1.0 if i == selected_idx else 0.0\n",
    "            with torch.no_grad():\n",
    "                mask.weight.data.fill_(value)\n",
    "\n",
    "def random_init(masked_module: nn.Module):\n",
    "    masks_modules = []\n",
    "    for name, child in masked_module.named_children():\n",
    "        if not isinstance(child, nn.ModuleList): continue\n",
    "        ## exclude sub_module that is None, aka bias_masks.\n",
    "        if all(isinstance(sub_module, Mask) for sub_module in child):\n",
    "            masks_modules.append(child)\n",
    "        \n",
    "    for masks in masks_modules:\n",
    "        for i, mask in enumerate(masks):\n",
    "            with torch.no_grad():\n",
    "                random_value = torch.rand_like(mask.weight.data)\n",
    "                mask.weight.data = random_value\n",
    "                \n",
    "def uniform_init(masked_module: nn.Module, factors: List[float]):  \n",
    "    masks_modules = []\n",
    "    for name, child in masked_module.named_children():\n",
    "        if not isinstance(child, nn.ModuleList): continue\n",
    "        assert len(factors) == len(child), (\n",
    "            f\"There are {len(child)} component models, \"\n",
    "            f\"but your passed factors have {len(factors)} values.\"\n",
    "        )\n",
    "        ## exclude sub_module that is None, aka bias_masks.\n",
    "        if all(isinstance(sub_module, Mask) for sub_module in child):\n",
    "            masks_modules.append(child)\n",
    "\n",
    "    for masks in masks_modules:\n",
    "        for factor, mask in zip(factors, masks):\n",
    "            with torch.no_grad():\n",
    "                mask.weight.data.fill_(factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e05e2f51-bcc0-49f4-97d5-fe6780cd7886",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_t(weight_name, parameters, num_layers):\n",
    "    \"\"\"\n",
    "    Computes the blending factor for a weight based on layer index and conditions.\n",
    "    \n",
    "    Args:\n",
    "        weight_name (str): Name of the weight.\n",
    "        parameters (dict): Mapping of conditions to blending values.\n",
    "        num_layers (int): Total number of layers in the model.\n",
    "        \n",
    "    Returns:\n",
    "        float: Computed blending value.\n",
    "    \"\"\"\n",
    "    anchors = parameters.get(\"default\")\n",
    "    if not isinstance(anchors, list):\n",
    "        anchors = [anchors]\n",
    "\n",
    "    for filter_name in parameters.keys():\n",
    "        if filter_name in weight_name:\n",
    "            anchors = parameters.get(filter_name)\n",
    "            break\n",
    "            \n",
    "    match = re.search(r\"layers\\.([^\\.]*)\\.\", weight_name)\n",
    "    if match:\n",
    "        layer_idx = int(match.group(1))\n",
    "        layer_t = layer_idx / (num_layers - 1)\n",
    "        scaled = layer_t * (len(anchors) - 1)\n",
    "        i0 = math.floor(scaled)\n",
    "        i1 = min(len(anchors) - 1, i0 + 1)\n",
    "        frac = scaled - i0\n",
    "        \n",
    "        blend_value = (1 - frac) * anchors[i0] + frac * anchors[i1]\n",
    "    else:\n",
    "        blend_value = anchors[0]\n",
    "        \n",
    "    return blend_value\n",
    "\n",
    "def assign_spherical_masks(masks, s0, s1):\n",
    "    assert len(masks) == 2, (\n",
    "        \"Spherical initialization only supports 2 models. \"\n",
    "        f\"Found {len(masks)}.\"\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        masks[0].weight.data.fill_(s0)\n",
    "        masks[1].weight.data.fill_(s1)\n",
    "        \n",
    "def spherical_init(\n",
    "    masked_module: nn.Module, \n",
    "    module_name: str,\n",
    "    parameters: Mapping = None,\n",
    "    num_layers: int  = None,\n",
    "):      \n",
    "    t = compute_t(module_name, parameters, num_layers)\n",
    "    if isinstance(masked_module, LinearsWithMasks):\n",
    "        weight_masks = masked_module.weight_masks\n",
    "        bias_masks = masked_module.bias_masks\n",
    "        v0, v1 = (x.weight.data for x in masked_module.linears)\n",
    "        s0, s1 = slerp(t, v0, v1)\n",
    "        assign_spherical_masks(weight_masks, s0, s1)\n",
    "        \n",
    "        if all(isinstance(mask, Mask) for mask in bias_masks):\n",
    "            v0, v1 = (x.bias.data for x in masked_module.linears)\n",
    "            s0, s1 = slerp(t, v0, v1)\n",
    "            assign_spherical_masks(bias_masks, s0, s1)\n",
    "        \n",
    "    elif isinstance(masked_module, EmbeddingsWithMasks):\n",
    "        masks = masked_module.masks\n",
    "        v0, v1 = (x.weight.data for x in masked_module.embeddings)\n",
    "        s0, s1 = slerp(t, v0, v1)\n",
    "        assign_spherical_masks(masks, s0, s1)\n",
    "        \n",
    "    elif isinstance(masked_module, RMSNormsWithMasks):\n",
    "        masks = masked_module.masks\n",
    "        v0, v1 = (x.weight.data for x in masked_module.rms_norms)\n",
    "        s0, s1 = slerp(t, v0, v1)\n",
    "        assign_spherical_masks(masks, s0, s1)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Does not support class {type(masked_module).__name__} yet.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fef0158d-e0f3-49fe-b1e5-227bf1ac099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_masked_modules(module):\n",
    "    masked_module_names = []\n",
    "    for parent_name, parent_module in module.named_modules():\n",
    "        for name, child in parent_module.named_children():\n",
    "            full_child_name = f\"{parent_name}.{name}\" if parent_name else name\n",
    "            if (\"WithMasks\" in type(child).__name__):\n",
    "                masked_module_names.append(full_child_name)\n",
    "\n",
    "    return masked_module_names\n",
    "\n",
    "INIT_MAP = dict(\n",
    "    random=random_init,\n",
    "    odd_one_out=odd_one_out,\n",
    "    uniform=uniform_init,\n",
    "    spherical=spherical_init\n",
    ")\n",
    "\n",
    "def init_(root_module, strategy=\"random\", **kwargs):\n",
    "    init_method = INIT_MAP[strategy]\n",
    "    masked_module_names = find_masked_modules(root_module)\n",
    "    \n",
    "    for module_name in tqdm(masked_module_names, desc=\"Setting up masks\"):\n",
    "        module_names = module_name.split(\".\")\n",
    "        target_module = root_module\n",
    "        for m_name in module_names:\n",
    "            target_module = getattr(target_module, m_name)\n",
    "\n",
    "        if strategy == \"spherical\":\n",
    "            kwargs[\"module_name\"] = module_name\n",
    "            \n",
    "        init_method(target_module, **kwargs)\n",
    "\n",
    "def initialize_masks(merger, mask_init):\n",
    "    # Initialize masks based on config\n",
    "    mask_strategy = mask_init[\"strategy\"]\n",
    "    if mask_strategy == \"uniform\":\n",
    "        if not mask_init[\"factors\"]:\n",
    "            raise ValueError(\n",
    "                \"Factors must be provided for uniform strategy\"\n",
    "            )\n",
    "        logger.info(f\"Applying uniform masks with factors = {factors}.\")\n",
    "        factors = mask_init[\"factors\"]\n",
    "        init_(merger.merger, strategy=\"uniform\", factors=factors)\n",
    "        \n",
    "    elif mask_strategy == \"random\":\n",
    "        logger.info(f\"Applying random masks.\")\n",
    "        init_(merger.merger, strategy=\"random\")\n",
    "        \n",
    "    elif mask_strategy == \"spherical\":\n",
    "        logger.info(f\"Applying spherical masks.\")\n",
    "        parameters = mask_init[\"parameters\"]\n",
    "        num_layers = len(merger.merger.model.layers)\n",
    "        init_(merger.merger, strategy=\"spherical\", \n",
    "              parameters=parameters, num_layers=num_layers)\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            f\"Unknown mask initialization strategy: {mask_strategy}.\"\n",
    "        )\n",
    "\n",
    "# _set_masks(merger.merger, strategy=\"uniform\", factors=factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "74de52e2-bc34-4809-8538-85a4b366441e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-01-18 13:19:04,016] [INFO] [train.initialize_masks:50] [PID:124456] [RANK:0] Applying spherical masks.\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up masks: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:24<00:00, 10.56it/s]\n"
     ]
    }
   ],
   "source": [
    "initialize_masks(merger, mask_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c66e7d3e-6fef-4682-b87a-cead1e826d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Merging masked modules: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:02<00:00, 96.26it/s]\n"
     ]
    }
   ],
   "source": [
    "merger.save_merged(\"./test-slerp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7aa38a75-f7cc-47f5-9ed8-ce10536cd3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up masks:   0%|                                                                                                                                                                                        | 0/255 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "module_name, target_module = _set_masks(merger.merger, strategy=\"uniform\", factors=[0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afccc30a-9c39-4232-b9f7-574336eb1151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lm_head',\n",
       " LinearsWithMasks(\n",
       "   (linears): ModuleList(\n",
       "     (0-1): 2 x Linear(in_features=3072, out_features=128256, bias=False)\n",
       "   )\n",
       "   (weight_masks): ModuleList(\n",
       "     (0-1): 2 x Mask(mask_mode=vector_input)\n",
       "   )\n",
       "   (weight_masks_constrainer): Constrainer(constrain_mode=identity)\n",
       "   (bias_masks): ModuleList(\n",
       "     (0-1): 2 x None\n",
       "   )\n",
       "   (bias_masks_constrainer): Constrainer(constrain_mode=identity)\n",
       " ))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module_name, target_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "623d1cb2-7e70-4f05-9725-3783d918ed8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'merger.model.embed_tokens.masks.0.weight': tensor([0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.embed_tokens.masks.1.weight': tensor([0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.q_proj.weight_masks.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.q_proj.weight_masks.1.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.k_proj.weight_masks.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.k_proj.weight_masks.1.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.v_proj.weight_masks.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.v_proj.weight_masks.1.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.o_proj.weight_masks.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.self_attn.o_proj.weight_masks.1.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.mlp.gate_proj.weight_masks.0.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.mlp.gate_proj.weight_masks.1.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.mlp.up_proj.weight_masks.0.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.mlp.up_proj.weight_masks.1.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.mlp.down_proj.weight_masks.0.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.mlp.down_proj.weight_masks.1.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.0.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.q_proj.weight_masks.0.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.q_proj.weight_masks.1.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.k_proj.weight_masks.0.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.k_proj.weight_masks.1.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.v_proj.weight_masks.0.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.v_proj.weight_masks.1.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.o_proj.weight_masks.0.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.self_attn.o_proj.weight_masks.1.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.mlp.gate_proj.weight_masks.0.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.mlp.gate_proj.weight_masks.1.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.mlp.up_proj.weight_masks.0.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.mlp.up_proj.weight_masks.1.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.mlp.down_proj.weight_masks.0.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.mlp.down_proj.weight_masks.1.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.1.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.q_proj.weight_masks.0.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.q_proj.weight_masks.1.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.k_proj.weight_masks.0.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.k_proj.weight_masks.1.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.v_proj.weight_masks.0.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.v_proj.weight_masks.1.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.o_proj.weight_masks.0.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.self_attn.o_proj.weight_masks.1.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.mlp.gate_proj.weight_masks.0.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.mlp.gate_proj.weight_masks.1.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.mlp.up_proj.weight_masks.0.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.mlp.up_proj.weight_masks.1.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.mlp.down_proj.weight_masks.0.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.mlp.down_proj.weight_masks.1.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.2.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.q_proj.weight_masks.0.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.q_proj.weight_masks.1.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.k_proj.weight_masks.0.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.k_proj.weight_masks.1.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.v_proj.weight_masks.0.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.v_proj.weight_masks.1.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.o_proj.weight_masks.0.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.self_attn.o_proj.weight_masks.1.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.mlp.gate_proj.weight_masks.0.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.mlp.gate_proj.weight_masks.1.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.mlp.up_proj.weight_masks.0.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.mlp.up_proj.weight_masks.1.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.mlp.down_proj.weight_masks.0.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.mlp.down_proj.weight_masks.1.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.3.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.q_proj.weight_masks.0.weight': tensor([0.8203, 0.8203, 0.8203,  ..., 0.8203, 0.8203, 0.8203],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.q_proj.weight_masks.1.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.k_proj.weight_masks.0.weight': tensor([0.8203, 0.8203, 0.8203,  ..., 0.8203, 0.8203, 0.8203],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.k_proj.weight_masks.1.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.v_proj.weight_masks.0.weight': tensor([0.8242, 0.8242, 0.8242,  ..., 0.8242, 0.8242, 0.8242],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.v_proj.weight_masks.1.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.o_proj.weight_masks.0.weight': tensor([0.8242, 0.8242, 0.8242,  ..., 0.8242, 0.8242, 0.8242],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.self_attn.o_proj.weight_masks.1.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.mlp.gate_proj.weight_masks.0.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.mlp.gate_proj.weight_masks.1.weight': tensor([0.8203, 0.8203, 0.8203,  ..., 0.8203, 0.8203, 0.8203],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.mlp.up_proj.weight_masks.0.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.mlp.up_proj.weight_masks.1.weight': tensor([0.8242, 0.8242, 0.8242,  ..., 0.8242, 0.8242, 0.8242],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.mlp.down_proj.weight_masks.0.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.mlp.down_proj.weight_masks.1.weight': tensor([0.8242, 0.8242, 0.8242,  ..., 0.8242, 0.8242, 0.8242],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.4.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.q_proj.weight_masks.0.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.q_proj.weight_masks.1.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.k_proj.weight_masks.0.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.k_proj.weight_masks.1.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.v_proj.weight_masks.0.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.v_proj.weight_masks.1.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.o_proj.weight_masks.0.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.self_attn.o_proj.weight_masks.1.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.mlp.gate_proj.weight_masks.0.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.mlp.gate_proj.weight_masks.1.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.mlp.up_proj.weight_masks.0.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.mlp.up_proj.weight_masks.1.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.mlp.down_proj.weight_masks.0.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.mlp.down_proj.weight_masks.1.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.5.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.q_proj.weight_masks.0.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.q_proj.weight_masks.1.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.k_proj.weight_masks.0.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.k_proj.weight_masks.1.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.v_proj.weight_masks.0.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.v_proj.weight_masks.1.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.o_proj.weight_masks.0.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.self_attn.o_proj.weight_masks.1.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.mlp.gate_proj.weight_masks.0.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.mlp.gate_proj.weight_masks.1.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.mlp.up_proj.weight_masks.0.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.mlp.up_proj.weight_masks.1.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.mlp.down_proj.weight_masks.0.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.mlp.down_proj.weight_masks.1.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.6.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.q_proj.weight_masks.0.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.q_proj.weight_masks.1.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.k_proj.weight_masks.0.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.k_proj.weight_masks.1.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.v_proj.weight_masks.0.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.v_proj.weight_masks.1.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.o_proj.weight_masks.0.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.self_attn.o_proj.weight_masks.1.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.mlp.gate_proj.weight_masks.0.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.mlp.gate_proj.weight_masks.1.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.mlp.up_proj.weight_masks.0.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.mlp.up_proj.weight_masks.1.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.mlp.down_proj.weight_masks.0.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.mlp.down_proj.weight_masks.1.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.7.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.q_proj.weight_masks.0.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.q_proj.weight_masks.1.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.k_proj.weight_masks.0.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.k_proj.weight_masks.1.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.v_proj.weight_masks.0.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.v_proj.weight_masks.1.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.o_proj.weight_masks.0.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.self_attn.o_proj.weight_masks.1.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.mlp.gate_proj.weight_masks.0.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.mlp.gate_proj.weight_masks.1.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.mlp.up_proj.weight_masks.0.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.mlp.up_proj.weight_masks.1.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.mlp.down_proj.weight_masks.0.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.mlp.down_proj.weight_masks.1.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.8.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.q_proj.weight_masks.0.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.q_proj.weight_masks.1.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.k_proj.weight_masks.0.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.k_proj.weight_masks.1.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.v_proj.weight_masks.0.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.v_proj.weight_masks.1.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.o_proj.weight_masks.0.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.self_attn.o_proj.weight_masks.1.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.mlp.gate_proj.weight_masks.0.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.mlp.gate_proj.weight_masks.1.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.mlp.up_proj.weight_masks.0.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.mlp.up_proj.weight_masks.1.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.mlp.down_proj.weight_masks.0.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.mlp.down_proj.weight_masks.1.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.9.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.q_proj.weight_masks.0.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.q_proj.weight_masks.1.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.k_proj.weight_masks.0.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.k_proj.weight_masks.1.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.v_proj.weight_masks.0.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.v_proj.weight_masks.1.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.o_proj.weight_masks.0.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.self_attn.o_proj.weight_masks.1.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.mlp.gate_proj.weight_masks.0.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.mlp.gate_proj.weight_masks.1.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.mlp.up_proj.weight_masks.0.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.mlp.up_proj.weight_masks.1.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.mlp.down_proj.weight_masks.0.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.mlp.down_proj.weight_masks.1.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.10.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.q_proj.weight_masks.0.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.q_proj.weight_masks.1.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.k_proj.weight_masks.0.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.k_proj.weight_masks.1.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.v_proj.weight_masks.0.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.v_proj.weight_masks.1.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.o_proj.weight_masks.0.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.self_attn.o_proj.weight_masks.1.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.mlp.gate_proj.weight_masks.0.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.mlp.gate_proj.weight_masks.1.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.mlp.up_proj.weight_masks.0.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.mlp.up_proj.weight_masks.1.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.mlp.down_proj.weight_masks.0.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.mlp.down_proj.weight_masks.1.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.11.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.q_proj.weight_masks.0.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.q_proj.weight_masks.1.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.k_proj.weight_masks.0.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.k_proj.weight_masks.1.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.v_proj.weight_masks.0.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.v_proj.weight_masks.1.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.o_proj.weight_masks.0.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.self_attn.o_proj.weight_masks.1.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.mlp.gate_proj.weight_masks.0.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.mlp.gate_proj.weight_masks.1.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.mlp.up_proj.weight_masks.0.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.mlp.up_proj.weight_masks.1.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.mlp.down_proj.weight_masks.0.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.mlp.down_proj.weight_masks.1.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.12.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.q_proj.weight_masks.0.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.q_proj.weight_masks.1.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.k_proj.weight_masks.0.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.k_proj.weight_masks.1.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.v_proj.weight_masks.0.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.v_proj.weight_masks.1.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.o_proj.weight_masks.0.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.self_attn.o_proj.weight_masks.1.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.mlp.gate_proj.weight_masks.0.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.mlp.gate_proj.weight_masks.1.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.mlp.up_proj.weight_masks.0.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.mlp.up_proj.weight_masks.1.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.mlp.down_proj.weight_masks.0.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.mlp.down_proj.weight_masks.1.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.13.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.q_proj.weight_masks.0.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.q_proj.weight_masks.1.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.k_proj.weight_masks.0.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.k_proj.weight_masks.1.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.v_proj.weight_masks.0.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.v_proj.weight_masks.1.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.o_proj.weight_masks.0.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.self_attn.o_proj.weight_masks.1.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.mlp.gate_proj.weight_masks.0.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.mlp.gate_proj.weight_masks.1.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.mlp.up_proj.weight_masks.0.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.mlp.up_proj.weight_masks.1.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.mlp.down_proj.weight_masks.0.weight': tensor([0.5156, 0.5156, 0.5156,  ..., 0.5156, 0.5156, 0.5156],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.mlp.down_proj.weight_masks.1.weight': tensor([0.4844, 0.4844, 0.4844,  ..., 0.4844, 0.4844, 0.4844],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.14.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.q_proj.weight_masks.0.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.q_proj.weight_masks.1.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.k_proj.weight_masks.0.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.k_proj.weight_masks.1.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.v_proj.weight_masks.0.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.v_proj.weight_masks.1.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.o_proj.weight_masks.0.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.self_attn.o_proj.weight_masks.1.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.mlp.gate_proj.weight_masks.0.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.mlp.gate_proj.weight_masks.1.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.mlp.up_proj.weight_masks.0.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.mlp.up_proj.weight_masks.1.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.mlp.down_proj.weight_masks.0.weight': tensor([0.5430, 0.5430, 0.5430,  ..., 0.5430, 0.5430, 0.5430],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.mlp.down_proj.weight_masks.1.weight': tensor([0.4551, 0.4551, 0.4551,  ..., 0.4551, 0.4551, 0.4551],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.15.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.q_proj.weight_masks.0.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.q_proj.weight_masks.1.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.k_proj.weight_masks.0.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.k_proj.weight_masks.1.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.v_proj.weight_masks.0.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.v_proj.weight_masks.1.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.o_proj.weight_masks.0.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.self_attn.o_proj.weight_masks.1.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.mlp.gate_proj.weight_masks.0.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.mlp.gate_proj.weight_masks.1.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.mlp.up_proj.weight_masks.0.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.mlp.up_proj.weight_masks.1.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.mlp.down_proj.weight_masks.0.weight': tensor([0.5742, 0.5742, 0.5742,  ..., 0.5742, 0.5742, 0.5742],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.mlp.down_proj.weight_masks.1.weight': tensor([0.4258, 0.4258, 0.4258,  ..., 0.4258, 0.4258, 0.4258],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.16.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.q_proj.weight_masks.0.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.q_proj.weight_masks.1.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.k_proj.weight_masks.0.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.k_proj.weight_masks.1.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.v_proj.weight_masks.0.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.v_proj.weight_masks.1.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.o_proj.weight_masks.0.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.self_attn.o_proj.weight_masks.1.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.mlp.gate_proj.weight_masks.0.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.mlp.gate_proj.weight_masks.1.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.mlp.up_proj.weight_masks.0.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.mlp.up_proj.weight_masks.1.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.mlp.down_proj.weight_masks.0.weight': tensor([0.6055, 0.6055, 0.6055,  ..., 0.6055, 0.6055, 0.6055],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.mlp.down_proj.weight_masks.1.weight': tensor([0.3965, 0.3965, 0.3965,  ..., 0.3965, 0.3965, 0.3965],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.17.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.q_proj.weight_masks.0.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.q_proj.weight_masks.1.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.k_proj.weight_masks.0.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.k_proj.weight_masks.1.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.v_proj.weight_masks.0.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.v_proj.weight_masks.1.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.o_proj.weight_masks.0.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.self_attn.o_proj.weight_masks.1.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.mlp.gate_proj.weight_masks.0.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.mlp.gate_proj.weight_masks.1.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.mlp.up_proj.weight_masks.0.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.mlp.up_proj.weight_masks.1.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.mlp.down_proj.weight_masks.0.weight': tensor([0.6328, 0.6328, 0.6328,  ..., 0.6328, 0.6328, 0.6328],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.mlp.down_proj.weight_masks.1.weight': tensor([0.3672, 0.3672, 0.3672,  ..., 0.3672, 0.3672, 0.3672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.18.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.q_proj.weight_masks.0.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.q_proj.weight_masks.1.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.k_proj.weight_masks.0.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.k_proj.weight_masks.1.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.v_proj.weight_masks.0.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.v_proj.weight_masks.1.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.o_proj.weight_masks.0.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.self_attn.o_proj.weight_masks.1.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.mlp.gate_proj.weight_masks.0.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.mlp.gate_proj.weight_masks.1.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.mlp.up_proj.weight_masks.0.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.mlp.up_proj.weight_masks.1.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.mlp.down_proj.weight_masks.0.weight': tensor([0.6641, 0.6641, 0.6641,  ..., 0.6641, 0.6641, 0.6641],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.mlp.down_proj.weight_masks.1.weight': tensor([0.3379, 0.3379, 0.3379,  ..., 0.3379, 0.3379, 0.3379],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.19.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.q_proj.weight_masks.0.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.q_proj.weight_masks.1.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.k_proj.weight_masks.0.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.k_proj.weight_masks.1.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.v_proj.weight_masks.0.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.v_proj.weight_masks.1.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.o_proj.weight_masks.0.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.self_attn.o_proj.weight_masks.1.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.mlp.gate_proj.weight_masks.0.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.mlp.gate_proj.weight_masks.1.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.mlp.up_proj.weight_masks.0.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.mlp.up_proj.weight_masks.1.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.mlp.down_proj.weight_masks.0.weight': tensor([0.6914, 0.6914, 0.6914,  ..., 0.6914, 0.6914, 0.6914],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.mlp.down_proj.weight_masks.1.weight': tensor([0.3066, 0.3066, 0.3066,  ..., 0.3066, 0.3066, 0.3066],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.20.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.q_proj.weight_masks.0.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.q_proj.weight_masks.1.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.k_proj.weight_masks.0.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.k_proj.weight_masks.1.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.v_proj.weight_masks.0.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.v_proj.weight_masks.1.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.o_proj.weight_masks.0.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.self_attn.o_proj.weight_masks.1.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.mlp.gate_proj.weight_masks.0.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.mlp.gate_proj.weight_masks.1.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.mlp.up_proj.weight_masks.0.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.mlp.up_proj.weight_masks.1.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.mlp.down_proj.weight_masks.0.weight': tensor([0.7344, 0.7344, 0.7344,  ..., 0.7344, 0.7344, 0.7344],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.mlp.down_proj.weight_masks.1.weight': tensor([0.2676, 0.2676, 0.2676,  ..., 0.2676, 0.2676, 0.2676],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.21.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.q_proj.weight_masks.0.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.q_proj.weight_masks.1.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.k_proj.weight_masks.0.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.k_proj.weight_masks.1.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.v_proj.weight_masks.0.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.v_proj.weight_masks.1.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.o_proj.weight_masks.0.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.self_attn.o_proj.weight_masks.1.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.mlp.gate_proj.weight_masks.0.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.mlp.gate_proj.weight_masks.1.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.mlp.up_proj.weight_masks.0.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.mlp.up_proj.weight_masks.1.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.mlp.down_proj.weight_masks.0.weight': tensor([0.7773, 0.7773, 0.7773,  ..., 0.7773, 0.7773, 0.7773],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.mlp.down_proj.weight_masks.1.weight': tensor([0.2227, 0.2227, 0.2227,  ..., 0.2227, 0.2227, 0.2227],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.22.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.q_proj.weight_masks.0.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.q_proj.weight_masks.1.weight': tensor([0.8203, 0.8203, 0.8203,  ..., 0.8203, 0.8203, 0.8203],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.k_proj.weight_masks.0.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.k_proj.weight_masks.1.weight': tensor([0.8203, 0.8203, 0.8203,  ..., 0.8203, 0.8203, 0.8203],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.v_proj.weight_masks.0.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.v_proj.weight_masks.1.weight': tensor([0.8203, 0.8203, 0.8203,  ..., 0.8203, 0.8203, 0.8203],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.o_proj.weight_masks.0.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.self_attn.o_proj.weight_masks.1.weight': tensor([0.8242, 0.8242, 0.8242,  ..., 0.8242, 0.8242, 0.8242],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.mlp.gate_proj.weight_masks.0.weight': tensor([0.8203, 0.8203, 0.8203,  ..., 0.8203, 0.8203, 0.8203],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.mlp.gate_proj.weight_masks.1.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.mlp.up_proj.weight_masks.0.weight': tensor([0.8242, 0.8242, 0.8242,  ..., 0.8242, 0.8242, 0.8242],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.mlp.up_proj.weight_masks.1.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.mlp.down_proj.weight_masks.0.weight': tensor([0.8242, 0.8242, 0.8242,  ..., 0.8242, 0.8242, 0.8242],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.mlp.down_proj.weight_masks.1.weight': tensor([0.1777, 0.1777, 0.1777,  ..., 0.1777, 0.1777, 0.1777],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.23.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.q_proj.weight_masks.0.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.q_proj.weight_masks.1.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.k_proj.weight_masks.0.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.k_proj.weight_masks.1.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.v_proj.weight_masks.0.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.v_proj.weight_masks.1.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.o_proj.weight_masks.0.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.self_attn.o_proj.weight_masks.1.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.mlp.gate_proj.weight_masks.0.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.mlp.gate_proj.weight_masks.1.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.mlp.up_proj.weight_masks.0.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.mlp.up_proj.weight_masks.1.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.mlp.down_proj.weight_masks.0.weight': tensor([0.8672, 0.8672, 0.8672,  ..., 0.8672, 0.8672, 0.8672],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.mlp.down_proj.weight_masks.1.weight': tensor([0.1338, 0.1338, 0.1338,  ..., 0.1338, 0.1338, 0.1338],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.24.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.q_proj.weight_masks.0.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.q_proj.weight_masks.1.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.k_proj.weight_masks.0.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.k_proj.weight_masks.1.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.v_proj.weight_masks.0.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.v_proj.weight_masks.1.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.o_proj.weight_masks.0.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.self_attn.o_proj.weight_masks.1.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.mlp.gate_proj.weight_masks.0.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.mlp.gate_proj.weight_masks.1.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.mlp.up_proj.weight_masks.0.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.mlp.up_proj.weight_masks.1.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.mlp.down_proj.weight_masks.0.weight': tensor([0.9102, 0.9102, 0.9102,  ..., 0.9102, 0.9102, 0.9102],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.mlp.down_proj.weight_masks.1.weight': tensor([0.0889, 0.0889, 0.0889,  ..., 0.0889, 0.0889, 0.0889],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.25.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.q_proj.weight_masks.0.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.q_proj.weight_masks.1.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.k_proj.weight_masks.0.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.k_proj.weight_masks.1.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.v_proj.weight_masks.0.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.v_proj.weight_masks.1.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.o_proj.weight_masks.0.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.self_attn.o_proj.weight_masks.1.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.mlp.gate_proj.weight_masks.0.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.mlp.gate_proj.weight_masks.1.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.mlp.up_proj.weight_masks.0.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.mlp.up_proj.weight_masks.1.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.mlp.down_proj.weight_masks.0.weight': tensor([0.9570, 0.9570, 0.9570,  ..., 0.9570, 0.9570, 0.9570],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.mlp.down_proj.weight_masks.1.weight': tensor([0.0444, 0.0444, 0.0444,  ..., 0.0444, 0.0444, 0.0444],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.26.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.q_proj.weight_masks.0.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.q_proj.weight_masks.1.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.k_proj.weight_masks.0.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.k_proj.weight_masks.1.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.v_proj.weight_masks.0.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.v_proj.weight_masks.1.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.o_proj.weight_masks.0.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.self_attn.o_proj.weight_masks.1.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.mlp.gate_proj.weight_masks.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.mlp.gate_proj.weight_masks.1.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.mlp.up_proj.weight_masks.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.mlp.up_proj.weight_masks.1.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.mlp.down_proj.weight_masks.0.weight': tensor([1., 1., 1.,  ..., 1., 1., 1.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.mlp.down_proj.weight_masks.1.weight': tensor([0., 0., 0.,  ..., 0., 0., 0.], dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.input_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.input_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.post_attention_layernorm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.layers.27.post_attention_layernorm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.norm.masks.0.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.model.norm.masks.1.weight': tensor(0.5000, dtype=torch.bfloat16),\n",
       " 'merger.lm_head.weight_masks.0.weight': tensor([0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        dtype=torch.bfloat16),\n",
       " 'merger.lm_head.weight_masks.1.weight': tensor([0.5000, 0.5000, 0.5000,  ..., 0.5000, 0.5000, 0.5000],\n",
       "        dtype=torch.bfloat16)}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.get_masks_state_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merger2",
   "language": "python",
   "name": "merger2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
