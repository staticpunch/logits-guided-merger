{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704792f9-3cf1-4550-9471-5063cd4decd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    PreTrainedModel,\n",
    "    PretrainedConfig,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser\n",
    ")\n",
    "\n",
    "from modeling_qwen2 import (\n",
    "    Qwen2RMSNorm, \n",
    "    Qwen2RotaryEmbedding, \n",
    "    Qwen2MLP, \n",
    "    Qwen2Attention, \n",
    "    Qwen2FlashAttention2, \n",
    "    Qwen2SdpaAttention, \n",
    "    Qwen2DecoderLayer, \n",
    "    Qwen2PreTrainedModel, \n",
    "    Qwen2Model, \n",
    "    Qwen2ForCausalLM,\n",
    ")\n",
    "\n",
    "from configuration_qwen2 import Qwen2Config\n",
    "\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPast,\n",
    ")\n",
    "\n",
    "# Configure logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d4ee96-688d-49da-bd40-9331588e87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_memory():\n",
    "    if not torch.cuda.is_available():\n",
    "        logger.info(\"CUDA is not available. No GPU memory to free.\")\n",
    "        return\n",
    "        \n",
    "    initial_memory = torch.cuda.memory_allocated()\n",
    "    logger.info(f\"Initial GPU memory allocated: {initial_memory / 1024**3:.2f} GB\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    final_memory = torch.cuda.memory_allocated()\n",
    "    logger.info(f\"Final GPU memory allocated: {final_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "    freed_memory = initial_memory - final_memory\n",
    "    logger.info(f\"Freed GPU memory: {freed_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2dd8c3d-92b0-4860-b879-b97fc0d28fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskConfig(PretrainedConfig):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = None,\n",
    "        value: Union[float, torch.Tensor] = None,\n",
    "        size: torch.Size = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.mode = mode\n",
    "        self.value = value\n",
    "        self.size = size\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "class Mask(nn.Module):\n",
    "    def __init__(self, mask_config: MaskConfig):\n",
    "        super().__init__()\n",
    "        self.config = mask_config\n",
    "        self.size = mask_config.size\n",
    "        assert self.size is not None, \"Mask size must be specified.\"\n",
    "\n",
    "        value = mask_config.value\n",
    "        if mask_config.mode == \"scalar\":\n",
    "            self.weight = nn.Parameter(torch.tensor(value if value is not None else 1.0))\n",
    "        elif mask_config.mode in (\"vector_input\", \"vector_output\"):\n",
    "            ones = self._get_ones(mask_config.mode)\n",
    "            self.weight = nn.Parameter(value if value is not None else ones)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported mask mode: {mask_config.mode}\")\n",
    "\n",
    "        self._check_shape_compatibility()\n",
    "\n",
    "    def _get_ones(self, mode: str) -> torch.Tensor:\n",
    "        \"\"\"Generates a tensor of ones based on mode and size.\"\"\"\n",
    "        dim = 0 if mode == \"vector_output\" else -1\n",
    "        features = self.size[dim]\n",
    "        if len(self.size) == 2 and mode == \"vector_output\":\n",
    "            return torch.ones(features, 1)\n",
    "        else:\n",
    "            return torch.ones(features)\n",
    "          \n",
    "\n",
    "    def _check_shape_compatibility(self):\n",
    "        \"\"\"Raises ValueError if the mask shape is incompatible with its size.\"\"\"\n",
    "        try:\n",
    "            in_test = torch.rand(self.size)\n",
    "            out_test = self.weight * in_test\n",
    "            assert out_test.shape == in_test.shape, (\n",
    "                \"After applying mask, the shape of input weight does not stay the same.\"\n",
    "            )\n",
    "        except RuntimeError:\n",
    "            raise ValueError(\"Mask initialized with an incompatible shape.\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.size != x.shape:\n",
    "            logger.warning(\"Warning: Input shape does not match mask shape.\")\n",
    "        return x * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8059dd6e-cfa0-4114-a51f-d933593b424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModuleWithMask(nn.Module, ABC):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ModuleWithMask, self).__init__()\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "class ModulesWithMasks(nn.Module, ABC):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ModulesWithMasks, self).__init__()\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def get_raw_masks(self):\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def get_constrained_masks(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e4b6a32a-c10a-41f0-9bf1-78d6eedb7b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 24\n",
    "out_features = 50\n",
    "lin1 = nn.Linear(in_features, out_features, bias=False)\n",
    "lin2 = nn.Linear(in_features, out_features, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ec2be5cb-d6e3-4580-a0f0-806afe233171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1379, -0.0828,  0.0579,  0.0869, -0.2780,  0.0153,  0.1296, -0.1406,\n",
       "          0.0408, -0.0731, -0.0952,  0.0755, -0.0227,  0.2615, -0.0460,  0.0749,\n",
       "         -0.0550,  0.0341,  0.0937,  0.0736, -0.1101, -0.0626,  0.0726, -0.0169]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 1\n",
    "a = lin1.weight.data * lin2.weight.data\n",
    "torch.sum(a, dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "60cf8162-ea40-4e1e-8a3a-3dfcb9adf39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1379)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lin1.weight.data[:, 0] * lin2.weight.data[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f83d33e8-d308-4a15-82a7-9a676febe4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1848,  0.1494,  0.1646,  ..., -0.0032, -0.0555, -0.1466],\n",
       "         [-0.1290, -0.0756, -0.0223,  ..., -0.1856,  0.0470, -0.0283],\n",
       "         [-0.1999, -0.1282, -0.0962,  ..., -0.0889, -0.0963, -0.1632],\n",
       "         ...,\n",
       "         [-0.0054, -0.0114,  0.0129,  ..., -0.0470,  0.0084,  0.1470],\n",
       "         [-0.1827, -0.1948, -0.1714,  ..., -0.0504,  0.1090, -0.1485],\n",
       "         [-0.0404,  0.1018, -0.0064,  ..., -0.1330,  0.0322, -0.0790]]),\n",
       " tensor([ 0.1848,  0.1494,  0.1646, -0.0410, -0.1585, -0.0646,  0.1476, -0.0333,\n",
       "         -0.1931, -0.1558, -0.1577, -0.1567,  0.2007, -0.0615,  0.0303, -0.1447,\n",
       "         -0.1068,  0.1688,  0.0174, -0.1891, -0.0137, -0.0032, -0.0555, -0.1466]),\n",
       " tensor([ 0.1848, -0.1290, -0.1999,  0.0977,  0.1508, -0.1669, -0.0660,  0.1283,\n",
       "         -0.0557,  0.1243,  0.0842, -0.0416, -0.1729, -0.1151,  0.1024,  0.0945,\n",
       "          0.0715, -0.0120, -0.1028,  0.0120, -0.0981,  0.0432,  0.1506,  0.0452,\n",
       "          0.1851, -0.0963,  0.1388,  0.0774, -0.1656,  0.0938,  0.2018, -0.1231,\n",
       "          0.0242,  0.1211,  0.1525, -0.0254,  0.0521, -0.1891,  0.0185,  0.1966,\n",
       "         -0.1704, -0.0166, -0.0395, -0.0886, -0.0032, -0.1650,  0.1343, -0.0054,\n",
       "         -0.1827, -0.0404]))"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = lin1.weight.data\n",
    "v, v[0, :], v[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d329c31b-08d9-4d50-9bef-da7ee09b361d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8753])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(5) * torch.rand(5)\n",
    "torch.sum(a, dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5bf6b1f5-34c2-4812-ae2a-bcfb1ebe8665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5828, 0.3854, 0.0289, 0.7288, 0.4752])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.rand(5))\n",
    "torch.relu(torch.rand(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "43bc25b5-8ae5-4c2f-a63c-ad62474f8308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3835, 1.7104, 1.0538, 1.0995, 1.5433])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.rand(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "0a25d893-65ed-4a1c-8838-bcb49653ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constrainer(nn.Module):\n",
    "    \"\"\"\n",
    "    Take as input modules to calculate statistics.\n",
    "    Forward method takes as input mask weights.\n",
    "    If modules are Linears, need to take care of \n",
    "    \"\"\"\n",
    "    def __init__(self, component_weights, constrain_mode):\n",
    "        super().__init__()\n",
    "        self.statistics = None\n",
    "        self.constrain_mode = constrain_mode\n",
    "        if (self.constrain_mode == \"spherical\" and \n",
    "            all([w is not None for w in component_weights])):\n",
    "            \n",
    "            assert len(component_weights) == 2, (\n",
    "                \"Spherical constraint (SLERP) only supports 2 component weights\"\n",
    "            )\n",
    "            self.dots = torch.sum(component_weights[0] * component_weights[1], dim=0, keepdim=True)\n",
    "            self.theta_0s = torch.arccos(self.dots)\n",
    "            self.sin_theta_0s = torch.sin(sin.theta_0s)\n",
    "        \n",
    "    def forward(self, mask_weights: List[torch.Tensor]):\n",
    "        if any([w is None for w in mask_weights]):\n",
    "            return mask_weights\n",
    "            \n",
    "        if self.constrain_mode == \"identity\":\n",
    "            return mask_weights\n",
    "        elif self.constrain_mode == \"01\":\n",
    "            mask_weights = [torch.exp(w) for w in mask_weights]\n",
    "            mask_weights = [w / sum(mask_weights) for w in mask_weights]\n",
    "            return mask_weights\n",
    "        elif self.constrain_mode == \"-11\":\n",
    "            return mask_weights\n",
    "        elif self.constrain_mode == \"spherical\":\n",
    "            \"\"\" Reference implementation\n",
    "            # Calculate initial angle between v0 and v1\n",
    "            theta_0 = np.arccos(dot)\n",
    "            sin_theta_0 = np.sin(theta_0)\n",
    "        \n",
    "            # Angle at timestep t\n",
    "            theta_t = theta_0 * t\n",
    "            sin_theta_t = np.sin(theta_t)\n",
    "        \n",
    "            # Finish the slerp algorithm\n",
    "            s0 = np.sin(theta_0 - theta_t) / sin_theta_0\n",
    "            s1 = sin_theta_t / sin_theta_0\n",
    "            \"\"\"\n",
    "            assert len(mask_weights) == 2, (\n",
    "                \"Spherical constraint (SLERP) only supports 2 mask weights\"\n",
    "            )\n",
    "            mask_weights = [torch.exp(w) for w in mask_weights]\n",
    "            ts = mask_weights[0] / sum(mask_weights)\n",
    "            # mask_weights = [w / sum(mask_weights) for w in mask_weights]\n",
    "            \n",
    "            # sin_theta_0s = torch.sin(self.theta_0s)\n",
    "\n",
    "            # Angle at timestep t\n",
    "            theta_ts = self.theta_0s * ts\n",
    "            sin_theta_ts = torch.sin(theta_ts)\n",
    "\n",
    "            # Finish calculating slerp factors\n",
    "            S0 = torch.sin(self.theta_0s - theta_ts) / self.sin_theta_0s\n",
    "            S1 = sin_theta_ts / self.sin_theta_0s\n",
    "            return [S0, S1]\n",
    "        else:\n",
    "            raise ValueError(f\"Does not support {self.constrain_mode} constraint yet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "1425bfa1-26eb-4976-b03d-5f2841d9922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearsWithMasks(ModulesWithMasks):\n",
    "    def __init__(\n",
    "        self,\n",
    "        linears: List[nn.Linear],\n",
    "        weight_modes: List[str] = [\"scalar\"],\n",
    "        weight_values: List[float] = None,\n",
    "        bias_modes: List[str] = [\"scalar\"],\n",
    "        bias_values: List[float] = None,\n",
    "        constrain_mode: str = \"identity\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if not all(isinstance(linear, nn.Linear) for linear in linears):\n",
    "            raise ValueError(\"All elements in 'linears' must be instances of nn.Linear.\")\n",
    "\n",
    "        if weight_values is None or len(weight_values) != len(linears):\n",
    "            raise ValueError(\n",
    "                f\"weight_values for masks: {weight_values} do not match with linear layers: {linears}\"\n",
    "            )\n",
    "        if bias_values is None:\n",
    "            bias_values = [None] * len(linears)\n",
    "        if len(bias_values) != len(linears):\n",
    "            raise ValueError(\n",
    "                f\"bias_values for masks: {bias_values} do not match with linear layers: {linears}\"\n",
    "            )\n",
    "\n",
    "        self.linears = nn.ModuleList(linears)\n",
    "        self.constrain_mode = constrain_mode\n",
    "\n",
    "        self.weight_masks = nn.ModuleList([\n",
    "            Mask(MaskConfig(mode, value, linear.weight.shape))\n",
    "            for mode, value, linear in zip(weight_modes, weight_values, linears)\n",
    "        ])\n",
    "        self.weight_masks_constrainer = Constrainer(\n",
    "            component_weights=[x.weight for x in linears],\n",
    "            constrain_mode=constrain_mode\n",
    "        )\n",
    "\n",
    "        self.bias_masks = nn.ModuleList([\n",
    "            Mask(MaskConfig(mode, value, linear.bias.shape)) if linear.bias is not None else None\n",
    "            for mode, value, linear in zip(bias_modes, bias_values, linears)\n",
    "        ])\n",
    "        self.bias_masks_constrainer = Constrainer(\n",
    "            component_weights=[x.bias if x.bias is not None else None for x in linears],\n",
    "            constrain_mode=constrain_mode\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        constrained_weight_masks = self.weight_masks_constrainer(\n",
    "            [mask.weight for mask in self.weight_masks]\n",
    "        )\n",
    "        weights = [\n",
    "            weight_mask * linear.weight for weight_mask, linear\n",
    "            in zip(constrained_weight_masks, self.linears)\n",
    "        ]\n",
    "        merged_weight = sum(weights)\n",
    "\n",
    "        constrained_bias_masks = self.bias_masks_constrainer([\n",
    "            mask.weight if mask is not None else None for mask in self.bias_masks\n",
    "        ])\n",
    "        biases = [\n",
    "            bias_mask * linear.bias if linear.bias is not None and bias_mask is not None\n",
    "            else linear.bias for bias_mask, linear in zip(constrained_bias_masks, self.linears)\n",
    "        ]\n",
    "\n",
    "        if all(b is None for b in biases):\n",
    "            merged_bias = None\n",
    "        else:\n",
    "            merged_bias = sum(\n",
    "                b if b is not None \n",
    "                else torch.zeros_like(merged_weight[:, 0])\n",
    "                for b in biases\n",
    "            )\n",
    "\n",
    "        return nn.functional.linear(x, merged_weight, merged_bias)\n",
    "\n",
    "    def get_raw_masks(self):\n",
    "        with torch.no_grad():\n",
    "            return dict(\n",
    "                weight_masks=[m.weight for m in self.weight_masks],\n",
    "                bias_masks=[m.weight if m is not None else None for m in self.bias_masks]\n",
    "            )\n",
    "        \n",
    "    def get_constrained_masks(self):\n",
    "        with torch.no_grad():\n",
    "            constrained_weight_masks = self.weight_masks_constrainer(\n",
    "                [mask.weight for mask in self.weight_masks]\n",
    "            )\n",
    "            constrained_bias_masks = self.bias_masks_constrainer([\n",
    "                mask.weight if mask is not None else None for mask in self.bias_masks\n",
    "            ])\n",
    "            return dict(\n",
    "                weight_masks=constrained_weight_masks,\n",
    "                bias_masks=constrained_bias_masks\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1f21e766-fc6e-48ba-92e5-c1753508cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from masks import LinearsWithMasks as LinearsWithMasksRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e31231ae-8f67-4a88-8347-a47493eec4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slerp(\n",
    "    t: Union[float, np.ndarray],\n",
    "    v0: Union[np.ndarray, torch.Tensor],\n",
    "    v1: Union[np.ndarray, torch.Tensor],\n",
    "    DOT_THRESHOLD: float = 0.9995,\n",
    "    eps: float = 1e-8,\n",
    "):\n",
    "    \"\"\"\n",
    "    Spherical linear interpolation\n",
    "\n",
    "    From: https://gist.github.com/dvschultz/3af50c40df002da3b751efab1daddf2c\n",
    "    Args:\n",
    "        t (float/np.ndarray): Float value between 0.0 and 1.0\n",
    "        v0 (np.ndarray): Starting vector\n",
    "        v1 (np.ndarray): Final vector\n",
    "        DOT_THRESHOLD (float): Threshold for considering the two vectors as\n",
    "                               colinear. Not recommended to alter this.\n",
    "    Returns:\n",
    "        v2 (np.ndarray): Interpolation vector between v0 and v1\n",
    "    \"\"\"\n",
    "    is_torch = False\n",
    "    if not isinstance(v0, np.ndarray):\n",
    "        is_torch = True\n",
    "        v0 = v0.detach().cpu().float().numpy()\n",
    "    if not isinstance(v1, np.ndarray):\n",
    "        is_torch = True\n",
    "        v1 = v1.detach().cpu().float().numpy()\n",
    "\n",
    "    # Copy the vectors to reuse them later\n",
    "    v0_copy = np.copy(v0)\n",
    "    v1_copy = np.copy(v1)\n",
    "\n",
    "    # Normalize the vectors to get the directions and angles\n",
    "    v0 = normalize(v0, eps)\n",
    "    v1 = normalize(v1, eps)\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "\n",
    "    # Dot product with the normalized vectors (can't use np.dot in W)\n",
    "    dot = np.sum(v0 * v1)\n",
    "\n",
    "    # If absolute value of dot product is almost 1, vectors are ~colinear, so use lerp\n",
    "    if np.abs(dot) > DOT_THRESHOLD:\n",
    "        res = lerp(t, v0_copy, v1_copy)\n",
    "        return maybe_torch(res, is_torch)\n",
    "\n",
    "    # Calculate initial angle between v0 and v1\n",
    "    theta_0 = np.arccos(dot)\n",
    "    sin_theta_0 = np.sin(theta_0)\n",
    "\n",
    "    # Angle at timestep t\n",
    "    theta_t = theta_0 * t\n",
    "    sin_theta_t = np.sin(theta_t)\n",
    "\n",
    "    # Finish the slerp algorithm\n",
    "    s0 = np.sin(theta_0 - theta_t) / sin_theta_0\n",
    "    s1 = sin_theta_t / sin_theta_0\n",
    "    return [dot, theta_0, theta_t, s0, s1]\n",
    "\n",
    "def maybe_torch(v: np.ndarray, is_torch: bool):\n",
    "    if is_torch:\n",
    "        return torch.from_numpy(v)\n",
    "    return v\n",
    "\n",
    "\n",
    "def normalize(v: np.ndarray, eps: float):\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    if norm_v > eps:\n",
    "        v = v / norm_v\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "2dc8baed-8c75-4abc-8343-4feac4673dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 20\n",
    "output_size = 40\n",
    "num_components = 2\n",
    "\n",
    "linears_with_bias = [nn.Linear(input_size, output_size, bias=True) for _ in range(num_components)]\n",
    "# Test without bias\n",
    "linears_without_bias = [nn.Linear(input_size, output_size, bias=False) for _ in range(num_components)]\n",
    "\n",
    "x = torch.rand(1, input_size)\n",
    "\n",
    "# for _ in range(10):  # Reduced number of iterations for faster testing\n",
    "weight_values = np.random.rand(num_components).tolist()\n",
    "weight_values = [None] * num_components\n",
    "bias_values = np.random.rand(num_components).tolist()\n",
    "bias_values = [None] * num_components\n",
    "\n",
    "# Test with bias\n",
    "masked_linears = LinearsWithMasks(\n",
    "    linears=linears_without_bias,\n",
    "    weight_modes=[\"vector_input\"] * num_components,\n",
    "    weight_values=weight_values,\n",
    "    bias_modes=[\"vector_input\"] * num_components,\n",
    "    bias_values=bias_values,\n",
    "    constrain_mode = \"spherical\"\n",
    ")\n",
    "\n",
    "# masked_linears_ref = LinearsWithMasksRef(\n",
    "#     linears=linears_without_bias,\n",
    "#     weight_modes=[\"vector_input\"] * num_components,\n",
    "#     weight_values=weight_values,\n",
    "#     bias_modes=[\"vectovector_inputr_input\"] * num_components,\n",
    "#     bias_values=bias_values,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "665b2c07-bbc3-4ad0-b2ee-f3f6af73cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.testing.assert_close(masked_linears(x), masked_linears_ref(x), atol=0, rtol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "00de16dc-7aa1-4597-95b5-47e64c27499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_linears(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "55e55022-99a6-41b8-a979-db0304789da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000,\n",
      "        0.5000, 0.5000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'weight_masks': [tensor([[0.6948, 0.6881, 0.7260, 0.6823, 0.6489, 0.7358, 0.7699, 0.7335, 0.7475,\n",
       "           0.7471, 0.6594, 0.6986, 0.6972, 0.6598, 0.6798, 0.7235, 0.7175, 0.6985,\n",
       "           0.6656, 0.7163]]),\n",
       "  tensor([[0.6948, 0.6881, 0.7260, 0.6823, 0.6489, 0.7358, 0.7699, 0.7335, 0.7475,\n",
       "           0.7471, 0.6594, 0.6986, 0.6972, 0.6598, 0.6798, 0.7235, 0.7175, 0.6985,\n",
       "           0.6656, 0.7163]])],\n",
       " 'bias_masks': [None, None]}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_linears.get_constrained_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a5e6f60d-5e02-4a31-84a5-674959436655",
   "metadata": {},
   "outputs": [],
   "source": [
    "constrainer = Constrainer(\n",
    "    component_weights=[x.weight for x in linears_without_bias],\n",
    "    constrain_mode=\"spherical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "da00371c-8e37-43f1-b77d-a9f650190191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5351, 1.5148, 1.6222, 1.4966, 1.3822, 1.6472, 1.7280, 1.6415, 1.6763,\n",
       "         1.6751, 1.4201, 1.5464, 1.5423, 1.4216, 1.4887, 1.6157, 1.5995, 1.5459,\n",
       "         1.4420, 1.5964]], grad_fn=<AcosBackward0>)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constrainer.theta_0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "d05127fe-5ada-41c1-a4c7-16eb88ac54ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0357,  0.0559, -0.0514,  0.0741,  0.1875, -0.0764, -0.1565, -0.0706,\n",
       "         -0.1053, -0.1041,  0.1501,  0.0244,  0.0285,  0.1487,  0.0820, -0.0448,\n",
       "         -0.0287,  0.0249,  0.1285, -0.0256]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "constrainer.dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "1c96f4e4-8dae-41ee-b4db-afda02f79a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float32(-0.033729836),\n",
       " np.float32(1.6045326),\n",
       " np.float32(0.8022663),\n",
       " np.float32(0.7193425),\n",
       " np.float32(0.7193425)]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v0 = linears_without_bias[0].weight.data[:, -1]\n",
    "v1 = linears_without_bias[1].weight.data[:, -1]\n",
    "slerp(\n",
    "    0.5, v0, v1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "8f851f1d-dc4c-4c91-bf97-db962ad5ca86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0657)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(v0 * v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8b467aee-2521-4aa7-8b71-f3d2a4a1a920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0900, -0.1653,  0.2175, -0.0066, -0.1509,  0.1738, -0.2021,  0.0056,\n",
       "          0.0747,  0.0987,  0.0641, -0.1328, -0.2082,  0.0532, -0.0573, -0.0543,\n",
       "         -0.1366,  0.1805,  0.1399,  0.0938]),\n",
       " tensor([-0.0444,  0.1529,  0.1763, -0.1462,  0.1757,  0.0038, -0.1280, -0.0950,\n",
       "          0.1156, -0.0166, -0.1705,  0.1983,  0.0292,  0.1613, -0.0939, -0.0343,\n",
       "          0.0375,  0.2133,  0.0792, -0.1354]))"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linears_without_bias[1].weight.data[1], linears_without_bias[0].weight.data[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merger2",
   "language": "python",
   "name": "merger2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
