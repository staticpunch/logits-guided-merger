{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704792f9-3cf1-4550-9471-5063cd4decd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    PreTrainedModel,\n",
    "    PretrainedConfig,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser\n",
    ")\n",
    "\n",
    "from modeling_qwen2 import (\n",
    "    Qwen2RMSNorm, \n",
    "    Qwen2RotaryEmbedding, \n",
    "    Qwen2MLP, \n",
    "    Qwen2Attention, \n",
    "    Qwen2FlashAttention2, \n",
    "    Qwen2SdpaAttention, \n",
    "    Qwen2DecoderLayer, \n",
    "    Qwen2PreTrainedModel, \n",
    "    Qwen2Model, \n",
    "    Qwen2ForCausalLM,\n",
    ")\n",
    "\n",
    "from configuration_qwen2 import Qwen2Config\n",
    "\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPast,\n",
    ")\n",
    "\n",
    "# Configure logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9d4ee96-688d-49da-bd40-9331588e87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_memory():\n",
    "    if not torch.cuda.is_available():\n",
    "        logger.info(\"CUDA is not available. No GPU memory to free.\")\n",
    "        return\n",
    "        \n",
    "    initial_memory = torch.cuda.memory_allocated()\n",
    "    logger.info(f\"Initial GPU memory allocated: {initial_memory / 1024**3:.2f} GB\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    final_memory = torch.cuda.memory_allocated()\n",
    "    logger.info(f\"Final GPU memory allocated: {final_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "    freed_memory = initial_memory - final_memory\n",
    "    logger.info(f\"Freed GPU memory: {freed_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2dd8c3d-92b0-4860-b879-b97fc0d28fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskConfig(PretrainedConfig):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = None,\n",
    "        value: Union[float, torch.Tensor] = None,\n",
    "        size: torch.Size = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.mode = mode\n",
    "        self.value = value\n",
    "        self.size = size\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "class Mask(nn.Module):\n",
    "    def __init__(self, mask_config: MaskConfig):\n",
    "        super().__init__()\n",
    "        self.config = mask_config\n",
    "        self.size = mask_config.size\n",
    "        assert self.size is not None, \"Mask size must be specified.\"\n",
    "\n",
    "        value = mask_config.value\n",
    "        if mask_config.mode == \"scalar\":\n",
    "            self.weight = nn.Parameter(torch.tensor(value if value is not None else 1.0))\n",
    "        elif mask_config.mode in (\"vector_input\", \"vector_output\"):\n",
    "            ones = self._get_ones(mask_config.mode)\n",
    "            self.weight = nn.Parameter(value if value is not None else ones)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported mask mode: {mask_config.mode}\")\n",
    "\n",
    "        self._check_shape_compatibility()\n",
    "\n",
    "    def _get_ones(self, mode: str) -> torch.Tensor:\n",
    "        \"\"\"Generates a tensor of ones based on mode and size.\"\"\"\n",
    "        dim = 0 if mode == \"vector_output\" else -1\n",
    "        features = self.size[dim]\n",
    "        if len(self.size) == 2 and mode == \"vector_output\":\n",
    "            return torch.ones(features, 1)\n",
    "        else:\n",
    "            return torch.ones(features)\n",
    "          \n",
    "\n",
    "    def _check_shape_compatibility(self):\n",
    "        \"\"\"Raises ValueError if the mask shape is incompatible with its size.\"\"\"\n",
    "        try:\n",
    "            in_test = torch.rand(self.size)\n",
    "            out_test = self.weight * in_test\n",
    "            assert out_test.shape == in_test.shape, (\n",
    "                \"After applying mask, the shape of input weight does not stay the same.\"\n",
    "            )\n",
    "        except RuntimeError:\n",
    "            raise ValueError(\"Mask initialized with an incompatible shape.\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.size != x.shape:\n",
    "            logger.warning(\"Warning: Input shape does not match mask shape.\")\n",
    "        return x * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8059dd6e-cfa0-4114-a51f-d933593b424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModuleWithMask(nn.Module, ABC):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ModuleWithMask, self).__init__()\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "class ModulesWithMasks(nn.Module, ABC):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ModulesWithMasks, self).__init__()\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def get_raw_masks(self):\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def get_constrained_masks(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "e4b6a32a-c10a-41f0-9bf1-78d6eedb7b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = 24\n",
    "out_features = 50\n",
    "lin1 = nn.Linear(in_features, out_features, bias=False)\n",
    "lin2 = nn.Linear(in_features, out_features, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "ec2be5cb-d6e3-4580-a0f0-806afe233171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1379, -0.0828,  0.0579,  0.0869, -0.2780,  0.0153,  0.1296, -0.1406,\n",
       "          0.0408, -0.0731, -0.0952,  0.0755, -0.0227,  0.2615, -0.0460,  0.0749,\n",
       "         -0.0550,  0.0341,  0.0937,  0.0736, -0.1101, -0.0626,  0.0726, -0.0169]])"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = 1\n",
    "a = lin1.weight.data * lin2.weight.data\n",
    "torch.sum(a, dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "60cf8162-ea40-4e1e-8a3a-3dfcb9adf39a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1379)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(lin1.weight.data[:, 0] * lin2.weight.data[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f83d33e8-d308-4a15-82a7-9a676febe4b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 24])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = lin1.weight.data\n",
    "v, v[0, :], v[:, 0]\n",
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d329c31b-08d9-4d50-9bef-da7ee09b361d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8753])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(5) * torch.rand(5)\n",
    "torch.sum(a, dim=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5bf6b1f5-34c2-4812-ae2a-bcfb1ebe8665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5828, 0.3854, 0.0289, 0.7288, 0.4752])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sigmoid(torch.rand(5))\n",
    "torch.relu(torch.rand(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "43bc25b5-8ae5-4c2f-a63c-ad62474f8308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.3835, 1.7104, 1.0538, 1.0995, 1.5433])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(torch.rand(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "0da3c9dc-14a9-4866-bc6a-2cae4bc58c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4680, 2.0391, 2.2767, 1.5416])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(4, 10)\n",
    "torch.linalg.norm(t, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "0a25d893-65ed-4a1c-8838-bcb49653ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Constrainer(nn.Module):\n",
    "    \"\"\"\n",
    "    Take as input modules to calculate statistics.\n",
    "    Forward method takes as input mask weights.\n",
    "    If modules are Linears, need to take care of \n",
    "    \"\"\"\n",
    "    def __init__(self, component_weights, constrain_mode):\n",
    "        super().__init__()\n",
    "        self.statistics = None\n",
    "        self.constrain_mode = constrain_mode\n",
    "        if (self.constrain_mode == \"spherical\" and all([w is not None for w in component_weights])):\n",
    "            assert len(component_weights) == 2, (\n",
    "                \"Spherical constraint (SLERP) only supports 2 component weights\"\n",
    "            )\n",
    "\n",
    "            v0 = self._normalize(v=component_weights[0], dim=0)\n",
    "            v1 = self._normalize(v=component_weights[1], dim=0)\n",
    "            self.dots = torch.sum(v0 * v1, dim=0, keepdim=True) ## (out_features, in_features) -> (1, in_features)\n",
    "            self.theta_0s = torch.arccos(self.dots)\n",
    "            self.sin_theta_0s = torch.sin(self.theta_0s)\n",
    "\n",
    "    def _normalize(self, v, dim, eps: float = 1e-8):\n",
    "        norm_v = torch.linalg.norm(v, dim=dim)\n",
    "        norm_v[norm_v < eps] = 1.0\n",
    "        v = v / norm_v\n",
    "        return v\n",
    "\n",
    "    def _constrain_identity(self, mask_weights: List[torch.Tensor]):\n",
    "        return mask_weights\n",
    "\n",
    "    def _constrain_0_1(self, mask_weights: List[torch.Tensor]):\n",
    "        mask_weights = [torch.exp(w) for w in mask_weights]\n",
    "        mask_weights = [w / sum(mask_weights) for w in mask_weights]\n",
    "        return mask_weights\n",
    "\n",
    "    def _constrain_neg1_1(self, mask_weights: List[torch.Tensor]):\n",
    "        return mask_weights\n",
    "\n",
    "    def _constrain_spherical(self, mask_weights: List[torch.Tensor]):\n",
    "        assert len(mask_weights) == 2, (\n",
    "            \"Spherical constraint (SLERP) only supports 2 mask weights\"\n",
    "        )\n",
    "        # Transform raw masks to factor t's.\n",
    "        mask_weights = [torch.exp(w) for w in mask_weights]\n",
    "        ts = mask_weights[0] / sum(mask_weights)\n",
    "\n",
    "        # Angle at timestep t\n",
    "        theta_ts = self.theta_0s * ts\n",
    "        sin_theta_ts = torch.sin(theta_ts)\n",
    "\n",
    "        # Finish calculating slerp factors\n",
    "        S0 = torch.sin(self.theta_0s - theta_ts) / self.sin_theta_0s\n",
    "        S1 = sin_theta_ts / self.sin_theta_0s\n",
    "        \n",
    "        return [S0, S1]\n",
    "        \n",
    "    def forward(self, mask_weights: List[torch.Tensor]):\n",
    "        if any([w is None for w in mask_weights]):\n",
    "            return mask_weights\n",
    "            \n",
    "        if self.constrain_mode == \"identity\":\n",
    "            return self._constrain_identity(mask_weights)\n",
    "        elif self.constrain_mode == \"01\":\n",
    "            return self._constrain_0_1(mask_weights)\n",
    "        elif self.constrain_mode == \"-11\":\n",
    "            return self._constrain_neg1_1(mask_weights)\n",
    "        elif self.constrain_mode == \"spherical\":\n",
    "            return self._constrain_spherical(mask_weights)\n",
    "        else:\n",
    "            raise ValueError(f\"Does not support {self.constrain_mode} constraint yet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "1425bfa1-26eb-4976-b03d-5f2841d9922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearsWithMasks(ModulesWithMasks):\n",
    "    def __init__(\n",
    "        self,\n",
    "        linears: List[nn.Linear],\n",
    "        weight_modes: List[str] = None,\n",
    "        weight_values: List[float] = None,\n",
    "        bias_modes: List[str] = None,\n",
    "        bias_values: List[float] = None,\n",
    "        constrain_mode: str = \"identity\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if not all(isinstance(linear, nn.Linear) for linear in linears):\n",
    "            raise ValueError(\"All elements in 'linears' must be instances of nn.Linear.\")\n",
    "\n",
    "        if weight_values is None or len(weight_values) != len(linears):\n",
    "            raise ValueError(\n",
    "                f\"Weight values for masks: {weight_values} do not match with linear layers: {linears}\"\n",
    "            )\n",
    "        if bias_values is None:\n",
    "            bias_values = [None] * len(linears)\n",
    "        if len(bias_values) != len(linears):\n",
    "            raise ValueError(\n",
    "                f\"Bias values for masks: {bias_values} do not match with linear layers: {linears}\"\n",
    "            )\n",
    "\n",
    "        self.linears = nn.ModuleList(linears)\n",
    "        self.constrain_mode = constrain_mode\n",
    "\n",
    "        self.weight_masks = nn.ModuleList([\n",
    "            Mask(MaskConfig(mode, value, linear.weight.shape))\n",
    "            for mode, value, linear in zip(weight_modes, weight_values, linears)\n",
    "        ])\n",
    "        \n",
    "        self.weight_masks_constrainer = Constrainer(\n",
    "            component_weights=[x.weight for x in self.linears], constrain_mode=constrain_mode\n",
    "        )\n",
    "\n",
    "        self.bias_masks = nn.ModuleList([\n",
    "            Mask(MaskConfig(mode, value, linear.bias.shape)) if linear.bias is not None else None\n",
    "            for mode, value, linear in zip(bias_modes, bias_values, linears)\n",
    "        ])\n",
    "        \n",
    "        self.bias_masks_constrainer = Constrainer(\n",
    "            component_weights=[x.bias if x.bias is not None else None for x in self.linears],\n",
    "            constrain_mode=constrain_mode,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        constrained_weight_masks = self.weight_masks_constrainer([m.weight for m in self.weight_masks])\n",
    "        weights = [\n",
    "            w_mask * linear.weight for w_mask, linear in zip(constrained_weight_masks, self.linears)\n",
    "        ]\n",
    "        merged_weight = sum(weights)\n",
    "\n",
    "        constrained_bias_masks = self.bias_masks_constrainer(\n",
    "            [m.weight if m is not None else None for m in self.bias_masks]\n",
    "        )\n",
    "        biases = [\n",
    "            b_mask * linear.bias if linear.bias is not None and b_mask is not None else linear.bias\n",
    "            for b_mask, linear in zip(constrained_bias_masks, self.linears)\n",
    "        ]\n",
    "\n",
    "        merged_bias = (\n",
    "            sum(b if b is not None else torch.zeros_like(merged_weight[:, 0]) for b in biases)\n",
    "            if not all(b is None for b in biases)\n",
    "            else None\n",
    "        )\n",
    "\n",
    "        return nn.functional.linear(x, merged_weight, merged_bias)\n",
    "\n",
    "    def get_raw_masks(self):\n",
    "        with torch.no_grad():\n",
    "            return {\n",
    "                \"weight_masks\": [m.weight for m in self.weight_masks],\n",
    "                \"bias_masks\": [m.weight if m is not None else None for m in self.bias_masks],\n",
    "            }\n",
    "\n",
    "    def get_constrained_masks(self):\n",
    "        with torch.no_grad():\n",
    "            constrained_weight_masks = self.weight_masks_constrainer(\n",
    "                [m.weight for m in self.weight_masks]\n",
    "            )\n",
    "            constrained_bias_masks = self.bias_masks_constrainer(\n",
    "                [m.weight if m is not None else None for m in self.bias_masks]\n",
    "            )\n",
    "            return {\n",
    "                \"weight_masks\": constrained_weight_masks,\n",
    "                \"bias_masks\": constrained_bias_masks,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1f21e766-fc6e-48ba-92e5-c1753508cddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from masks import LinearsWithMasks as LinearsWithMasksRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "e31231ae-8f67-4a88-8347-a47493eec4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slerp(\n",
    "    t: Union[float, np.ndarray],\n",
    "    v0: Union[np.ndarray, torch.Tensor],\n",
    "    v1: Union[np.ndarray, torch.Tensor],\n",
    "    DOT_THRESHOLD: float = 0.9995,\n",
    "    eps: float = 1e-8,\n",
    "):\n",
    "    \"\"\"\n",
    "    Spherical linear interpolation\n",
    "\n",
    "    From: https://gist.github.com/dvschultz/3af50c40df002da3b751efab1daddf2c\n",
    "    Args:\n",
    "        t (float/np.ndarray): Float value between 0.0 and 1.0\n",
    "        v0 (np.ndarray): Starting vector\n",
    "        v1 (np.ndarray): Final vector\n",
    "        DOT_THRESHOLD (float): Threshold for considering the two vectors as\n",
    "                               colinear. Not recommended to alter this.\n",
    "    Returns:\n",
    "        v2 (np.ndarray): Interpolation vector between v0 and v1\n",
    "    \"\"\"\n",
    "    is_torch = False\n",
    "    if not isinstance(v0, np.ndarray):\n",
    "        is_torch = True\n",
    "        v0 = v0.detach().cpu().float().numpy()\n",
    "    if not isinstance(v1, np.ndarray):\n",
    "        is_torch = True\n",
    "        v1 = v1.detach().cpu().float().numpy()\n",
    "\n",
    "    # Copy the vectors to reuse them later\n",
    "    v0_copy = np.copy(v0)\n",
    "    v1_copy = np.copy(v1)\n",
    "\n",
    "    # Normalize the vectors to get the directions and angles\n",
    "    v0 = normalize(v0, eps)\n",
    "    v1 = normalize(v1, eps)\n",
    "    # import ipdb; ipdb.set_trace()\n",
    "\n",
    "    # Dot product with the normalized vectors (can't use np.dot in W)\n",
    "    dot = np.sum(v0 * v1)\n",
    "\n",
    "    # If absolute value of dot product is almost 1, vectors are ~colinear, so use lerp\n",
    "    if np.abs(dot) > DOT_THRESHOLD:\n",
    "        res = lerp(t, v0_copy, v1_copy)\n",
    "        return maybe_torch(res, is_torch)\n",
    "\n",
    "    # Calculate initial angle between v0 and v1\n",
    "    theta_0 = np.arccos(dot)\n",
    "    sin_theta_0 = np.sin(theta_0)\n",
    "\n",
    "    # Angle at timestep t\n",
    "    theta_t = theta_0 * t\n",
    "    sin_theta_t = np.sin(theta_t)\n",
    "\n",
    "    # Finish the slerp algorithm\n",
    "    s0 = np.sin(theta_0 - theta_t) / sin_theta_0\n",
    "    s1 = sin_theta_t / sin_theta_0\n",
    "    return [s0, s1]\n",
    "    # return [dot, theta_0, theta_t, s0, s1]\n",
    "\n",
    "def maybe_torch(v: np.ndarray, is_torch: bool):\n",
    "    if is_torch:\n",
    "        return torch.from_numpy(v)\n",
    "    return v\n",
    "\n",
    "\n",
    "def normalize(v: np.ndarray, eps: float):\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    if norm_v > eps:\n",
    "        v = v / norm_v\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "2dc8baed-8c75-4abc-8343-4feac4673dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 20\n",
    "output_size = 40\n",
    "num_components = 2\n",
    "\n",
    "linears_with_bias = [nn.Linear(input_size, output_size, bias=True) for _ in range(num_components)]\n",
    "# Test without bias\n",
    "linears_without_bias = [nn.Linear(input_size, output_size, bias=False) for _ in range(num_components)]\n",
    "\n",
    "x = torch.rand(1, input_size)\n",
    "\n",
    "# for _ in range(10):  # Reduced number of iterations for faster testing\n",
    "weight_values = np.random.rand(num_components).tolist()\n",
    "weight_values = [None] * num_components\n",
    "bias_values = np.random.rand(num_components).tolist()\n",
    "bias_values = [None] * num_components\n",
    "\n",
    "# Test with bias\n",
    "masked_linears = LinearsWithMasks(\n",
    "    linears=linears_without_bias,\n",
    "    weight_modes=[\"vector_input\"] * num_components,\n",
    "    weight_values=weight_values,\n",
    "    bias_modes=[\"vector_input\"] * num_components,\n",
    "    bias_values=bias_values,\n",
    "    constrain_mode = \"spherical\"\n",
    ")\n",
    "\n",
    "# masked_linears_ref = LinearsWithMasksRef(\n",
    "#     linears=linears_without_bias,\n",
    "#     weight_modes=[\"vector_input\"] * num_components,\n",
    "#     weight_values=weight_values,\n",
    "#     bias_modes=[\"vectovector_inputr_input\"] * num_components,\n",
    "#     bias_values=bias_values,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "665b2c07-bbc3-4ad0-b2ee-f3f6af73cfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.testing.assert_close(masked_linears(x), masked_linears_ref(x), atol=0, rtol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "00de16dc-7aa1-4597-95b5-47e64c27499f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# masked_linears(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "55e55022-99a6-41b8-a979-db0304789da0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight_masks': [tensor([[0.7016, 0.7169, 0.6246, 0.8854, 0.8869, 0.6671, 0.6055, 0.6743, 0.9067,\n",
       "           0.6699, 0.7139, 0.6198, 0.7296, 0.9081, 0.6037, 0.7482, 0.7769, 0.6714,\n",
       "           0.7849, 0.6778]]),\n",
       "  tensor([[0.7016, 0.7169, 0.6246, 0.8854, 0.8869, 0.6671, 0.6055, 0.6743, 0.9067,\n",
       "           0.6699, 0.7139, 0.6198, 0.7296, 0.9081, 0.6037, 0.7482, 0.7769, 0.6714,\n",
       "           0.7849, 0.6778]])],\n",
       " 'bias_masks': [None, None]}"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_linears.get_constrained_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a5e6f60d-5e02-4a31-84a5-674959436655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constrainer = Constrainer(\n",
    "#     component_weights=[x.weight for x in linears_without_bias],\n",
    "#     constrain_mode=\"spherical\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "1c96f4e4-8dae-41ee-b4db-afda02f79a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float32(0.7848908), np.float32(0.7848908)]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v0 = linears_without_bias[0].weight.data[:, -2]\n",
    "v1 = linears_without_bias[1].weight.data[:, -2]\n",
    "slerp(\n",
    "    0.5, v0, v1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "970990f6-c4e4-41ed-a68e-1aec6703697f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "8f851f1d-dc4c-4c91-bf97-db962ad5ca86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.False_"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(v0 * v1).data.numpy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "fe68d20c-05e1-4210-85a9-04ad0201f845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(-0.025634324)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(v0.numpy() * v1.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "8b467aee-2521-4aa7-8b71-f3d2a4a1a920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0900, -0.1653,  0.2175, -0.0066, -0.1509,  0.1738, -0.2021,  0.0056,\n",
       "          0.0747,  0.0987,  0.0641, -0.1328, -0.2082,  0.0532, -0.0573, -0.0543,\n",
       "         -0.1366,  0.1805,  0.1399,  0.0938]),\n",
       " tensor([-0.0444,  0.1529,  0.1763, -0.1462,  0.1757,  0.0038, -0.1280, -0.0950,\n",
       "          0.1156, -0.0166, -0.1705,  0.1983,  0.0292,  0.1613, -0.0939, -0.0343,\n",
       "          0.0375,  0.2133,  0.0792, -0.1354]))"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linears_without_bias[1].weight.data[1], linears_without_bias[0].weight.data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80b5b96-0e76-46d3-a10e-84e122386f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merger2",
   "language": "python",
   "name": "merger2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
