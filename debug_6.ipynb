{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704792f9-3cf1-4550-9471-5063cd4decd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    PreTrainedModel,\n",
    "    PretrainedConfig,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser\n",
    ")\n",
    "\n",
    "from transformers import (\n",
    "    HfArgumentParser,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "\n",
    "# from modeling_qwen2 import (\n",
    "#     Qwen2RMSNorm, \n",
    "#     Qwen2RotaryEmbedding, \n",
    "#     Qwen2MLP, \n",
    "#     Qwen2Attention, \n",
    "#     Qwen2FlashAttention2, \n",
    "#     Qwen2SdpaAttention, \n",
    "#     Qwen2DecoderLayer, \n",
    "#     Qwen2PreTrainedModel, \n",
    "#     Qwen2Model, \n",
    "#     Qwen2ForCausalLM,\n",
    "# )\n",
    "\n",
    "from configuration_qwen2 import Qwen2Config\n",
    "\n",
    "from transformers.modeling_outputs import (\n",
    "    BaseModelOutputWithPast,\n",
    "    CausalLMOutputWithPast\n",
    ")\n",
    "\n",
    "# Configure logger\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7a1e57c-cc69-4cf0-9502-ab38783d3e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_smol = load_dataset(\"HuggingFaceTB/smoltalk\", \"smol-rewrite\", split=\"test\")\n",
    "summarize_smol = load_dataset(\"HuggingFaceTB/smoltalk\", \"smol-summarize\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df7eb11-e92c-45ff-a9bd-6dfbb0c7b1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_train = load_dataset(\"HuggingFaceTB/smoltalk\", \"smol-rewrite\", split=\"train\")\n",
    "summarize_train = load_dataset(\"HuggingFaceTB/smoltalk\", \"smol-summarize\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e250c23-2d2e-40c9-96ad-8ecda02fc701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.listdir(\"/workspace/HUB_LLM/091224_llama3_70b/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e953732a-ae0d-4300-823f-6b034760b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig, TextStreamer\n",
    "def generate(prompt, model, tokenizer, max_new_tokens=1024):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\")[\"input_ids\"].to(model.device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        generation_config = GenerationConfig(\n",
    "            repetition_penalty=1.13,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=0.4,\n",
    "            top_p=0.95,\n",
    "            # top_k=20,\n",
    "            # bos_token_id=tokenizer.bos_token_id,\n",
    "            # eos_token_id=tokenizer.eos_token_id,\n",
    "            # eos_token_id=0, # for open-end generation.\n",
    "            eos_token_id=[128001, 128009],\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            do_sample=False,\n",
    "            use_cache=True,\n",
    "            return_dict_in_generate=True,\n",
    "            output_attentions=False,\n",
    "            output_hidden_states=False,\n",
    "            output_scores=False,\n",
    "        )\n",
    "        streamer = TextStreamer(tokenizer, skip_prompt=True)\n",
    "        generated = model.generate(\n",
    "            inputs=input_ids,\n",
    "            generation_config=generation_config,\n",
    "            streamer=streamer,\n",
    "        )\n",
    "    gen_tokens = generated[\"sequences\"].cpu()[:, len(input_ids[0]):]\n",
    "    output = tokenizer.batch_decode(gen_tokens)[0]\n",
    "    output = output.split(tokenizer.eos_token)[0]\n",
    "    return output.strip()\n",
    "\n",
    "def get_logits(text, model, tokenizer):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(**input_ids).logits\n",
    "    return logits\n",
    "\n",
    "def get_hidden_states(text, model, tokenizer):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\").to(model.device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_ids, output_hidden_states=True, use_cache=False)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9d4ee96-688d-49da-bd40-9331588e87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def free_memory():\n",
    "    if not torch.cuda.is_available():\n",
    "        logger.info(\"CUDA is not available. No GPU memory to free.\")\n",
    "        return\n",
    "        \n",
    "    initial_memory = torch.cuda.memory_allocated()\n",
    "    logger.info(f\"Initial GPU memory allocated: {initial_memory / 1024**3:.2f} GB\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    final_memory = torch.cuda.memory_allocated()\n",
    "    logger.info(f\"Final GPU memory allocated: {final_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "    freed_memory = initial_memory - final_memory\n",
    "    logger.info(f\"Freed GPU memory: {freed_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2dd8c3d-92b0-4860-b879-b97fc0d28fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskConfig(PretrainedConfig):\n",
    "    def __init__(\n",
    "        self,\n",
    "        mode: str = None,\n",
    "        value: Union[float, torch.Tensor] = None,\n",
    "        size: torch.Size = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.mode = mode\n",
    "        self.value = value\n",
    "        self.size = size\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "class Mask(nn.Module):\n",
    "    def __init__(self, mask_config: MaskConfig):\n",
    "        super().__init__()\n",
    "        self.config = mask_config\n",
    "        self.size = mask_config.size\n",
    "        assert self.size is not None, \"Mask size must be specified.\"\n",
    "\n",
    "        value = mask_config.value\n",
    "        if value is not None:\n",
    "            logger.warning(\"Highly reccommend initializing mask value using dedicated setup functions.\")\n",
    "            if not isinstance(value, torch.Tensor): \n",
    "                try: value = torch.tensor(value)\n",
    "                except: raise ValueError(\n",
    "                    f\"Unable to convert {value} to torch.Tensor required for initializing a mask's weight.\"\n",
    "                )\n",
    "\n",
    "        ## TODO: might refactor later: modify _get_ones() to handle scalar mode.\n",
    "        if mask_config.mode == \"scalar\":\n",
    "            self.weight = nn.Parameter(value if value is not None else torch.tensor(1.0))\n",
    "            \n",
    "        elif mask_config.mode in (\"vector_input\", \"vector_output\"):\n",
    "            ones = self._get_ones(mask_config.mode)\n",
    "            self.weight = nn.Parameter(value if value is not None else ones)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported mask mode: {mask_config.mode}\")\n",
    "\n",
    "        self._check_shape_compatibility()\n",
    "\n",
    "    def _get_ones(self, mode: str) -> torch.Tensor:\n",
    "        \"\"\"Generates a tensor of ones based on mode and size.\"\"\"\n",
    "        dim = 0 if mode == \"vector_output\" else -1\n",
    "        features = self.size[dim]\n",
    "        if len(self.size) == 2 and mode == \"vector_output\":\n",
    "            return torch.ones(features, 1)\n",
    "        else:\n",
    "            return torch.ones(features)\n",
    "          \n",
    "\n",
    "    def _check_shape_compatibility(self):\n",
    "        \"\"\"Raises ValueError if the mask shape is incompatible with its size.\"\"\"\n",
    "        try:\n",
    "            in_test = torch.rand(self.size)\n",
    "            out_test = self.weight * in_test\n",
    "            assert out_test.shape == in_test.shape, (\n",
    "                \"After applying mask, the shape of input weight does not stay the same.\"\n",
    "            )\n",
    "        except RuntimeError:\n",
    "            raise ValueError(\"Mask initialized with an incompatible shape.\")\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.size != x.shape:\n",
    "            logger.warning(\"Warning: Input shape does not match mask shape.\")\n",
    "        return x * self.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8059dd6e-cfa0-4114-a51f-d933593b424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModuleWithMask(nn.Module, ABC):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ModuleWithMask, self).__init__()\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "class ModulesWithMasks(nn.Module, ABC):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(ModulesWithMasks, self).__init__()\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def get_raw_masks(self):\n",
    "        pass\n",
    "        \n",
    "    @abstractmethod\n",
    "    def get_constrained_masks(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb194d9c-95ab-44f0-bbdd-ecbfed06dcab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def relu_01(x: torch.Tensor) -> torch.Tensor:\n",
    "    return F.relu(x) - F.relu(x - 1.0)\n",
    "\n",
    "relu_01(torch.tensor(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ccbb0e-a42f-46b3-8830-180d61eff426",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a25d893-65ed-4a1c-8838-bcb49653ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def silu_01(x: torch.Tensor) -> torch.Tensor:\n",
    "    return F.silu(x) - F.silu(x - 1.0)\n",
    "\n",
    "def relu_01(x: torch.Tensor) -> torch.Tensor:\n",
    "    return F.relu(x) - F.relu(x - 1.0)\n",
    "\n",
    "def normalize(v, dim, eps: float = 1e-8):\n",
    "    norm_v = torch.linalg.norm(v, dim=dim)\n",
    "    norm_v[norm_v < eps] = 1.0\n",
    "    v = v / norm_v\n",
    "    return v\n",
    "\n",
    "class Constrainer(nn.Module):\n",
    "\n",
    "    def __init__(self, component_weights, constrain_mode, mask_mode):\n",
    "        super().__init__()\n",
    "        self.statistics = None\n",
    "        self.constrain_mode = constrain_mode\n",
    "        self.mask_mode = mask_mode\n",
    "        if self.constrain_mode not in (\"identity\", \"01\", \"-11\", \"spherical\", \"sum1\"):\n",
    "            raise ValueError(f\"Does not support {self.constrain_mode} constraint yet!\")\n",
    "            \n",
    "        if (self.constrain_mode == \"spherical\" and all([w is not None for w in component_weights])):\n",
    "            self._get_spherical_stats(component_weights)\n",
    "\n",
    "    def _get_spherical_stats(\n",
    "        self, \n",
    "        component_weights: List[torch.Tensor], \n",
    "        DOT_THRESHOLD: float = 0.99995\n",
    "    ):\n",
    "        with torch.no_grad():\n",
    "            if any([w is None for w in component_weights]):\n",
    "                raise ValueError(\"Spherical constraint (SLERP) does not support None weights.\")\n",
    "            if len(component_weights) != 2: \n",
    "                raise ValueError(\n",
    "                    \"Spherical constraint (SLERP) only supports 2 component weights, \" +\n",
    "                    f\"{len(component_weights)} components found.\"\n",
    "                )\n",
    "\n",
    "            \n",
    "            dim = 0 if self.mask_mode in (\"vector_input\") else None\n",
    "            v0 = normalize(component_weights[0], dim=dim)\n",
    "            v1 = normalize(component_weights[1], dim=dim)\n",
    "            self.dots = torch.sum(v0 * v1, dim=dim, keepdim=False) ## (out_features, in_features) -> (in_features, )\n",
    "            self.theta_0s = torch.arccos(self.dots)\n",
    "            self.sin_theta_0s = torch.sin(self.theta_0s)\n",
    "        \n",
    "    def _constrain_identity(self, mask_weights: List[torch.Tensor]):\n",
    "        return mask_weights\n",
    "\n",
    "    def _constrain_sumone(self, mask_weights: List[torch.Tensor]):\n",
    "        W = [w / sum(mask_weights) for w in mask_weights]\n",
    "        return W\n",
    "\n",
    "    def _constrain_0_1(self, mask_weights: List[torch.Tensor]):\n",
    "        W = [torch.sigmoid(w) for w in mask_weights]\n",
    "        return W\n",
    "\n",
    "    def _constrain_neg1_1(self, mask_weights: List[torch.Tensor]):\n",
    "        return mask_weights\n",
    "\n",
    "    def _constrain_spherical(self, mask_weights: List[torch.Tensor], DOT_THRESHOLD: float = 0.9995):\n",
    "        assert len(mask_weights) == 2, (\n",
    "            \"Spherical constraint (SLERP) only supports 2 mask weights\"\n",
    "        )\n",
    "        \n",
    "        # Transform raw masks to factor t's.\n",
    "        ## QUESTION MASK: Does this modify mask_weights in-place? I only \n",
    "        ## update them via backprop.\n",
    "        # W = [torch.exp(w) for w in mask_weights]\n",
    "        # T = W[0] / sum(W)\n",
    "\n",
    "        ## ignore mask_weights[1]\n",
    "        T = silu_01(mask_weights[0])\n",
    "\n",
    "        # Angle at timestep t's\n",
    "        theta_ts = self.theta_0s * T\n",
    "        sin_theta_ts = torch.sin(theta_ts)\n",
    "\n",
    "        # Finish calculating slerp factors\n",
    "        S0 = torch.sin(self.theta_0s - theta_ts) / self.sin_theta_0s\n",
    "        S1 = sin_theta_ts / self.sin_theta_0s\n",
    "\n",
    "        # Avoid NaN\n",
    "        nan_indices = self.dots.float() > DOT_THRESHOLD\n",
    "        S0[nan_indices] = 1 - T[nan_indices]\n",
    "        S1[nan_indices] = T[nan_indices]\n",
    "        \n",
    "        return [S0, S1]\n",
    "        \n",
    "    def forward(self, mask_weights: List[torch.Tensor]):\n",
    "        if any([w is None for w in mask_weights]):\n",
    "            return mask_weights\n",
    "            \n",
    "        if self.constrain_mode == \"identity\":\n",
    "            return self._constrain_identity(mask_weights)\n",
    "        elif self.constrain_mode == \"01\":\n",
    "            return self._constrain_0_1(mask_weights)\n",
    "        elif self.constrain_mode == \"-11\":\n",
    "            return self._constrain_neg1_1(mask_weights)\n",
    "        elif self.constrain_mode == \"sum1\":\n",
    "            return self._constrain_sumone(mask_weights)\n",
    "        elif self.constrain_mode == \"spherical\":\n",
    "            return self._constrain_spherical(mask_weights)\n",
    "        else:\n",
    "            raise ValueError(f\"Does not support {self.constrain_mode} constraint yet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1425bfa1-26eb-4976-b03d-5f2841d9922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearsWithMasks(ModulesWithMasks):\n",
    "    def __init__(\n",
    "        self,\n",
    "        linears: List[nn.Linear],\n",
    "        weight_modes: List[str] = None,\n",
    "        weight_values: List[float] = None,\n",
    "        bias_modes: List[str] = None,\n",
    "        bias_values: List[float] = None,\n",
    "        constrain_mode: str = \"identity\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if not all(isinstance(linear, nn.Linear) for linear in linears):\n",
    "            raise ValueError(\"All elements in 'linears' must be instances of nn.Linear.\")\n",
    "\n",
    "        if weight_values is None or len(weight_values) != len(linears):\n",
    "            raise ValueError(\n",
    "                f\"Weight values for masks: {weight_values} do not match with linear layers: {linears}\"\n",
    "            )\n",
    "        if bias_values is None:\n",
    "            bias_values = [None] * len(linears)\n",
    "        if len(bias_values) != len(linears):\n",
    "            raise ValueError(\n",
    "                f\"Bias values for masks: {bias_values} do not match with linear layers: {linears}\"\n",
    "            )\n",
    "\n",
    "        self.linears = nn.ModuleList(linears)\n",
    "        self.constrain_mode = constrain_mode\n",
    "\n",
    "        self.weight_masks = nn.ModuleList([\n",
    "            Mask(MaskConfig(mode, value, linear.weight.shape))\n",
    "            for mode, value, linear in zip(weight_modes, weight_values, linears)\n",
    "        ])\n",
    "        \n",
    "        self.weight_masks_constrainer = Constrainer(\n",
    "            component_weights=[x.weight for x in self.linears], \n",
    "            constrain_mode=constrain_mode, mask_mode=weight_modes[0]\n",
    "        )\n",
    "\n",
    "        self.bias_masks = nn.ModuleList([\n",
    "            Mask(MaskConfig(mode, value, linear.bias.shape)) if linear.bias is not None else None\n",
    "            for mode, value, linear in zip(bias_modes, bias_values, linears)\n",
    "        ])\n",
    "        \n",
    "        self.bias_masks_constrainer = Constrainer(\n",
    "            component_weights=[x.bias if x.bias is not None else None for x in self.linears],\n",
    "            constrain_mode=constrain_mode, mask_mode=bias_modes[0]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        constrained_weight_masks = self.weight_masks_constrainer([m.weight for m in self.weight_masks])\n",
    "        masked_weights = [\n",
    "            w_mask * linear.weight for w_mask, linear in zip(constrained_weight_masks, self.linears)\n",
    "        ]\n",
    "        merged_weight = sum(masked_weights)\n",
    "\n",
    "        constrained_bias_masks = self.bias_masks_constrainer(\n",
    "            [m.weight if m is not None else None for m in self.bias_masks]\n",
    "        )\n",
    "        masked_biases = [\n",
    "            b_mask * linear.bias if linear.bias is not None and b_mask is not None else linear.bias\n",
    "            for b_mask, linear in zip(constrained_bias_masks, self.linears)\n",
    "        ]\n",
    "\n",
    "        merged_bias = (\n",
    "            sum(b if b is not None else torch.zeros_like(merged_weight[:, 0]) for b in masked_biases)\n",
    "            if not all(b is None for b in masked_biases) else None\n",
    "        )\n",
    "\n",
    "        return nn.functional.linear(x, merged_weight, merged_bias)\n",
    "\n",
    "    def get_raw_masks(self):\n",
    "        with torch.no_grad():\n",
    "            return {\n",
    "                \"weight_masks\": [m.weight for m in self.weight_masks],\n",
    "                \"bias_masks\": [m.weight if m is not None else None for m in self.bias_masks],\n",
    "            }\n",
    "\n",
    "    def get_constrained_masks(self):\n",
    "        with torch.no_grad():\n",
    "            constrained_weight_masks = self.weight_masks_constrainer(\n",
    "                [m.weight for m in self.weight_masks]\n",
    "            )\n",
    "            constrained_bias_masks = self.bias_masks_constrainer(\n",
    "                [m.weight if m is not None else None for m in self.bias_masks]\n",
    "            )\n",
    "            return {\n",
    "                \"weight_masks\": constrained_weight_masks,\n",
    "                \"bias_masks\": constrained_bias_masks,\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e80b5b96-0e76-46d3-a10e-84e122386f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNormsWithMasks(ModulesWithMasks):\n",
    "    def __init__(\n",
    "        self,\n",
    "        rms_norms: List[nn.Module],\n",
    "        modes: List[str] = None,\n",
    "        values: List[float] = None,\n",
    "        constrain_mode: str = \"identity\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        sizes = [norm.weight.shape for norm in rms_norms]\n",
    "        if any([mode != \"scalar\" for mode in modes]):\n",
    "            logger.warning(\n",
    "                f\"Though you want to make a masks of modes {modes} \" + \\\n",
    "                \"for RMSNorms' weights, by default a mask only accepts a scalar mask. \" + \\\n",
    "                \"Converting modes to `scalar`.\"\n",
    "            )\n",
    "            modes = [\"scalar\"] * len(modes)\n",
    "            \n",
    "        if values is None or len(values) != len(rms_norms):\n",
    "            raise ValueError(f\"values for masks: {values} do not match with RMSNorm layers: {rms_norms}\")\n",
    "\n",
    "        self.rms_norms = nn.ModuleList(rms_norms)\n",
    "        self.masks = nn.ModuleList([\n",
    "            Mask(MaskConfig(mode, value, norm.weight.shape))\n",
    "            for mode, value, norm in zip(modes, values, rms_norms)\n",
    "        ])\n",
    "        self.masks_constrainer = Constrainer(\n",
    "            component_weights=[norm.weight for norm in self.rms_norms], \n",
    "            constrain_mode=constrain_mode, mask_mode=modes[0]\n",
    "        )\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        constrained_masks = self.masks_constrainer([m.weight for m in self.masks])\n",
    "        masked_weights = [mask * norm.weight for mask, norm in zip(constrained_masks, self.rms_norms)]\n",
    "        merged_weight = sum(masked_weights)\n",
    "        variance_epsilon = self.rms_norms[0].variance_epsilon\n",
    "        for norm in self.rms_norms:\n",
    "            assert variance_epsilon == norm.variance_epsilon, (\"Variance epsilon among models must be consistent\")\n",
    "        input_dtype = hidden_states.dtype\n",
    "        hidden_states = hidden_states.to(torch.float32)\n",
    "        variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
    "        hidden_states = hidden_states * torch.rsqrt(variance + variance_epsilon)\n",
    "        return merged_weight * hidden_states.to(input_dtype)\n",
    "\n",
    "    def get_raw_masks(self):\n",
    "        with torch.no_grad():\n",
    "            return {\"masks\": [m.weight for m in self.masks]}\n",
    "\n",
    "    def get_constrained_masks(self):\n",
    "        with torch.no_grad():\n",
    "            constrained_masks = self.masks_constrainer([m.weight for m in self.masks])\n",
    "            return {\"masks\": constrained_masks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "462f8ba9-7b19-449a-98c6-59d470820b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsWithMasks(ModulesWithMasks):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embeddings: List[nn.Embedding],\n",
    "        modes: List[str] = None,\n",
    "        values: List[float] = None,\n",
    "        constrain_mode: str = \"identity\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        if values is None or len(values) != len(embeddings):\n",
    "            raise ValueError(f\"values for masks: {values} do not match with Embedding layers: {embeddings}\")\n",
    "\n",
    "        self.embeddings = nn.ModuleList(embeddings)\n",
    "        sizes = [emb.weight.shape for emb in embeddings]\n",
    "        self.masks = nn.ModuleList([\n",
    "            Mask(MaskConfig(mode, value, size))\n",
    "            for mode, value, size in zip(modes, values, sizes)\n",
    "        ])\n",
    "        self.masks_constrainer = Constrainer(\n",
    "            component_weights=[emb.weight for emb in self.embeddings], \n",
    "            constrain_mode=constrain_mode, mask_mode=modes[0]\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        constrained_masks = self.masks_constrainer([m.weight for m in self.masks])\n",
    "        masked_weights = [mask * emb.weight for mask, emb in zip(constrained_masks, self.embeddings)]\n",
    "        merged_weight = sum(masked_weights)\n",
    "        \n",
    "        an_embedding = self.embeddings[0]\n",
    "        for other_embedding in self.embeddings:\n",
    "            assert an_embedding.padding_idx == other_embedding.padding_idx\n",
    "            assert an_embedding.max_norm == other_embedding.max_norm\n",
    "            assert an_embedding.norm_type == other_embedding.norm_type\n",
    "            assert an_embedding.scale_grad_by_freq == other_embedding.scale_grad_by_freq\n",
    "            assert an_embedding.sparse == other_embedding.sparse\n",
    "            \n",
    "        return nn.functional.embedding(\n",
    "            input_ids,\n",
    "            merged_weight,\n",
    "            padding_idx=an_embedding.padding_idx,\n",
    "            max_norm=an_embedding.max_norm,\n",
    "            norm_type=an_embedding.norm_type,\n",
    "            scale_grad_by_freq=an_embedding.scale_grad_by_freq,\n",
    "            sparse=an_embedding.sparse,\n",
    "        )\n",
    "        \n",
    "    def get_raw_masks(self):\n",
    "        with torch.no_grad():\n",
    "            return {\"masks\": [m.weight for m in self.masks]}\n",
    "\n",
    "    def get_constrained_masks(self):\n",
    "        with torch.no_grad():\n",
    "            constrained_masks = self.masks_constrainer([m.weight for m in self.masks])\n",
    "            return {\"masks\": constrained_masks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7657c75d-74c7-4c89-a070-47f541588d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def odd_one_out(masked_module: nn.Module, selected_idx: int):  \n",
    "    assert selected_idx is not None and isinstance(selected_idx, int), (\n",
    "        \"Must provide valid model index. Check whether passed index is `int`\"\n",
    "    )\n",
    "    masks_modules = []\n",
    "    for name, child in masked_module.named_children():\n",
    "        if not isinstance(child, nn.ModuleList): continue\n",
    "        assert selected_idx < len(child), (\n",
    "            f\"There are only {len(child)} component models, passed model index is {selected_idx}\"\n",
    "        )\n",
    "        ## exclude sub_module that is None, aka bias_masks.\n",
    "        if all(isinstance(sub_module, Mask) for sub_module in child):\n",
    "            masks_modules.append(child)\n",
    "        \n",
    "    for masks in masks_modules:\n",
    "        for i, mask in enumerate(masks):\n",
    "            value = 1.0 if i == selected_idx else 0.0\n",
    "            with torch.no_grad():\n",
    "                mask.weight.data.fill_(value)\n",
    "\n",
    "def random_init(masked_module: nn.Module):\n",
    "    masks_modules = []\n",
    "    for name, child in masked_module.named_children():\n",
    "        if not isinstance(child, nn.ModuleList): continue\n",
    "        ## exclude sub_module that is None, aka bias_masks.\n",
    "        if all(isinstance(sub_module, Mask) for sub_module in child):\n",
    "            masks_modules.append(child)\n",
    "        \n",
    "    for masks in masks_modules:\n",
    "        for i, mask in enumerate(masks):\n",
    "            with torch.no_grad():\n",
    "                random_value = torch.rand_like(mask.weight.data)\n",
    "                mask.weight.data = random_value\n",
    "\n",
    "def uniform_init(masked_module: nn.Module, factors: List[float]):  \n",
    "    masks_modules = []\n",
    "    for name, child in masked_module.named_children():\n",
    "        if not isinstance(child, nn.ModuleList): continue\n",
    "        assert len(factors) == len(child), (\n",
    "            f\"There are {len(child)} component models, but your passed factors have {len(factors)} values.\"\n",
    "        )\n",
    "        ## exclude sub_module that is None, aka bias_masks.\n",
    "        if all(isinstance(sub_module, Mask) for sub_module in child):\n",
    "            masks_modules.append(child)\n",
    "\n",
    "    for masks in masks_modules:\n",
    "        for factor, mask in zip(factors, masks):\n",
    "            with torch.no_grad():\n",
    "                mask.weight.data.fill_(factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f062b07f-a3cb-4e17-a3e8-71474dafb17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_masked_modules(module):\n",
    "    masked_module_names = []\n",
    "    for parent_name, parent_module in module.named_modules():\n",
    "        for name, child in parent_module.named_children():\n",
    "            full_child_name = f\"{parent_name}.{name}\" if parent_name else name\n",
    "            if (\"WithMasks\" in type(child).__name__):\n",
    "                masked_module_names.append(full_child_name)\n",
    "\n",
    "    return masked_module_names\n",
    "\n",
    "def get_init_method(strategy):\n",
    "    MAP = {\n",
    "        \"random\": random_init,\n",
    "        \"odd_one_out\": odd_one_out,\n",
    "        \"uniform\": uniform_init\n",
    "    }\n",
    "    selected_init_method = MAP[strategy]\n",
    "    \n",
    "    return selected_init_method\n",
    "    \n",
    "def set_masks(root_module, strategy=\"random\", **kwargs):\n",
    "\n",
    "    init_method = get_init_method(strategy)\n",
    "    masked_module_names = find_masked_modules(root_module)\n",
    "    \n",
    "    for module_name in tqdm(masked_module_names, desc=\"Setting up masks\"):\n",
    "        module_names = module_name.split(\".\")\n",
    "        target_module = root_module\n",
    "        for m_name in module_names:\n",
    "            target_module = getattr(target_module, m_name)\n",
    "\n",
    "        init_method(target_module, **kwargs)\n",
    "\n",
    "def set_constrainers(root_module, constrain_mode, **kwargs):\n",
    "    if constrain_mode not in (\"identity\", \"01\", \"-11\", \"spherical\"):\n",
    "        raise ValueError(f\"Does not support {self.constrain_mode} constraint yet!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb6846b2-893e-4006-8d82-49053c805e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MergerConfig(PretrainedConfig):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_paths: List[str] = None,\n",
    "        mode: str = None,\n",
    "        constrain_mode: str = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.model_paths = model_paths\n",
    "        self.mode = mode\n",
    "        self.constrain_mode = constrain_mode\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "class Merger(PreTrainedModel):\n",
    "    def __init__(self, merge_config):\n",
    "        super().__init__(merge_config)\n",
    "        \"\"\"\n",
    "        Need to check whether models are mergeable (having some sort of the same config)\n",
    "        \"\"\"\n",
    "        self.merge_config = merge_config\n",
    "        self.num_models = len(merge_config.model_paths)\n",
    "        self.configs = [\n",
    "            AutoConfig.from_pretrained(path) \n",
    "            # Qwen2Config.from_pretrained(path)\n",
    "            for path in merge_config.model_paths\n",
    "        ]\n",
    "        # self.merger = Qwen2ForCausalLM(self.config)\n",
    "        self.models = nn.ModuleList([\n",
    "            # Qwen2ForCausalLM.from_pretrained(\n",
    "            AutoModelForCausalLM.from_pretrained(\n",
    "                merge_config.model_paths[i], \n",
    "                config=self.configs[i],\n",
    "                torch_dtype=torch.bfloat16\n",
    "            ) \n",
    "            for i in range(self.num_models)\n",
    "        ])\n",
    "        # self.__post_init__(merge_config)\n",
    "        \n",
    "    def __post_init__(self):\n",
    "        for model in self.models:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        self.merger = copy.deepcopy(self.models[0])\n",
    "        init_masks(\n",
    "            self.merger, self.models, self.merge_config\n",
    "        )\n",
    "        free_memory()\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: torch.LongTensor = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        past_key_values: Optional[List[torch.FloatTensor]] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        use_cache: Optional[bool] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "        cache_position: Optional[torch.LongTensor] = None,\n",
    "        num_logits_to_keep: int = 0,\n",
    "        **loss_kwargs,\n",
    "    ) -> Union[Tuple, CausalLMOutputWithPast]:\n",
    "        output_attentions = output_attentions if output_attentions is not None else True\n",
    "        output_hidden_states = (\n",
    "            output_hidden_states if output_hidden_states is not None else True\n",
    "        )\n",
    "        return_dict = return_dict if return_dict is not None else True\n",
    "\n",
    "        # decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\n",
    "        inputs = dict(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            past_key_values=past_key_values,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            use_cache=use_cache,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "            cache_position=cache_position,\n",
    "        )\n",
    "        return {\n",
    "            \"merger_outputs\": self.merger(**inputs),\n",
    "            \"component_outputs\": [model(**inputs) for model in self.models]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0302363-53fa-4a4b-bb61-525cb5295061",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_modules_to_add_masks(target_module):\n",
    "    module_names_to_replace = []\n",
    "    for parent_name, parent_module in target_module.named_modules():\n",
    "        for name, child in parent_module.named_children():\n",
    "            full_child_name = f\"{parent_name}.{name}\" if parent_name else name\n",
    "            if (isinstance(child, (nn.Linear, nn.Embedding)) \n",
    "                or \"RMSNorm\" in type(child).__name__):\n",
    "                module_names_to_replace.append(full_child_name)\n",
    "\n",
    "    return module_names_to_replace\n",
    "\n",
    "def init_masks(target_module: nn.Module, ref_modules: nn.Module, merge_config: MergerConfig):\n",
    "    \"\"\"\n",
    "    Replaces eligible submodules in target_module with masked versions, \n",
    "    using corresponding modules from ref_modules as a reference for weights.\n",
    "\n",
    "    Args:\n",
    "        target_module: The module in which to replace submodules.\n",
    "        ref_modules: A list of modules to use as a reference for weights.\n",
    "        strategy: The initialization strategy for factors (\"naive\" or others to be implemented).\n",
    "    \"\"\"\n",
    "    mode = merge_config.mode\n",
    "    constrain_mode = merge_config.constrain_mode\n",
    "    module_names_to_replace = find_modules_to_add_masks(target_module)\n",
    "    \n",
    "    for module_name in tqdm(module_names_to_replace, desc=\"Initializing masks\"):\n",
    "        module_names = module_name.split(\".\")\n",
    "        target_child = target_module\n",
    "        ref_children = ref_modules\n",
    "\n",
    "        for m_name in module_names:\n",
    "            target_child = getattr(target_child, m_name)\n",
    "            ref_children = [getattr(ref_module, m_name) for ref_module in ref_children]\n",
    "\n",
    "        num_components = len(ref_modules)\n",
    "        modes = [mode for _ in ref_children]\n",
    "        factors = [None for _ in ref_children]\n",
    "\n",
    "        if isinstance(target_child, nn.Linear):\n",
    "            new_module = LinearsWithMasks(\n",
    "                linears=ref_children,\n",
    "                weight_modes=modes,\n",
    "                weight_values=factors,\n",
    "                bias_modes=modes,\n",
    "                bias_values=factors,\n",
    "                constrain_mode=constrain_mode\n",
    "            )\n",
    "\n",
    "        elif isinstance(target_child, nn.Embedding):\n",
    "            new_module = EmbeddingsWithMasks(ref_children, modes, factors, constrain_mode)\n",
    "        elif \"RMSNorm\" in type(target_child).__name__:\n",
    "            new_module = RMSNormsWithMasks(ref_children, modes, factors, constrain_mode)\n",
    "\n",
    "        # Replace the original module with the new masked module\n",
    "        parent_module = target_module\n",
    "        for m_name in module_names[:-1]:\n",
    "            parent_module = getattr(parent_module, m_name)\n",
    "        setattr(parent_module, module_names[-1], new_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed640347-bad5-433a-a391-bcd5f69c767c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(0.9, np.exp(1/np.e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61b2a3e6-cf38-4a7b-89f6-2274eca5697b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MergerConfig {\n",
       "  \"constrain_mode\": \"spherical\",\n",
       "  \"mode\": \"scalar\",\n",
       "  \"model_paths\": [\n",
       "    \"/workspace/dont15/models/llama32_smol_rewrite_50k/\",\n",
       "    \"/workspace/dont15/models/llama32_smol_summarize_50k/\"\n",
       "  ],\n",
       "  \"transformers_version\": \"4.47.1\"\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_config = MergerConfig(\n",
    "    model_paths = [\n",
    "        \"/workspace/dont15/models/llama32_smol_rewrite_50k/\",\n",
    "        \"/workspace/dont15/models/llama32_smol_summarize_50k/\",\n",
    "        # \"/workspace/HUB_LLM/Llama-3.2-3B-Instruct\",\n",
    "    ],\n",
    "    # mode = \"vector_input\",\n",
    "    mode = \"scalar\",\n",
    "    constrain_mode = \"spherical\"\n",
    ")\n",
    "merge_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9839af4-c5a9-46dc-81ad-027e1532a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merger.config = merge_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fb57dd6-28ce-41c5-a322-d001b2e4bd3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ce75f36d4943f89cb5802d2031d3b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fec1ef136764a7d945c8b6e931f6cf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [01:02<00:00,  4.11it/s]\n",
      "2024-12-24 09:25:00,900 - INFO - Initial GPU memory allocated: 0.00 GB\n",
      "2024-12-24 09:25:03,362 - INFO - Final GPU memory allocated: 0.00 GB\n",
      "2024-12-24 09:25:03,363 - INFO - Freed GPU memory: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "merger = Merger(merge_config)\n",
    "merger = merger.to(device=\"cuda:7\", dtype=torch.bfloat16)\n",
    "merger.__post_init__()\n",
    "merger = merger.to(device=\"cuda:7\", dtype=torch.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aff3f980-fe3c-44bf-9834-968d38d75397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _constrain_spherical(self, mask_weights: List[torch.Tensor], DOT_THRESHOLD: float = 0.9995):\n",
    "#     assert len(mask_weights) == 2, (\n",
    "#         \"Spherical constraint (SLERP) only supports 2 mask weights\"\n",
    "#     )\n",
    "\n",
    "    \n",
    "#     T = my_silu(mask_weights[0])\n",
    "\n",
    "#     # Angle at timestep t's\n",
    "#     theta_ts = self.theta_0s * T\n",
    "#     sin_theta_ts = torch.sin(theta_ts)\n",
    "\n",
    "#     # Finish calculating slerp factors\n",
    "#     S0 = torch.sin(self.theta_0s - theta_ts) / self.sin_theta_0s\n",
    "#     S1 = sin_theta_ts / self.sin_theta_0s\n",
    "\n",
    "#     # Avoid NaN\n",
    "#     nan_indices = self.dots.float() > DOT_THRESHOLD\n",
    "#     S0[nan_indices] = 1 - T[nan_indices]\n",
    "#     S1[nan_indices] = T[nan_indices]\n",
    "    \n",
    "#     return [S0, S1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06ed686f-76eb-4bd1-8ae4-a2777846a8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spherical'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.merger.model.embed_tokens.masks_constrainer.constrain_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb41e7cc-037f-470e-8a34-ba98317756b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9844, device='cuda:7', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.merger.model.embed_tokens.masks_constrainer.dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "805f11b3-a0bc-4dbd-b172-8e07f29e9863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5938, device='cuda:7', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = merger.merger.model.layers[10].mlp.down_proj.get_raw_masks()['weight_masks'][0].data\n",
    "# cons = merger.merger.model.layers[10].mlp.down_proj.weight_masks_constrainer\n",
    "# T = my_silu(x)\n",
    "# T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a811b0b0-e5cb-4353-ad2c-ea23bb1b02b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0525, device='cuda:7', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# theta_ts = cons.theta_0s * T\n",
    "# theta_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "079bc73e-b488-4826-961d-4474ff162326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4062, device='cuda:7', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1 - T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ba6673fb-f3a3-4029-a848-c8832253bb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4062, device='cuda:7', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.sin(cons.theta_0s - theta_ts) / cons.sin_theta_0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9663dac5-b792-4a12-83a2-6ab166c8d2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.03588867, dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (cons.theta_0s - theta_ts).float().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ce991aa4-c0d2-4d68-a3ea-0e6977f1ffde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.03588867, dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.sin(cons.theta_0s - theta_ts).float().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5f2fc-d8ae-4117-91ab-642b65ac86c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "fdc7086e-0e9e-43c1-9638-553243d3b3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = torch.tensor(0.111, dtype=torch.bfloat16)\n",
    "# torch.sin(x) == x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ef0a9c0-973b-48ef-a7c7-599c54138c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight_masks': [Parameter containing:\n",
       "  tensor(1., device='cuda:7', dtype=torch.bfloat16, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor(1., device='cuda:7', dtype=torch.bfloat16, requires_grad=True)],\n",
       " 'bias_masks': [None, None]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.merger.model.layers[10].mlp.down_proj.get_raw_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c75c8fa-b617-4f27-b490-7b85347826b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight_masks': [tensor(0.5039, device='cuda:7', dtype=torch.bfloat16),\n",
       "  tensor(0.5039, device='cuda:7', dtype=torch.bfloat16)],\n",
       " 'bias_masks': [None, None]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.merger.model.layers[13].mlp.down_proj.get_constrained_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4ff580b7-58bc-4efc-a9c3-2b7407403db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1533, device='cuda:7', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merger.merger.model.layers[10].mlp.down_proj.weight_masks_constrainer.theta_0s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ab87c56-0fc1-4403-86ed-42384e395fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dots = merger.merger.model.layers[0].mlp.gate_proj.weight_masks_constrainer.dots\n",
    "# dots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c1b94c1-e8da-43ec-8e84-8a9fe1951832",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up masks: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:00<00:00, 17186.46it/s]\n"
     ]
    }
   ],
   "source": [
    "set_masks(merger.merger, strategy=\"random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05dde21c-d6cd-46d3-b7d6-508ee1f0ab67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up masks: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 327/327 [00:00<00:00, 14337.18it/s]\n"
     ]
    }
   ],
   "source": [
    "set_masks(merger.merger, strategy=\"odd_one_out\", selected_idx=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e68ef671-8cb9-4305-b1de-ea0bcf3dfccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up masks: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 255/255 [00:00<00:00, 21177.48it/s]\n"
     ]
    }
   ],
   "source": [
    "set_masks(merger.merger, strategy=\"uniform\", factors=[0.6, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e7655c9-106d-400b-be04-5128069895c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(merge_config.model_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9eeaf4a3-33f4-4b0f-bf59-7797c9c986e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[128000, 128009]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(\"<|eot_id|>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "198f8245-6e74-4a55-9bbd-9d0ad94d24d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128001"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1d1d72a3-cac4-467e-830d-dc79c9f3eae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_example = rewrite_smol[19]\n",
    "rewrite_messages = rewrite_example[\"messages\"]\n",
    "rewrite_text = tokenizer.apply_chat_template(\n",
    "    rewrite_messages[:-1], tokenize=False, add_generation_prompt=True\n",
    ")\n",
    "\n",
    "summarize_example = summarize_smol[20]\n",
    "summarize_messages = summarize_example[\"messages\"]\n",
    "summarize_text = tokenizer.apply_chat_template(\n",
    "    summarize_messages[:-1], tokenize=False, add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7fea058d-bbc5-4de9-8569-27f126021f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: Provide a concise, objective summary of the input text in up to three sentences, focusing on key actions and intentions without using second or third person pronouns.\n",
      "------------------------------------------------------------------------------------------\n",
      "USER: Police used water cannons to disperse hundreds of demonstrators gathered Tuesday in Istanbul's main commercial street to protest the building of a road through a university forest in the Turkish capital city of Ankara. Protesters gathered in Istiklal Street and chanted anti-government slogans such as, \"This is just the beginning, the resistance will continue,\" \"A thousand greetings to the resistance,\" \"Killer police will pay,\" and \"Police go away, these streets are ours.\" The new round of protests in Istanbul erupted after the Ankara Municipality began cutting trees Friday in the Middle Eastern Technical University forest to make way for a highway development project. Police used their shields and water cannons to clear the main part of Istiklal Street, pushing protesters into side streets. \"This is not a designated meeting area. Please clear the street,\" the police announced over loudspeakers. One protester was knocked to the ground by a water cannon and lost consciousness for several minutes. \"In a bit they will start rounding up people. There is no law left in the country,\" said a lawyer from the Istanbul Bar Association on standby in case of detentions. Earlier in the day, Turkish Prime Minister Recep Tayyip Erdogan said in a speech delivered in parliament that the construction of the road would go on and criticized the demonstrators. \"For a road, everything can be sacrificed, because a road is civilization. But those who are not civilized will not understand the value of a road. They don't know it,\" he said. The ruling Justice and Development Party has come under criticism for its large-scale development projects. In May, widespread protests swept through Turkey over plans to turn a central Istanbul park into a shopping mall.\n",
      "------------------------------------------------------------------------------------------\n",
      "ASSISTANT: Hundreds of protesters gathered in Istanbul's Istiklal Street on Tuesday to oppose the construction of a highway through the Middle Eastern Technical University forest in Ankara. Demonstrators chanted anti-government slogans, and police used water cannons and shields to disperse the crowd, pushing them into side streets. The protests were triggered by the Ankara Municipality's decision to begin cutting trees on Friday for the highway project. One protester was briefly knocked unconscious by a water cannon, and a lawyer from the Istanbul Bar Association warned of impending arrests, criticizing the lack of legal protection. Prime Minister Recep Tayyip Erdogan defended the project, stating that roads are essential for civilization and criticizing the demonstrators for not understanding their value. The ruling Justice and Development Party has faced criticism for its large-scale development projects, including a recent protest in May over plans to convert a central Istanbul park into a shopping mall.\n",
      "------------------------------------------------------------------------------------------\n",
      "Protesters gathered in Istanbul's Istiklal Street to demonstrate against the construction of a road through a university forest in Ankara. Police used water cannons to disperse the crowd, injuring one demonstrator. The protests follow similar demonstrations in May when a central Istanbul park was planned to be turned into a shopping mall. Turkish Prime Minister Recep Tayyip Erdogan defended the road construction, stating that it represents progress and civilization. However, critics argue that the government's development projects often disregard environmental concerns and public opinion. The situation remains tense, with some fearing potential arrests.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "for message in summarize_messages:\n",
    "    print(f\"{message['role'].upper()}: {message['content']}\")\n",
    "    print(\"---\" * 30)\n",
    "    \n",
    "answer = generate(summarize_text, merger.merger, tokenizer, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed809e1d-b592-4289-8cb8-9a1cfe1f4641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYSTEM: You're an AI assistant for text re-writing. Rewrite the input text to make it more professional and formal while retaining its essential content.\n",
      "------------------------------------------------------------------------------------------\n",
      "USER: Hey Sarah,\n",
      "\n",
      "How's it going? 😄 I was thinking it would be cool if we could do a project together where we integrate some math concepts into your visual arts classes. I've been working on a few evidence-based teaching practices and thought it could really enhance the student experience. What do you think?\n",
      "\n",
      "Can we chat more about this? Maybe we can flesh out some ideas before the staff meeting?\n",
      "\n",
      "Thanks!\n",
      "Alex\n",
      "------------------------------------------------------------------------------------------\n",
      "ASSISTANT: Dear Sarah,\n",
      "\n",
      "I hope this message finds you well. I have been contemplating a collaborative project that integrates mathematical concepts into your visual arts curriculum. I believe this interdisciplinary approach, supported by evidence-based teaching practices, could significantly enhance the educational experience for our students.\n",
      "\n",
      "Could we arrange a time to discuss this further? It would be beneficial to develop some concrete ideas before the upcoming staff meeting.\n",
      "\n",
      "Thank you for considering this opportunity.\n",
      "\n",
      "Best regards,\n",
      "Alex\n",
      "------------------------------------------------------------------------------------------\n",
      "Dear Sarah,\n",
      "\n",
      "I hope this message finds you well. I have been considering a potential collaboration between our departments, specifically integrating mathematical concepts into your visual arts classes. My research has led me to explore several evidence-based teaching practices that could significantly enhance the learning experience for students.\n",
      "\n",
      "I believe that combining mathematics with art could provide a unique and engaging approach to education, fostering creativity and problem-solving skills in a way that traditional methods may not. I would love to discuss this idea further with you and hear your thoughts on how we might implement such a project.\n",
      "\n",
      "Would you be available to meet at your earliest convenience to brainstorm some initial ideas? Perhaps we could also touch base before the upcoming staff meeting to gauge interest and gather support from other colleagues.\n",
      "\n",
      "Thank you for considering this proposal. I look forward to your response.\n",
      "\n",
      "Best regards,\n",
      "Alex\n",
      "\n",
      "P.S. If you'd like, we can schedule a time to meet via video call or in person, whichever is most convenient for you. Just let me know! 📅👍\n",
      "\n",
      "Note: The tone of the email remains friendly and collaborative, but the language is more polished and professional. The P.S. adds a flexible scheduling option for the meeting. \n",
      "\n",
      "Here's another version:\n",
      "\n",
      "Dear Sarah,\n",
      "\n",
      "I hope this message finds you well\n"
     ]
    }
   ],
   "source": [
    "for message in rewrite_messages:\n",
    "    print(f\"{message['role'].upper()}: {message['content']}\")\n",
    "    print(\"---\" * 30)\n",
    "\n",
    "# print(rewrite_text)\n",
    "answer = generate(rewrite_text, merger.merger, tokenizer, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "560671a4-80b8-43d1-8fbb-de99c9fb56f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear Sarah,\n",
      "\n",
      "I hope this message finds you well. I have been considering a potential collaboration that integrates mathematical concepts into your visual arts curriculum. My recent work has focused on evidence-based teaching practices, which I believe could significantly enrich the educational experience for our students.\n",
      "\n",
      "I would appreciate the opportunity to discuss this idea further with you at your earliest convenience. Perhaps we could schedule a time to outline some initial thoughts before the upcoming staff meeting.\n",
      "\n",
      "Thank you for considering this proposal.\n",
      "\n",
      "Best regards,\n",
      "Alex\n",
      "\n",
      "P.S. I am eager to hear your thoughts on this matter.<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "answer = generate(rewrite_text, merger.models[0], tokenizer, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd86ccf0-1313-43d8-859f-c2ecab695322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a concise, objective summary of the text in three sentences:\n",
      "\n",
      "Protesters gathered in Istanbul's Istiklal Street to demonstrate against the destruction of a university forest to build a highway, with chants and slogans calling for continued resistance. Police responded with water cannons, clearing the main street and pushing protesters into side alleys, while one demonstrator was briefly knocked unconscious. The Turkish government, led by Prime Minister Recep Tayyip Erdogan, has faced criticism for its large-scale development projects, including this latest move, which has sparked renewed protests.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "answer = generate(summarize_text, merger.models[1], tokenizer, max_new_tokens=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb063275-ac97-468e-8d02-b594ac129eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_merged = get_logits(text, merger.merger, tokenizer)\n",
    "logits_0 = get_logits(text, merger.models[1], tokenizer)\n",
    "torch.allclose(logits_merged, logits_0, atol=0, rtol=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
