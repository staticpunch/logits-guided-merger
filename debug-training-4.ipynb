{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e91e4bd-dd42-4c21-b5ea-8f4a2ee3ce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Model merging training implementation using PyTorch and Transformers.\n",
    "Implements custom data collation and training for merged language models.\n",
    "\"\"\"\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Callable, Dict, List, NewType, Optional, Tuple, Union, Mapping\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import datasets\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import safetensors\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "import copy\n",
    "import gc\n",
    "\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    PreTrainedTokenizerBase,\n",
    "    PreTrainedModel,\n",
    "    PretrainedConfig,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaConfig,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    default_data_collator,\n",
    "    is_torch_xla_available,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "from transformers.utils import CONFIG_NAME\n",
    "\n",
    "# from accurate_masks import (\n",
    "# from efficient_masks import (\n",
    "from merger import (\n",
    "    MergerConfig,\n",
    "    # Merger,\n",
    "    NewMerger,\n",
    "    init_masks,\n",
    "    set_masks\n",
    ")\n",
    "\n",
    "from utils import (\n",
    "    generate, \n",
    "    get_hidden_states, \n",
    "    get_logits,\n",
    "    free_memory\n",
    ")\n",
    "# Configure logger\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, \n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd01048a-09b5-43db-97ad-e81bd9ca6fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Option 1: Set specific GPU devices\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c21b6f1-47a4-4bea-b81b-86f57543f099",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"Handles data loading and preprocessing.\"\"\"\n",
    "    \n",
    "    def __init__(self, tokenizer: PreTrainedTokenizerBase):\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def load_dataset(self):\n",
    "        \"\"\"Load and prepare the training dataset.\"\"\"\n",
    "        summarize_train = load_dataset(\n",
    "            \"HuggingFaceTB/smoltalk\",\n",
    "            \"smol-summarize\",\n",
    "            split=\"train\"\n",
    "        )\n",
    "        summarize_train = summarize_train.add_column(\n",
    "            name=\"data_source\",\n",
    "            column=[1 for _ in summarize_train]\n",
    "        )\n",
    "        return summarize_train.shuffle(seed=42).select(range(30000))\n",
    "    \n",
    "    def tokenize(self, element):\n",
    "        \"\"\"Tokenize a single element from the dataset.\"\"\"\n",
    "        templated = self.tokenizer.apply_chat_template(\n",
    "            element[\"messages\"],\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        )\n",
    "        return self.tokenizer(\n",
    "            templated,\n",
    "            truncation=True,\n",
    "            max_length=2048,\n",
    "            add_special_tokens=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbe1946d-df3e-4b95-8207-877c5dfebd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_without_fast_tokenizer_warning(tokenizer, *pad_args, **pad_kwargs):\n",
    "    \"\"\"\n",
    "    Pads without triggering the warning about how using the pad function is sub-optimal when using a fast tokenizer.\n",
    "    \"\"\"\n",
    "\n",
    "    # To avoid errors when using Feature extractors\n",
    "    if not hasattr(tokenizer, \"deprecation_warnings\"):\n",
    "        return tokenizer.pad(*pad_args, **pad_kwargs)\n",
    "\n",
    "    # Save the state of the warning, then disable it\n",
    "    warning_state = tokenizer.deprecation_warnings.get(\"Asking-to-pad-a-fast-tokenizer\", False)\n",
    "    tokenizer.deprecation_warnings[\"Asking-to-pad-a-fast-tokenizer\"] = True\n",
    "\n",
    "    try:\n",
    "        padded = tokenizer.pad(*pad_args, **pad_kwargs)\n",
    "    finally:\n",
    "        # Restore the state of the warning.\n",
    "        tokenizer.deprecation_warnings[\"Asking-to-pad-a-fast-tokenizer\"] = warning_state\n",
    "\n",
    "    return padded\n",
    "\n",
    "@dataclass\n",
    "class MergerDataCollator:\n",
    "    tokenizer: PreTrainedTokenizerBase\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    return_tensors: str = \"pt\"\n",
    "\n",
    "    def __call__(self, examples):\n",
    "        \"\"\"\n",
    "        copied from DataCollatorForLanguageModeling\n",
    "        examples: List[Union[List[int], Any, Dict[str, Any]]]\n",
    "        \"\"\"\n",
    "        # Handle dict or lists with proper padding and conversion to tensor.\n",
    "        if not isinstance(examples[0], Mapping):\n",
    "            raise ValueError(\"Data collator only processes list of dictionaries.\")\n",
    "\n",
    "        inputs_ids = []\n",
    "        data_sources = []\n",
    "        for i in range(len(examples)):\n",
    "            _ = examples[i].pop(\"attention_mask\")\n",
    "            inputs_ids.append({\"input_ids\": examples[i].pop(\"input_ids\")})\n",
    "            data_sources.append(examples[i].pop(\"data_source\"))\n",
    "            \n",
    "        batch = pad_without_fast_tokenizer_warning(\n",
    "            self.tokenizer, inputs_ids, return_tensors=\"pt\", \n",
    "            pad_to_multiple_of=self.pad_to_multiple_of\n",
    "        )\n",
    "\n",
    "        labels = batch[\"input_ids\"].clone()\n",
    "        if self.tokenizer.pad_token_id is not None:\n",
    "            labels[labels == self.tokenizer.pad_token_id] = -100\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        # Handle data_source - convert to tensor\n",
    "        batch[\"data_source\"] = torch.tensor(\n",
    "            [src for src in data_sources], dtype=torch.long\n",
    "        )\n",
    "        \n",
    "        for key in examples[0]:\n",
    "            if key in batch:\n",
    "                raise ValueError(\n",
    "                    f\"`{key}` feature is collated. \"\n",
    "                    \"Overriding it with its initial values is prohibitted.\"\n",
    "                )\n",
    "            else:\n",
    "                batch[key] = [x[key] for x in examples]\n",
    "        logger.info_once(f\">>> Collator output keys: {batch.keys()}\")\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0891539-136e-4a0e-95d9-32767e42f5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_logits_target(logits_components, data_source):\n",
    "    \"\"\"Select appropriate logits based on data source.\"\"\"\n",
    "    # logits_components ~ [(batch_size, seq_len, vocab_size) * n_components]\n",
    "    # stacked_logits.shape = (n_components, batch_size, seq_len, vocab_size)\n",
    "    # data_source.shape == (batch_size,)\n",
    "    # indices.shape == (batch_size, 1, 1)\n",
    "    stacked_logits = torch.stack(logits_components)\n",
    "    indices = data_source.unsqueeze(-1).unsqueeze(-1)\n",
    "    return stacked_logits[indices]\n",
    "\n",
    "def selective_logits_target(logits_components, data_source):\n",
    "    \"\"\"Select appropriate logits based on data source.\"\"\"\n",
    "\n",
    "    logits_target = torch.empty_like(logits_components[0])\n",
    "    for idx, source in enumerate(data_source):\n",
    "        logits_target[idx] = logits_components[source][idx]\n",
    "\n",
    "    return logits_target\n",
    "\n",
    "def masked_kl_div(logits_a, logits_b, mask, temperature=1.0):\n",
    "    # (batch_size, seq_len, vocab_size) -> (batch_size * seq_len, vocab_size)\n",
    "    logits_a = logits_a.view(-1, logits_a.size(-1)) / temperature\n",
    "    logits_b = logits_b.view(-1, logits_b.size(-1)) / temperature\n",
    "\n",
    "    # (batch_size * seq_len,)\n",
    "    mask = mask.view(-1)\n",
    "\n",
    "    assert mask.size(0) == logits_a.size(0)\n",
    "\n",
    "    log_probs_a = nn.functional.log_softmax(logits_a, dim=-1)\n",
    "    log_probs_b = nn.functional.log_softmax(logits_b, dim=-1)\n",
    "\n",
    "    # (batch_size * seq_len, vocab_size) -> (batch_size * seq_len)\n",
    "    div = log_probs_a.exp() * (log_probs_a - log_probs_b)\n",
    "    div = div.sum(-1)\n",
    "\n",
    "    ## taking average on effective tokens.\n",
    "    div = (div * mask).sum() / mask.sum() * (temperature ** 2)\n",
    "    return div\n",
    "\n",
    "def builtin_kl_div(logits_a, logits_b, mask, temperature=1.0):\n",
    "    kl_fct = nn.KLDivLoss(reduction=\"none\")\n",
    "    diff = (\n",
    "        kl_fct(\n",
    "            F.log_softmax(logits_b / temperature, dim=-1),\n",
    "            F.softmax(logits_a / temperature, dim=-1)\n",
    "        )\n",
    "        * (temperature) ** 2\n",
    "    )\n",
    "    \n",
    "    # Calculate final loss\n",
    "    loss = (diff.sum(-1) * mask).sum() / mask.sum()\n",
    "    return loss\n",
    "\n",
    "class MergerTrainer(Trainer):\n",
    "    \"\"\"Custom trainer for merged model training.\"\"\"\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        data_source = inputs.pop(\"data_source\")\n",
    "        effective_idxs = (labels != -100).float()\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        logits_merged = outputs[\"merger_outputs\"].logits\n",
    "        logits_components = [x.logits for x in outputs[\"components_outputs\"]]\n",
    "\n",
    "        # Compute target logits and KL divergence\n",
    "        logits_target = selective_logits_target(logits_components, data_source)\n",
    "        \n",
    "        # temperature = 1.0\n",
    "        # kl_fct = nn.KLDivLoss(reduction=\"none\")\n",
    "        # diff = (\n",
    "        #     kl_fct(\n",
    "        #         F.log_softmax(logits_target / temperature, dim=-1),\n",
    "        #         F.softmax(logits_merged / temperature, dim=-1)\n",
    "        #     )\n",
    "        #     * (temperature) ** 2\n",
    "        # )\n",
    "        \n",
    "        # # Calculate final loss\n",
    "        # loss = (diff * effective_idxs).sum(dim=-1)\n",
    "        # loss = (loss / effective_idxs.sum(dim=1)).mean()\n",
    "\n",
    "\n",
    "        # loss = masked_kl_div(logits_merged, logits_target, effective_idxs)\n",
    "        loss = builtin_kl_div(logits_merged, logits_target, effective_idxs)\n",
    "        # logger.info(f\">>> mdfk: {loss}\")\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def _load_from_checkpoint(self, resume_from_checkpoint, model=None):\n",
    "        assert model is not None, (\n",
    "            \"Must pass an initialized model to trainer instead of model path.\"\n",
    "        )\n",
    "        # Look for trainable parameters file\n",
    "        masks_file = os.path.join(resume_from_checkpoint, \"masks.safetensors\")\n",
    "        if not os.path.isfile(trainable_params_file):\n",
    "            masks_file = os.path.join(resume_from_checkpoint, \"masks.bin\")\n",
    "        \n",
    "        if not os.path.isfile(masks_file):\n",
    "            raise ValueError(\n",
    "                f\"Can't find trainable parameters file in {resume_from_checkpoint}. \"\n",
    "                \"Expected either masks.safetensors or masks.bin\"\n",
    "            )\n",
    "    \n",
    "        config_file = os.path.join(resume_from_checkpoint, CONFIG_NAME)\n",
    "        if os.path.isfile(config_file):\n",
    "            config = PretrainedConfig.from_json_file(config_file)\n",
    "            checkpoint_version = config.transformers_version\n",
    "            if checkpoint_version is not None and checkpoint_version != __version__:\n",
    "                logger.warning(\n",
    "                    f\"You are resuming training from a checkpoint trained with {checkpoint_version} of \"\n",
    "                    f\"Transformers but your current version is {__version__}. This is not recommended and could \"\n",
    "                    \"yield to errors or unwanted behaviors.\"\n",
    "                )\n",
    "    \n",
    "        if os.path.isfile(masks_file):\n",
    "            weights_only_kwarg = {\"weights_only\": True} if is_torch_greater_or_equal_than_1_13 else {}\n",
    "            # If the model is on the GPU, it still works!\n",
    "            # We load the model state dict on the CPU to avoid an OOM error.\n",
    "            if self.args.save_safetensors and masks_file.endswith(\".safetensors\"):\n",
    "                state_dict = safetensors.torch.load_file(safe_weights_file, device=\"cpu\")\n",
    "            else:\n",
    "                state_dict = torch.load(\n",
    "                    masks_file,\n",
    "                    map_location=\"cpu\",\n",
    "                    **weights_only_kwarg,\n",
    "                )\n",
    "    \n",
    "            # workaround for FSDP bug https://github.com/pytorch/pytorch/issues/82963\n",
    "            # which takes *args instead of **kwargs\n",
    "            load_result = model.load_state_dict(state_dict, False)\n",
    "            if len(load_result.missing_keys) != 0:\n",
    "                logger.info(\n",
    "                    \"There were missing keys in the checkpoint model loaded. \"\n",
    "                    \"However, this is an expected behavior since we are only \"\n",
    "                    \"loading partial weights (masks).\"\n",
    "                )\n",
    "            # release memory\n",
    "            del state_dict\n",
    "            gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5696e43c-d407-4953-8b81-28ca34a23c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Args:\n",
    "    model_name: str = \"...\"  # You can replace this with any causal language model from HuggingFace\n",
    "    dataset_name: str = \"...\"  # Replace with your dataset name (e.g., \"your_username/your_dataset\")\n",
    "    train_split: str = \"train\"  # e.g., \"train[:80%]\" for an 80/20 train/validation split\n",
    "    validation_split: str = None  # e.g., \"train[80%:]\"\n",
    "    output_dir: str = \"./trained_masks\"\n",
    "    per_device_train_batch_size: int = 1\n",
    "    per_device_eval_batch_size: int = 8\n",
    "    gradient_accumulation_steps: int = 32\n",
    "    learning_rate: float = 5e-3\n",
    "    num_train_epochs: int = 1\n",
    "    save_steps: int = 100\n",
    "    eval_steps: int = 5000\n",
    "    logging_steps: int = 10\n",
    "    logging_dir: str = \"./trained_masks/logs\"\n",
    "    evaluation_strategy: str = \"steps\"\n",
    "    report_to: str = None\n",
    "    remove_unused_columns: bool = False\n",
    "    logging_first_step: bool = True\n",
    "    gradient_checkpointing: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d75bc334-1c97-4311-93a3-571ffe40f60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize configuration\n",
    "merge_config = MergerConfig(\n",
    "    model_paths=[\n",
    "        \"nguyenthanhdo/llama32_smol_rewrite_50k\",\n",
    "        \"nguyenthanhdo/llama32_smol_summarize_50k\",\n",
    "    ],\n",
    "    mode=\"vector_input\",\n",
    "    constrain_mode=\"identity\"\n",
    ")\n",
    "\n",
    "# Setup tokenizer and data processing\n",
    "tokenizer = AutoTokenizer.from_pretrained(merge_config.model_paths[0])\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_processor = DataProcessor(tokenizer)\n",
    "train_dataset = data_processor.load_dataset()\n",
    "tokenized_dataset = train_dataset.map(\n",
    "    data_processor.tokenize,\n",
    "    remove_columns=[\"messages\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a144ef3b-f871-4067-9833-65a34188a8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 10:16:46,865 - INFO - Creating merger with dummy weights ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5febe98b37467da432bedeeb1ca609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46d9bf358f3d4e17b86adc4febbc7d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a419218878940be968cefcaca164e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing masks:   1%|â–ˆâ–Ž                                                                                                                                                                            | 2/255 [00:07<15:13,  3.61s/it]2025-01-06 10:16:56,272 - WARNING - Though you want to make a masks of modes ['vector_input', 'vector_input'] for RMSNorms' weights, by default a mask only accepts a scalar mask. Converting modes to `scalar`.\n",
      "Initializing masks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 255/255 [00:28<00:00,  9.04it/s]\n",
      "Setting up masks: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 255/255 [00:00<00:00, 38590.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize merger model\n",
    "merger = NewMerger.from_pretrained(\n",
    "    None,\n",
    "    merge_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "set_masks(merger.merger, strategy=\"uniform\", factors=[0.99, 0.01])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2483c3a0-6ae9-4d36-8a90-684494f08dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from safetensors.torch import load_file as safe_load_file\n",
    "# state_dict = safe_load_file(\"./trained_masks/model.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b974a02b-0029-482e-b156-468fd1cfb2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1503346"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trainable_count = 0\n",
    "# for k, v in state_dict.items():\n",
    "#     trainable_count += v.numel()\n",
    "# trainable_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d657a00e-9012-4515-9087-8f919200ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_masks(merger.merger, strategy=\"uniform\", factors=[0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dea11545-f255-446b-ae37-98e0d4fd0014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merger.load_masks(\"./trained_masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44e04cff-3be7-41e7-b393-e9edfc01e474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merger.merger.model.embed_tokens.get_raw_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b0df58b-0d9b-4148-a14d-29967375e279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# merger = NewMerger.from_pretrained(\n",
    "#     \"./trained_masks\",\n",
    "#     merge_config,\n",
    "#     torch_dtype=torch.bfloat16,\n",
    "#     device_map=\"auto\",\n",
    "#     attn_implementation=\"flash_attention_2\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f11b513-6bf0-4b9b-833d-5dd9ef3a7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merger.save_pretrained(\"./trained_masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0881557b-1b22-4f8b-8694-8274dd12d931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 10:17:17,212 - INFO - Initial GPU memory allocated: 0.00 GB\n",
      "2025-01-06 10:17:17,363 - INFO - Final GPU memory allocated: 0.00 GB\n",
      "2025-01-06 10:17:17,364 - INFO - Freed GPU memory: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "# Monitor memory usage\n",
    "initial_memory = torch.cuda.memory_allocated()\n",
    "logger.info(f\"Initial GPU memory allocated: {initial_memory / 1024**3:.2f} GB\")\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "final_memory = torch.cuda.memory_allocated()\n",
    "logger.info(f\"Final GPU memory allocated: {final_memory / 1024**3:.2f} GB\")\n",
    "logger.info(f\"Freed GPU memory: {(initial_memory - final_memory) / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b80a1459-db79-4b6d-b48f-abe251903369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Setup training arguments and data collator\n",
    "args = Args()\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=args.output_dir,\n",
    "    per_device_train_batch_size=args.per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=args.per_device_eval_batch_size,\n",
    "    gradient_accumulation_steps=args.gradient_accumulation_steps,\n",
    "    learning_rate=args.learning_rate,\n",
    "    num_train_epochs=args.num_train_epochs,\n",
    "    save_steps=args.save_steps,\n",
    "    evaluation_strategy=args.evaluation_strategy if args.validation_split else \"no\",\n",
    "    eval_steps=args.eval_steps if args.validation_split else None,\n",
    "    logging_steps=args.logging_steps,\n",
    "    logging_dir=args.logging_dir,\n",
    "    report_to=args.report_to,  # Enable TensorBoard logging\n",
    "    remove_unused_columns=args.remove_unused_columns,\n",
    "    logging_first_step=args.logging_first_step,\n",
    "    gradient_checkpointing=args.gradient_checkpointing,\n",
    "    save_safetensors=True\n",
    ")\n",
    "\n",
    "data_collator = MergerDataCollator(\n",
    "    tokenizer,\n",
    "    pad_to_multiple_of=8,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# Initialize and start training\n",
    "trainer = MergerTrainer(\n",
    "    model=merger,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=None,\n",
    "    data_collator=data_collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84ffdf19-9b4c-4394-a6bf-fe91626a749b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 10:17:24,869 - INFO - >>> Collator output keys: dict_keys(['input_ids', 'attention_mask', 'labels', 'data_source'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='258' max='937' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [258/937 24:19 < 1:04:31, 0.18 it/s, Epoch 0.27/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.353600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.721000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.442200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.372900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.341400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.324400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.309000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.293400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.283800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.281000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.266400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.274900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.266800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.256000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.269800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.252400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.255500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.255400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.251600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.244400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.235400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.247700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.240500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.235700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:2481\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2475\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2476\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2479\u001b[0m )\n\u001b[1;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2487\u001b[0m ):\n\u001b[1;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/trainer.py:3579\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3578\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3579\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3584\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3585\u001b[0m ):\n",
      "Cell \u001b[0;32mIn[5], line 63\u001b[0m, in \u001b[0;36mMergerTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m     60\u001b[0m data_source \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_source\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     61\u001b[0m effective_idxs \u001b[38;5;241m=\u001b[39m (labels \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m---> 63\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m logits_merged \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerger_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mlogits\n\u001b[1;32m     65\u001b[0m logits_components \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mlogits \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponents_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/workspace/logits-guided-merger/merger.py:225\u001b[0m, in \u001b[0;36mNewMerger.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# During training, we want both merger and component outputs\u001b[39;00m\n\u001b[1;32m    224\u001b[0m merger_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerger(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m--> 225\u001b[0m components_outputs \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerger_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: merger_outputs,\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponents_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: components_outputs\n\u001b[1;32m    230\u001b[0m }\n",
      "File \u001b[0;32m/workspace/logits-guided-merger/merger.py:225\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# During training, we want both merger and component outputs\u001b[39;00m\n\u001b[1;32m    224\u001b[0m merger_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerger(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m--> 225\u001b[0m components_outputs \u001b[38;5;241m=\u001b[39m [\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels]\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmerger_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: merger_outputs,\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponents_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: components_outputs\n\u001b[1;32m    230\u001b[0m }\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:1190\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[0m\n\u001b[1;32m   1187\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1190\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1203\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:915\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m position_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    913\u001b[0m     position_ids \u001b[38;5;241m=\u001b[39m cache_position\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 915\u001b[0m causal_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_causal_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    918\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds\n\u001b[1;32m    920\u001b[0m \u001b[38;5;66;03m# create position embeddings to be shared across the decoder layers\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/transformers/models/llama/modeling_llama.py:992\u001b[0m, in \u001b[0;36mLlamaModel._update_causal_mask\u001b[0;34m(self, attention_mask, input_tensor, cache_position, past_key_values, output_attentions)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_causal_mask\u001b[39m(\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    985\u001b[0m     attention_mask: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    989\u001b[0m     output_attentions: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m    990\u001b[0m ):\n\u001b[1;32m    991\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_attn_implementation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflash_attention_2\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 992\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m:\n\u001b[1;32m    993\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m attention_mask\n\u001b[1;32m    994\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:1178\u001b[0m, in \u001b[0;36mTensor.__contains__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__contains__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, element)\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1175\u001b[0m     element, (torch\u001b[38;5;241m.\u001b[39mTensor, Number, torch\u001b[38;5;241m.\u001b[39mSymInt, torch\u001b[38;5;241m.\u001b[39mSymFloat, torch\u001b[38;5;241m.\u001b[39mSymBool)\n\u001b[1;32m   1176\u001b[0m ):\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;66;03m# type hint doesn't understand the __contains__ result array\u001b[39;00m\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensor.__contains__ only supports Tensor or scalar, but you passed in a \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(element)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1182\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "367ae422-1fe4-41e9-b45e-3ba69cdc88d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 09:48:24,520 - INFO - >>> Collator output keys: dict_keys(['input_ids', 'attention_mask', 'labels', 'data_source'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[128000, 128006,   9125,  ..., 128001, 128001, 128001],\n",
      "        [128000, 128006,   9125,  ..., 128001, 128001, 128001]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), 'labels': tensor([[128000, 128006,   9125,  ...,   -100,   -100,   -100],\n",
      "        [128000, 128006,   9125,  ...,   -100,   -100,   -100]]), 'data_source': tensor([1, 1])}\n"
     ]
    }
   ],
   "source": [
    "inputs = data_collator([x for x in tokenized_dataset.select(range(2))])\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a7f2852-c310-4e92-b51f-b0de0243be11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000, 128006,   9125,  ..., 128001, 128001, 128001],\n",
       "         [128000, 128006,   9125,  ..., 128001, 128001, 128001]],\n",
       "        device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'),\n",
       " 'labels': tensor([[128000, 128006,   9125,  ...,   -100,   -100,   -100],\n",
       "         [128000, 128006,   9125,  ...,   -100,   -100,   -100]],\n",
       "        device='cuda:0'),\n",
       " 'data_source': tensor([1, 1], device='cuda:0')}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {k: v.to(device=merger.device) for k, v in inputs.items()}\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fa592b5-6b7f-4afa-83e1-8d859d8e16f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = inputs[\"labels\"].clone()\n",
    "effective_idxs = (labels != -100).float().unsqueeze(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c1d1e647-7414-4a6a-a6b8-f8795e738932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0024, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.compute_loss(merger, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9a349a4-04ff-4c7a-90d4-6b74caa003fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = merger(**inputs)\n",
    "logits_merged = outputs[\"merger_outputs\"].logits\n",
    "logits_components = [x.logits for x in outputs[\"components_outputs\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96e8a41f-c8bc-4c88-a2cf-8919982c65a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.3125,  7.7188, 13.1875,  ..., -6.2188, -6.2188, -6.2188],\n",
       "         [ 1.0156,  0.2188, -0.8008,  ...,  3.3438,  3.3438,  3.3438],\n",
       "         [ 3.1094,  4.7812,  3.5781,  ..., -1.0781, -1.0781, -1.0781],\n",
       "         ...,\n",
       "         [ 0.4160,  1.6172,  2.3750,  ..., -2.0312, -2.0312, -2.0312],\n",
       "         [ 0.6211,  1.8828,  2.5156,  ..., -1.9609, -1.9609, -1.9609],\n",
       "         [ 0.7734,  1.8828,  2.5781,  ..., -1.9141, -1.9141, -1.9141]],\n",
       "\n",
       "        [[ 5.3125,  7.7188, 13.1875,  ..., -6.2188, -6.2188, -6.2188],\n",
       "         [ 1.0156,  0.2188, -0.8008,  ...,  3.3438,  3.3438,  3.3438],\n",
       "         [ 3.1094,  4.7812,  3.5781,  ..., -1.0781, -1.0781, -1.0781],\n",
       "         ...,\n",
       "         [ 0.9570,  2.0625,  3.1562,  ..., -1.1562, -1.1562, -1.1562],\n",
       "         [ 0.9492,  2.0938,  3.1406,  ..., -1.2109, -1.2109, -1.2109],\n",
       "         [ 1.0156,  2.1406,  3.1719,  ..., -1.2344, -1.2344, -1.2344]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fa7b1c5-faef-4cc6-8d6a-8b5b587333f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.2812,  7.6875, 13.1250,  ..., -6.1562, -6.1562, -6.1562],\n",
       "         [ 0.8477,  0.1689, -0.8867,  ...,  3.3594,  3.3594,  3.3594],\n",
       "         [ 3.0781,  4.7812,  3.6094,  ..., -1.0234, -1.0234, -1.0234],\n",
       "         ...,\n",
       "         [ 3.3594,  3.5156,  5.2812,  ..., -3.0156, -3.0156, -3.0156],\n",
       "         [ 3.3594,  3.5156,  5.2812,  ..., -3.0156, -3.0156, -3.0156],\n",
       "         [ 3.3594,  3.5156,  5.2812,  ..., -3.0156, -3.0156, -3.0156]],\n",
       "\n",
       "        [[ 5.2812,  7.6875, 13.1250,  ..., -6.1562, -6.1562, -6.1562],\n",
       "         [ 0.8477,  0.1689, -0.8867,  ...,  3.3594,  3.3594,  3.3594],\n",
       "         [ 3.0781,  4.7812,  3.6094,  ..., -1.0234, -1.0234, -1.0234],\n",
       "         ...,\n",
       "         [ 3.3594,  3.5156,  5.2812,  ..., -3.0156, -3.0156, -3.0156],\n",
       "         [ 3.3594,  3.5156,  5.2812,  ..., -3.0156, -3.0156, -3.0156],\n",
       "         [ 3.3594,  3.5156,  5.2812,  ..., -3.0156, -3.0156, -3.0156]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_components[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37fb4bfa-1d09-4bc4-8045-7e1b7daf94ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
       "\n",
       "Subclass and override for custom behavior.\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdata_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_source\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0meffective_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlogits_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"merger_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlogits_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"components_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Compute target logits and KL divergence\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlogits_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselective_logits_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtemperature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mkl_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKLDivLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"none\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mkl_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_target\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_merged\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Calculate final loss\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meffective_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0meffective_idxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# logger.info(f\">>> mdfk: {loss}\")\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_109058/1704935865.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.compute_loss??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fd9dcc3-21cf-4bdb-a2b8-85fc20f55114",
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_kl_div(logits_a, logits_b, mask, temperature=1.0):\n",
    "    logits_a = logits_a.view(-1, logits_a.size(-1)) / temperature\n",
    "    logits_b = logits_b.view(-1, logits_b.size(-1)) / temperature\n",
    "    mask = mask.view(-1)\n",
    "\n",
    "    assert mask.size(0) == logits_a.size(0)\n",
    "\n",
    "    log_probs_a = nn.functional.log_softmax(logits_a, dim=-1)\n",
    "    log_probs_b = nn.functional.log_softmax(logits_b, dim=-1)\n",
    "\n",
    "    div = log_probs_a.exp() * (log_probs_a - log_probs_b)\n",
    "    div = div.sum(-1)\n",
    "\n",
    "    div = (div * mask).sum() / mask.sum() * (temperature ** 2)\n",
    "    return div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db689e70-6df7-4b24-ab21-ce6243358f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0889, device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_kl_div(logits_components[1], logits_components[0], effective_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9eb6874c-420e-4d4d-a6fb-9b73ceb53326",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 1.0\n",
    "kl_fct = nn.KLDivLoss(reduction=\"none\")\n",
    "diff = (\n",
    "    kl_fct(\n",
    "        F.log_softmax(logits_components[1] / temperature, dim=-1),\n",
    "        F.softmax(logits_components[0] / temperature, dim=-1)\n",
    "    )\n",
    "    * (temperature) ** 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "590066dd-806e-4405-b465-339e26e178d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000, 128006,   9125,  ..., 128001, 128001, 128001],\n",
       "         [128000, 128006,   9125,  ..., 128001, 128001, 128001]],\n",
       "        device='cuda:0'),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0')}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ab4e13a-76ba-4bcb-a0d8-31617f54ad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate final loss\n",
    "loss = (diff * effective_idxs).sum(dim=-1)\n",
    "loss = (loss / effective_idxs.sum(dim=1)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a1d8071d-36b7-433f-9f27-e97fe527855c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.1562,  7.2812, 13.3125,  ..., -6.1250, -6.1250, -6.1250],\n",
       "         [ 2.1406,  0.4219,  2.6562,  ...,  0.3164,  0.3164,  0.3164],\n",
       "         [ 4.0938,  1.6641,  2.5156,  ..., -2.3594, -2.3594, -2.3594],\n",
       "         ...,\n",
       "         [ 3.5312,  4.6250,  5.9375,  ..., -2.5156, -2.5156, -2.5156],\n",
       "         [ 3.5312,  4.6250,  5.9375,  ..., -2.5156, -2.5156, -2.5156],\n",
       "         [ 3.5312,  4.6250,  5.9375,  ..., -2.5156, -2.5156, -2.5156]],\n",
       "\n",
       "        [[ 5.1562,  7.2812, 13.3125,  ..., -6.1250, -6.1250, -6.1250],\n",
       "         [ 2.1406,  0.4219,  2.6562,  ...,  0.3164,  0.3164,  0.3164],\n",
       "         [ 4.0938,  1.6641,  2.5156,  ..., -2.3594, -2.3594, -2.3594],\n",
       "         ...,\n",
       "         [ 3.5312,  4.6250,  5.9375,  ..., -2.5156, -2.5156, -2.5156],\n",
       "         [ 3.5312,  4.6250,  5.9375,  ..., -2.5156, -2.5156, -2.5156],\n",
       "         [ 3.5312,  4.6250,  5.9375,  ..., -2.5156, -2.5156, -2.5156]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_components[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0368bed8-b830-4794-ac87-4000df2a1044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8594, device='cuda:0', dtype=torch.bfloat16, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(logits_merged - logits_components[1]).pow(2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ac18f-a0c9-4ff3-aadd-b7561db2c208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "58737a5e-a7ef-4407-a0e1-22a6adc306e3",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacity of 79.21 GiB of which 81.25 MiB is free. Process 3192013 has 79.11 GiB memory in use. Of the allocated memory 75.54 GiB is allocated by PyTorch, and 2.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mkl_fct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_softmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits_components\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msoftmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits_components\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/loss.py:541\u001b[0m, in \u001b[0;36mKLDivLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl_div\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_target\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/functional.py:3381\u001b[0m, in \u001b[0;36mkl_div\u001b[0;34m(input, target, size_average, reduce, reduction, log_target)\u001b[0m\n\u001b[1;32m   3378\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3379\u001b[0m         reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m-> 3381\u001b[0m reduced \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkl_div\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_target\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_target\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatchmean\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   3384\u001b[0m     reduced \u001b[38;5;241m=\u001b[39m reduced \u001b[38;5;241m/\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 274.00 MiB. GPU 0 has a total capacity of 79.21 GiB of which 81.25 MiB is free. Process 3192013 has 79.11 GiB memory in use. Of the allocated memory 75.54 GiB is allocated by PyTorch, and 2.90 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "kl_fct(\n",
    "    F.log_softmax(logits_components[0] / temperature, dim=-1),\n",
    "    F.softmax(logits_components[1] / temperature, dim=-1)\n",
    ").sum(-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe84d21e-cbf1-4407-a94c-a0c05bf114dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
       "\n",
       "Subclass and override for custom behavior.\n",
       "\u001b[0;31mSource:\u001b[0m   \n",
       "    \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"labels\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdata_source\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_source\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0meffective_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlogits_merged\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"merger_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlogits_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"components_outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Compute target logits and KL divergence\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mlogits_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselective_logits_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_source\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mtemperature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mkl_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKLDivLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"none\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0mkl_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_target\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m                \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_merged\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m            \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemperature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# Calculate final loss\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdiff\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0meffective_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0meffective_idxs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;31m# logger.info(f\">>> mdfk: {loss}\")\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mFile:\u001b[0m      /tmp/ipykernel_105163/1704935865.py\n",
       "\u001b[0;31mType:\u001b[0m      method"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.compute_loss??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5cedda5a-f753-4a62-a8a4-18772933ac0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'weight_masks': [Parameter containing:\n",
       "  tensor([1.0078, 0.9219, 1.2891,  ..., 0.9766, 1.0781, 1.4062], device='cuda:0',\n",
       "         dtype=torch.bfloat16, requires_grad=True),\n",
       "  Parameter containing:\n",
       "  tensor([0.5273, 0.2832, 0.5859,  ..., 0.1475, 0.4023, 0.7812], device='cuda:0',\n",
       "         dtype=torch.bfloat16, requires_grad=True)],\n",
       " 'bias_masks': [None, None]}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.model.merger.model.layers[8].mlp.up_proj.get_constrained_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d64d684-d171-446b-8339-46aa36a1782f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'Provide a concise, objective summary of the input text in up to three sentences, focusing on key actions and intentions without using second or third person pronouns.',\n",
       "  'role': 'system'},\n",
       " {'content': \"By . Ted Thornhill . A mom may have saved her teenage son's life by spying on his Facebook page, as she found death threats on it and alerted police. The concerned parent, from Salt Lake City, called the authorities when she found threats to shoot her son - who attends West High School â€“ had been posted on his profile page. The threats were allegedly made by two male teenagers, 16 and 17, who police arrested when they were found waiting in a car near the school on Friday. Potential life-saver: A mother of a West High School pupil alerted police after she saw threats to her son's life had been made on his Facebook page . Police said they found a gun, loaded magazine, ammunition, cash, marijuana and a bong inside the car. Salt Lake police detective Greg Wilking told Deseret News: â€˜She [the mother] had actually read threats and seen the threat on his Facebook page. There were very specific threats that they were going to go the high school and shoot her son. â€˜There was a picture of the gun on Instagram, the gun that was seized. And there were letters written on the hand that was holding the gun, and those letters were gang affiliated.â€™ Praise: The police said the mother did the right thing by reporting the threat (file picture) He described the threat to the teenagerâ€™s life as â€˜credibleâ€™. The two arrested boys, who were not West High School students, have been place in juvenile detention and charged with various misdemeanours. Police are not yet certain whether the two arrested teens were waiting to shoot the boy threatened on Facebook or what the origin of the dispute was. Wilking said that the mother had done the right thing by alerting the authorities to the threat. Sorry we are not currently accepting comments on this article.\",\n",
       "  'role': 'user'},\n",
       " {'content': \"A mother in Salt Lake City may have saved her teenage son's life by discovering death threats on his Facebook page and alerting the police. The threats, which included a picture of a gun on Instagram, were made by two male teenagers, aged 16 and 17. Police arrested the suspects near West High School on Friday, finding a gun, loaded magazine, ammunition, cash, marijuana, and a bong in their car. The teens, who are not students at West High, have been charged with various misdemeanors and placed in juvenile detention. Detective Greg Wilking praised the mother for her quick action, describing the threat as credible. The police are still investigating the origin of the dispute and the suspects' intentions.\",\n",
       "  'role': 'assistant'}]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2b2066e-951a-446c-a315-b027835dfdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4\n",
    "system = train_dataset[idx]['messages'][0]['content']\n",
    "prompt = train_dataset[idx]['messages'][1]['content']\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8175fe4-cccc-4ce6-9b28-5ca5320feb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emily met Tom at the parent-teacher conference and wants to discuss teaching methods and offers to give a guest lecture on the history of Pine Grove School. She also invites Tom to meet for coffee to talk more. Emily is working on a book about the history of education in colonial America.<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "answer = generate(text, trainer.model.merger, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0d368a2d-afd8-4e13-bf8b-94608d735d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewrite_train = load_dataset(\"HuggingFaceTB/smoltalk\", \"smol-rewrite\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e259767-bc32-46e4-bb1d-c847f19643d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You're an AI assistant for text re-writing. Rewrite the input text to make it more concise while preserving its core meaning.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Hey Michael,\n",
      "\n",
      "I hope you're doing well! I wanted to touch base with you regarding the progress on our nutrition curriculum project. I've been working on the lesson plans for grades 3-5 and have made some great strides. I'd love to get your feedback on what I've put together so far.\n",
      "\n",
      "Also, I wanted to share a new recipe I tried out this weekend - a quinoa and black bean salad that was a hit with my family. I thought you might enjoy it too, given our mutual love for healthy cooking. I'll attach the recipe below.\n",
      "\n",
      "Finally, I've been giving some thought to pursuing a Master's degree in Nutrition Education. I know you've been in the field for a while now, and I was hoping to get your advice on the best path forward. If you have any insights or recommendations, I'd be incredibly grateful.\n",
      "\n",
      "Looking forward to catching up soon!\n",
      "\n",
      "Best,\n",
      "Emily<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 300\n",
    "system = rewrite_train[idx]['messages'][0]['content']\n",
    "prompt = rewrite_train[idx]['messages'][1]['content']\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2f0006db-151c-4d85-9529-b3979e4fabd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emily is sharing updates on the nutrition curriculum project and seeking feedback on the lesson plans for grades 3-5. She also shares a new quinoa and black bean salad recipe and asks for advice on pursuing a Master's degree in Nutrition Education. Emily looks forward to catching up soon.<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "answer = generate(text, trainer.model.merger, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9aa5e940-61a6-43a9-a97f-2283cb444239",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.merger.save_pretrained(\"./trained_masks\", safe_serialization=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merger2",
   "language": "python",
   "name": "merger2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
